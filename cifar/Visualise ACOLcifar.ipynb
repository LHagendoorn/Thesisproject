{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising & measuring ACOL on CIFAR\n",
    "Use this notebook to inspect the clusters and see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10_ACOLPL_VGG16 as cifar10\n",
    "#import cifar10_ACOL_VGG16_onfc8 as cifar10\n",
    "#import cifar10_ACOL_VGG16_varianceSelection as cifar10\n",
    "#import cifar10_ACOL_VGG16_fc7_norelu as cifar10\n",
    "#import cifar10_ACOLPL_VGG16_selectedFeatures as cifar10\n",
    "\n",
    "eval_dir = '/code/logs/cifar10_eval'\n",
    "eval_data = 'test'\n",
    "checkpoint_dir = '/code/logs/cifar10_train'\n",
    "eval_interval_secs = 60 * 5\n",
    "num_examples = 10000\n",
    "run_once = True\n",
    "\n",
    "labelNames=np.array(['airplane','automobile','bird','cat','deer','dog','frog','horse', 'ship','truck'])\n",
    "batchsize = 48\n",
    "testSize=batchsize*50\n",
    "clustCount = 6\n",
    "classCount = 2\n",
    "#classNames = np.array(['Stuff and Horse','Animals'])\n",
    "#classNames = np.array(['airplane&bird','automobile&truck','cat&dog','deer&horse','frog&ship'])\n",
    "classNames = np.array(['Manmade','Animals'])\n",
    "#supLab = tf.constant([0,1,0,3,4,3,5,4,5,1]) \n",
    "supLab = tf.constant([0,0,1,1,1,1,1,1,0,0])\n",
    "#supLab = tf.constant([0,0,1,1,1,1,1,0,0,0]) #Man mande+horse vs animals-horse\n",
    "#supLab = tf.constant([0,0,1,0,0,1,0,1,1,1]) #Man mande vs animals mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_once(saver, summary_writer, summary_op, softmaxmat, images, labels, img_raw, superLabels):\n",
    "  \"\"\"Run Eval once.\n",
    "\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      #ckpt.model_checkpoint_path = \"/code/logs/cifar10_train/model.ckpt-47253\"\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      #print(ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "      return\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(num_examples / batch_size))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * batch_size\n",
    "      step = 0\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        softmaxmat_r, images_r, labels_r, img_raw_r, superLabels_r = sess.run([softmaxmat, images, labels, img_raw, superLabels])\n",
    "        step += 1\n",
    "\n",
    "      # Compute precision @ 1.\n",
    "      #precision = true_count / total_sample_count\n",
    "      #print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "      #summary = tf.Summary()\n",
    "      #summary.ParseFromString(sess.run(summary_op))\n",
    "      #summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "      #summary_writer.add_summary(summary, global_step)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "    return softmaxmat_r, images_r, labels_r, img_raw_r, superLabels_r\n",
    "\n",
    "def optimistic_restore(session, save_file):\n",
    "    reader = tf.train.NewCheckpointReader(save_file)\n",
    "    saved_shapes = reader.get_variable_to_shape_map()\n",
    "    var_names = sorted([(var.name, var.name.split(':')[0]) for var in tf.global_variables() if var.name.split(':')[0] in saved_shapes])\n",
    "    restore_vars = []\n",
    "    name2var = dict(zip(map(lambda x:x.name.split(':')[0], tf.global_variables()), tf.global_variables()))\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        for var_name, saved_var_name in var_names:\n",
    "            curr_var = name2var[saved_var_name]\n",
    "            var_shape = curr_var.get_shape().as_list()\n",
    "            if var_shape == saved_shapes[saved_var_name]:\n",
    "                restore_vars.append(curr_var)\n",
    "    saver = tf.train.Saver(restore_vars)\n",
    "    saver.restore(session, save_file)\n",
    "\n",
    "def evaluate():\n",
    "  \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = True #eval_data == 'test'\n",
    "    with tf.device('/cpu:0'):\n",
    "      images, img_raw, labels, superLabels = cifar10.inputs(eval_data=eval_data, raw=True)\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    _, _, softmaxMat = cifar10.inference(images, batchsize, testKeep=1.0)\n",
    "    #labels = tf.reshape(tf.one_hot(labels,12,dtype='int32'),(-1,2,6))\n",
    "    #flatSoftmaxMat = tf.reshape(softmaxMat,(-1,12))\n",
    "    # Calculate predictions.\n",
    "    #top_k_op = tf.nn.in_top_k(flatSoftmaxMat, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        cifar10.MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter('/code/logs/cifar10_eval', g)\n",
    "\n",
    "    total_softmaxmat = np.array([])\n",
    "    #total_images = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    total_img_raw = np.array([])\n",
    "    total_superlab = np.array([])\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "      ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "      print(ckpt.model_checkpoint_path)\n",
    "      if ckpt and ckpt.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "        #ckpt.model_checkpoint_path = \"/code/logs/cifar10_train/vgg16fc7_ACOL_frozen_2class10clust_01thresh\"\n",
    "        #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        optimistic_restore(sess, ckpt.model_checkpoint_path)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(ckpt.model_checkpoint_path)\n",
    "        # Assuming model_checkpoint_path looks something like:\n",
    "        #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "        # extract global_step from it.\n",
    "        global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "      else:\n",
    "        print('No checkpoint file found')\n",
    "        return\n",
    "      \n",
    "      coord = tf.train.Coordinator()\n",
    "      try:\n",
    "        threads = []\n",
    "        for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "          threads.extend(qr.create_threads(sess, coord=coord, daemon=True, start=True))\n",
    "\n",
    "        while True:\n",
    "          #softmaxmat_r, _, labels_r, img_raw_r, superLabels_r = eval_once(saver, summary_writer, summary_op, softmaxMat, images, labels, img_raw, superLabels)\n",
    "          softmaxmat_r, images_r, labels_r, img_raw_r, superLabels_r = sess.run([softmaxMat, images, labels, img_raw, superLabels])\n",
    "          print(superLabels_r.shape)\n",
    "          if total_labels.shape[0]>0:\n",
    "            total_softmaxmat = np.vstack([total_softmaxmat,softmaxmat_r])\n",
    "            #total_images = np.vstack([total_images,images_r])\n",
    "            #total_labels = np.hstack([total_labels,labels_r]) #NOTE vstack voor PL (for some reason)\n",
    "            total_labels = np.vstack([total_labels,labels_r]) #NOTE vstack voor PL (for some reason)\n",
    "            total_img_raw = np.vstack([total_img_raw,img_raw_r])\n",
    "            total_superlab = np.hstack([total_superlab,superLabels_r])\n",
    "          else:\n",
    "            total_softmaxmat = softmaxmat_r\n",
    "            #total_images = images_r\n",
    "            total_labels = labels_r\n",
    "            total_img_raw = img_raw_r\n",
    "            total_superlab = superLabels_r\n",
    "        \n",
    "          if total_labels.shape[0]+1 > testSize:\n",
    "            coord.request_stop()\n",
    "            break\n",
    "      \n",
    "          print(labels_r[:10])\n",
    "          print(total_labels.shape)\n",
    "      except Exception as e:  # pylint: disable=broad-except\n",
    "        coord.request_stop(e)\n",
    "    \n",
    "    return total_softmaxmat, 0, total_labels, total_img_raw, total_superlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(1,), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"batch:1\", shape=(48, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"batch_1:0\", shape=(48, 224, 224, 3), dtype=float32, device=/device:CPU:0)\n",
      "build model started\n",
      "Tensor(\"pool5:0\", shape=(48, 7, 7, 512), dtype=float32)\n",
      "build model finished: 0s\n",
      "/code/logs/cifar10_train/model.ckpt-50000\n",
      "/code/logs/cifar10_train/model.ckpt-50000\n",
      "(48,)\n",
      "[[8]\n",
      " [3]\n",
      " [0]\n",
      " [8]\n",
      " [6]\n",
      " [1]\n",
      " [6]\n",
      " [0]\n",
      " [6]\n",
      " [8]]\n",
      "(48, 1)\n",
      "(48,)\n",
      "[[0]\n",
      " [6]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [9]\n",
      " [3]\n",
      " [9]\n",
      " [7]\n",
      " [6]]\n",
      "(96, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [7]\n",
      " [6]\n",
      " [9]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [6]\n",
      " [1]\n",
      " [7]]\n",
      "(144, 1)\n",
      "(48,)\n",
      "[[2]\n",
      " [2]\n",
      " [5]\n",
      " [1]\n",
      " [8]\n",
      " [8]\n",
      " [5]\n",
      " [9]\n",
      " [7]\n",
      " [0]]\n",
      "(192, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [7]\n",
      " [0]\n",
      " [5]\n",
      " [8]\n",
      " [7]\n",
      " [3]\n",
      " [2]\n",
      " [7]\n",
      " [8]]\n",
      "(240, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [1]\n",
      " [9]\n",
      " [3]\n",
      " [6]\n",
      " [3]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [5]]\n",
      "(288, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [1]\n",
      " [6]\n",
      " [4]\n",
      " [9]\n",
      " [9]\n",
      " [7]\n",
      " [6]\n",
      " [2]\n",
      " [6]]\n",
      "(336, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [0]\n",
      " [6]\n",
      " [3]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [8]\n",
      " [4]\n",
      " [7]]\n",
      "(384, 1)\n",
      "(48,)\n",
      "[[2]\n",
      " [5]\n",
      " [7]\n",
      " [2]\n",
      " [4]\n",
      " [9]\n",
      " [2]\n",
      " [2]\n",
      " [6]\n",
      " [6]]\n",
      "(432, 1)\n",
      "(48,)\n",
      "[[9]\n",
      " [7]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]]\n",
      "(480, 1)\n",
      "(48,)\n",
      "[[0]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [0]]\n",
      "(528, 1)\n",
      "(48,)\n",
      "[[5]\n",
      " [0]\n",
      " [7]\n",
      " [0]\n",
      " [0]\n",
      " [6]\n",
      " [9]\n",
      " [1]\n",
      " [0]\n",
      " [6]]\n",
      "(576, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [7]\n",
      " [8]\n",
      " [4]\n",
      " [0]\n",
      " [3]\n",
      " [6]]\n",
      "(624, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [9]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [8]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [7]]\n",
      "(672, 1)\n",
      "(48,)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [6]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [6]\n",
      " [9]\n",
      " [9]]\n",
      "(720, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [8]\n",
      " [1]\n",
      " [1]\n",
      " [4]\n",
      " [8]\n",
      " [7]\n",
      " [2]\n",
      " [6]\n",
      " [9]]\n",
      "(768, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " [4]\n",
      " [1]\n",
      " [4]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [7]]\n",
      "(816, 1)\n",
      "(48,)\n",
      "[[2]\n",
      " [7]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [0]\n",
      " [3]]\n",
      "(864, 1)\n",
      "(48,)\n",
      "[[0]\n",
      " [4]\n",
      " [7]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [3]\n",
      " [3]\n",
      " [1]\n",
      " [2]]\n",
      "(912, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [0]\n",
      " [8]\n",
      " [9]\n",
      " [0]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [1]]\n",
      "(960, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [9]\n",
      " [7]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [9]\n",
      " [8]\n",
      " [2]]\n",
      "(1008, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [9]\n",
      " [6]\n",
      " [6]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [3]\n",
      " [0]\n",
      " [1]]\n",
      "(1056, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [0]\n",
      " [1]\n",
      " [6]\n",
      " [3]\n",
      " [9]\n",
      " [7]\n",
      " [3]\n",
      " [9]\n",
      " [0]]\n",
      "(1104, 1)\n",
      "(48,)\n",
      "[[3]\n",
      " [2]\n",
      " [3]\n",
      " [7]\n",
      " [5]\n",
      " [0]\n",
      " [1]\n",
      " [8]\n",
      " [2]\n",
      " [8]]\n",
      "(1152, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [9]\n",
      " [8]\n",
      " [7]\n",
      " [5]\n",
      " [3]\n",
      " [8]\n",
      " [1]\n",
      " [0]\n",
      " [7]]\n",
      "(1200, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [6]\n",
      " [3]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [7]\n",
      " [0]\n",
      " [0]\n",
      " [8]]\n",
      "(1248, 1)\n",
      "(48,)\n",
      "[[3]\n",
      " [5]\n",
      " [8]\n",
      " [4]\n",
      " [8]\n",
      " [4]\n",
      " [2]\n",
      " [9]\n",
      " [1]\n",
      " [2]]\n",
      "(1296, 1)\n",
      "(48,)\n",
      "[[7]\n",
      " [7]\n",
      " [2]\n",
      " [9]\n",
      " [6]\n",
      " [9]\n",
      " [2]\n",
      " [8]\n",
      " [6]\n",
      " [4]]\n",
      "(1344, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [2]\n",
      " [2]\n",
      " [4]\n",
      " [4]\n",
      " [3]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [6]]\n",
      "(1392, 1)\n",
      "(48,)\n",
      "[[3]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [5]\n",
      " [6]\n",
      " [9]\n",
      " [7]]\n",
      "(1440, 1)\n",
      "(48,)\n",
      "[[5]\n",
      " [0]\n",
      " [1]\n",
      " [4]\n",
      " [2]\n",
      " [1]\n",
      " [9]\n",
      " [6]\n",
      " [5]\n",
      " [3]]\n",
      "(1488, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [0]]\n",
      "(1536, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [3]\n",
      " [4]\n",
      " [4]\n",
      " [7]\n",
      " [2]\n",
      " [1]\n",
      " [7]\n",
      " [6]\n",
      " [4]]\n",
      "(1584, 1)\n",
      "(48,)\n",
      "[[2]\n",
      " [7]\n",
      " [9]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [6]\n",
      " [7]\n",
      " [4]\n",
      " [3]]\n",
      "(1632, 1)\n",
      "(48,)\n",
      "[[7]\n",
      " [4]\n",
      " [7]\n",
      " [8]\n",
      " [5]\n",
      " [6]\n",
      " [9]\n",
      " [1]\n",
      " [5]\n",
      " [5]]\n",
      "(1680, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [9]\n",
      " [9]\n",
      " [6]\n",
      " [0]\n",
      " [9]\n",
      " [4]\n",
      " [9]\n",
      " [4]\n",
      " [5]]\n",
      "(1728, 1)\n",
      "(48,)\n",
      "[[9]\n",
      " [9]\n",
      " [5]\n",
      " [4]\n",
      " [8]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [0]]\n",
      "(1776, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [0]\n",
      " [3]\n",
      " [4]\n",
      " [1]\n",
      " [8]\n",
      " [1]\n",
      " [3]\n",
      " [8]\n",
      " [3]]\n",
      "(1824, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [8]\n",
      " [4]\n",
      " [7]\n",
      " [9]\n",
      " [8]\n",
      " [4]\n",
      " [3]\n",
      " [6]\n",
      " [1]]\n",
      "(1872, 1)\n",
      "(48,)\n",
      "[[0]\n",
      " [2]\n",
      " [7]\n",
      " [3]\n",
      " [3]\n",
      " [7]\n",
      " [5]\n",
      " [3]\n",
      " [8]\n",
      " [1]]\n",
      "(1920, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [9]\n",
      " [4]\n",
      " [4]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [6]\n",
      " [3]\n",
      " [2]]\n",
      "(1968, 1)\n",
      "(48,)\n",
      "[[1]\n",
      " [6]\n",
      " [7]\n",
      " [4]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [9]]\n",
      "(2016, 1)\n",
      "(48,)\n",
      "[[9]\n",
      " [5]\n",
      " [8]\n",
      " [5]\n",
      " [7]\n",
      " [8]\n",
      " [9]\n",
      " [6]\n",
      " [7]\n",
      " [9]]\n",
      "(2064, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [6]\n",
      " [2]\n",
      " [2]]\n",
      "(2112, 1)\n",
      "(48,)\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " [0]\n",
      " [4]\n",
      " [0]\n",
      " [1]\n",
      " [8]\n",
      " [9]\n",
      " [2]]\n",
      "(2160, 1)\n",
      "(48,)\n",
      "[[8]\n",
      " [1]\n",
      " [8]\n",
      " [5]\n",
      " [7]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [5]]\n",
      "(2208, 1)\n",
      "(48,)\n",
      "[[4]\n",
      " [0]\n",
      " [3]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]]\n",
      "(2256, 1)\n",
      "(48,)\n",
      "[[3]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [6]\n",
      " [8]\n",
      " [0]\n",
      " [5]]\n",
      "(2304, 1)\n",
      "(48,)\n",
      "[[2]\n",
      " [9]\n",
      " [1]\n",
      " [3]\n",
      " [5]\n",
      " [9]\n",
      " [6]\n",
      " [6]\n",
      " [2]\n",
      " [7]]\n",
      "(2352, 1)\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "softmaxmat, _, lbls, img_raw, superlbls = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(superlbls.shape)\n",
    "superlbls[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgr2rgb = np.array([0,1,2])\n",
    "imgs_raw = img_raw[:,:,:,bgr2rgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['horse'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a7acc1ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 10\n",
    "plt.imshow(imgs_raw[ind].astype(np.uint8),vmin=0,vmax=255,aspect='equal', interpolation='none') \n",
    "labelNames[lbls[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "superClass = np.argmax(np.max(softmaxmat, axis=2),axis=1)\n",
    "print(softmaxmat.shape)\n",
    "#print(np.max(softmaxmat,axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster = []\n",
    "for i in range(testSize):\n",
    "    cluster.append(softmaxmat[i,superClass[i],:])\n",
    "cluster = np.argmax(np.array(cluster),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superClass[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superlbls[lbls.flatten()==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superlbls[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superClass</th>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Animals</th>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Manmade</th>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index\n",
       "superClass cluster       \n",
       "Animals    0           13\n",
       "           1          445\n",
       "           2          100\n",
       "           3          266\n",
       "           4          480\n",
       "           5          399\n",
       "Manmade    0          154\n",
       "           1           28\n",
       "           2          330\n",
       "           3          130\n",
       "           4           54\n",
       "           5            1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif = pd.DataFrame([classNames[superClass],cluster,range(testSize)],['superClass','cluster','index']).T\n",
    "classifGrouped = classif.groupby(['superClass','cluster']).count()\n",
    "classifGrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot 5 images of each cluster in class c:\n",
    "c='Manmade'\n",
    "#c='Animals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t=[classif[(classif['superClass']==c) & (classif['cluster']==i)]['index'] for i in range(clustCount)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imCount=10\n",
    "f, plots = plt.subplots(len(t),imCount)\n",
    "f.set_figwidth(10*7)\n",
    "f.set_figheight(clustCount*7)\n",
    "plt.tight_layout()\n",
    "for clust in range(len(t)):\n",
    "    for index in range(imCount):\n",
    "        if index < len(t[clust]):\n",
    "            plots[clust,index].set_title(labelNames[lbls[t[clust].iloc[index]]])\n",
    "            if len(imgs_raw[t[clust]].shape)>3:\n",
    "                plots[clust,index].imshow(imgs_raw[t[clust]][index,:,:,:].astype(np.uint8),vmin=0,vmax=255,aspect='equal', interpolation='none')\n",
    "            else:\n",
    "                plots[clust,index].imshow(imgs_raw[t[clust]][:,:,:].astype(np.uint8),vmin=0,vmax=255,aspect='equal', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred = softmaxmat\n",
    "onehotLabels = np.zeros((len(lbls),np.max(lbls)+1))\n",
    "onehotLabels[np.arange(len(lbls)),lbls.T] = 1 #NOTE lbls.T voor PL\n",
    "ypred = ypred.reshape((testSize,clustCount*classCount))\n",
    "#print(np.argmax(ypred,1))\n",
    "ypred = np.argmax(ypred,1)\n",
    "print(np.sum(onehotLabels[ypred==0],0))\n",
    "ylookup = np.argmax([np.sum(onehotLabels[ypred==i],0) for i in range(clustCount*classCount)],1)\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = np.equal(yconverted, lbls.T[0]) #NOTE lbls.T voor PL\n",
    "clustAcc = np.mean(correct_prediction)\n",
    "print('Clustering Accuracy: %g'%(clustAcc))\n",
    "print(np.reshape(ylookup,(classCount,clustCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcls = np.array(zip(ypred,lbls))\n",
    "counts = [np.bincount(clustcls[:,1][clustcls[:,0]==i]) for i in range(clustCount*classCount)]\n",
    "#Per clust \"accuracy\":\n",
    "clustAcc = [[np.max(c)/np.sum(c),np.sum(c),labelNames[np.argmax(c)]] if len(c)>0 else 0 for c in counts]\n",
    "print('Manmade')\n",
    "clustAcc[:clustCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Animals')\n",
    "clustAcc[clustCount:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pur = np.sum([np.max(c) if len(c)>0 else 0 for c in counts])/testSize\n",
    "print(\"Purity of clustering: %g\"%pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "superypred = np.argmax(np.max(softmaxmat,2),1)\n",
    "correct_prediction = np.equal(superypred, superlbls)\n",
    "print(superypred)\n",
    "print(superlbls)\n",
    "acc = np.mean(correct_prediction)\n",
    "print('Superclass Accuracy: %g'%(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TSNE things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TSNE raw CIFAR\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(verbose=2)\n",
    "#print(tf.reshape(imgs_raw,[imgs_raw.shape[0],-1]).shape)\n",
    "tsned = model.fit_transform(np.reshape(imgs_raw,[imgs_raw.shape[0],-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(tsned.shape)\n",
    "plt.figure(figsize=[50,50])\n",
    "for im in range(imgs_raw.shape[0]):\n",
    "    plt.imshow(imgs_raw[im].astype(np.uint8),vmin=0,vmax=255,aspect='equal', interpolation='none',extent=[tsned[im,0]-1,tsned[im,0]+1,tsned[im,1]-1,tsned[im,1]+1])\n",
    "plt.scatter(tsned[:,0],tsned[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for i in np.unique(lbls):\n",
    "    plt.scatter(tsned[[lbls==i]][:,0],tsned[[lbls==i]][:,1],cmap='viridis',label=labelNames[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
