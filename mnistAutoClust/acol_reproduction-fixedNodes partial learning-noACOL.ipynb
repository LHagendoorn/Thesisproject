{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACOL replication tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#imports and settings:\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from jupyterthemes import jtplot\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import threshold\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "#jtplot.style()\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "\n",
    "local_file = base.maybe_download(TRAIN_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_images = mnist.extract_images(f)\n",
    "    \n",
    "local_file = base.maybe_download(TRAIN_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_labels = mnist.extract_labels(f, one_hot=True)\n",
    "\n",
    "local_file = base.maybe_download(TEST_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_images = mnist.extract_images(f)\n",
    "\n",
    "local_file = base.maybe_download(TEST_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_labels = mnist.extract_labels(f, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustCount = 5\n",
    "classCount = 2\n",
    "net = 0\n",
    "trainsteps = 50000\n",
    "#trainsteps = 30000\n",
    "perc = 0.1\n",
    "validation_size=5000\n",
    "_epochs_completed_train = 0\n",
    "_index_in_epoch_train = 0\n",
    "_epochs_completed_val = 0\n",
    "_index_in_epoch_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][1,0] = 1\n",
    "y2[6][1,1] = 1\n",
    "y2[7][1,2] = 1\n",
    "y2[8][1,3] = 1\n",
    "y2[9][1,4] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_super_labels = np.array([y[np.argmax(train_labels[j])] for j in range(60000)])\n",
    "train_labels_clipped = np.array([y2[np.argmax(train_labels[j])] for j in range(int(60000*perc))])\n",
    "train_labels_clipped = np.concatenate([train_labels_clipped,np.array([emptyy2[np.argmax(train_labels[j])] for j in range(int(60000*perc),60000)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not 0 <= validation_size <= len(train_images):\n",
    "    raise ValueError(\n",
    "        'Validation size should be between 0 and {}. Received: {}.'\n",
    "        .format(len(train_images), validation_size))\n",
    "\n",
    "validation_images = train_images[:validation_size]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "validation_super_labels = train_super_labels[:validation_size]\n",
    "validation_labels_clipped = train_labels_clipped[:validation_size]\n",
    "train_images = train_images[validation_size:]\n",
    "train_labels = train_labels[validation_size:]\n",
    "train_super_labels = train_super_labels[validation_size:]\n",
    "train_labels_clipped = train_labels_clipped[validation_size:]\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1] * train_images.shape[2])\n",
    "train_images = train_images.astype(np.float32)\n",
    "train_images = np.multiply(train_images, 1.0 / 255.0)\n",
    "\n",
    "validation_images = validation_images.reshape(validation_images.shape[0],validation_images.shape[1] * validation_images.shape[2])\n",
    "validation_images = validation_images.astype(np.float32)\n",
    "validation_images = np.multiply(validation_images, 1.0 / 255.0)\n",
    "\n",
    "#    options = dict(dtype=dtypes.float32, reshape=True, seed=None)\n",
    "  \n",
    "#    train = DataSet(train_images, train_labels, **options)\n",
    "#    validation = DataSet(validation_images, validation_labels, **options)\n",
    "#    test = DataSet(test_images, test_labels, **options)\n",
    "  \n",
    "#    mnist = base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, shuffle, images, labels, superlabels, ep_compl, ep_ind):\n",
    "    _epochs_completed = ep_compl\n",
    "    _index_in_epoch = ep_ind\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = _index_in_epoch\n",
    "    _num_examples = images.shape[0]\n",
    "    # Shuffle for the first epoch\n",
    "    if _epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      _images = images[perm0]\n",
    "      _labels = labels[perm0]\n",
    "      _super_labels = superlabels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = _num_examples - start\n",
    "      images_rest_part = _images[start:_num_examples]\n",
    "      labels_rest_part = _labels[start:_num_examples]\n",
    "      super_labels_rest_part = _super_labels[start:_num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(_num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        _images = images[perm]\n",
    "        print(_images)\n",
    "        _labels = labels[perm]\n",
    "        _super_labels = super_labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size - rest_num_examples\n",
    "      end = _index_in_epoch\n",
    "      images_new_part = _images[start:end]\n",
    "      labels_new_part = _labels[start:end]\n",
    "      super_labels_new_part = _super_labels[start:end]\n",
    "      return np.concatenate((images_rest_part, images_new_part), axis=0) , np.concatenate((labels_rest_part, labels_new_part), axis=0), np.concatenate((super_labels_rest_part, super_labels_new_part), axis=0)\n",
    "    else:\n",
    "      _index_in_epoch += batch_size\n",
    "      end = _index_in_epoch\n",
    "      return _images[start:end], _labels[start:end], _super_labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper funcs\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def matrix_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    return tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "\n",
    "def avg_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_sum(totalSoft,2)\n",
    "\n",
    "def max_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_max(totalSoft,2)\n",
    "\n",
    "def initACOL(in_size,clust,clss):\n",
    "    acolLayers = []\n",
    "    for i in range(clss):\n",
    "        acolLayers.append([\n",
    "            weight_variable([in_size, clustCount]),\n",
    "            bias_variable([clustCount])\n",
    "        ])\n",
    "    return acolLayers\n",
    "        \n",
    "def connectACOL(inLayer,acol):\n",
    "    clust = []\n",
    "    for l in range(0,len(acol)):\n",
    "        clust.append(tf.matmul(inLayer, acol[l][0]) + acol[l][1])\n",
    "    return clust\n",
    "        \n",
    "def acol(input,clust_count, class_count):\n",
    "    acolLayers = []\n",
    "    for i in range(class_count):\n",
    "        if isinstance(input, tuple):\n",
    "                input = input[0]\n",
    "\n",
    "        #I don't know what this bit does, but I don't think it'll hurt anything\n",
    "        #Or maybe it does, who knows\n",
    "        input_shape = input.get_shape()\n",
    "        if input_shape.ndims == 4:\n",
    "            dim = 1\n",
    "            for d in input_shape[1:].as_list():\n",
    "                dim *= d\n",
    "        #    feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n",
    "        else:\n",
    "            feed_in, dim = (input, int(input_shape[-1]))\n",
    "\n",
    "        init_weights = tf.truncated_normal_initializer(0.0, stddev=0.1)#(0.0, stddev=0.01)\n",
    "        init_biases = tf.constant_initializer(1.0)#(0.1)\n",
    "\n",
    "        weights = weight_variable([dim, clust_count])\n",
    "        biases = bias_variable([clust_count])\n",
    "\n",
    "        acoll = tf.nn.xw_plus_b(input,weights,biases)\n",
    "        acolLayers.append(acol)\n",
    "    return acolLayers    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders (weights&biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    acol = initACOL(1024,clustCount,classCount)\n",
    "\n",
    "    #final fc layer\n",
    "    W_fc2 = weight_variable([1024, classCount])\n",
    "    b_fc2 = bias_variable([classCount])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    dropout=0.3\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    l_pool1 = max_pool_2x2(l_conv1)\n",
    "\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_pool1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_pool2, [-1, 7*7*64])\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(dropout))\n",
    "\n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([3,3,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([3,3,32,32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "\n",
    "    #conv_layer3\n",
    "    W_conv3 = weight_variable([3,3,32,64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "\n",
    "    #conv_layer4\n",
    "    W_conv4 = weight_variable([3,3,64,64])\n",
    "    b_conv4 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    #acol = initACOL(2048,clustCount,classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_conv1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    l_drop1 = tf.nn.dropout(l_pool2, tf.constant(0.25))\n",
    "\n",
    "    #conv 3\n",
    "    l_conv3 = tf.nn.relu(conv2d(l_drop1, W_conv3) + b_conv3)\n",
    "    #conv 4\n",
    "    l_conv4 = tf.nn.relu(conv2d(l_conv3, W_conv4) + b_conv4)\n",
    "    l_pool4 = max_pool_2x2(l_conv4)\n",
    "\n",
    "    l_drop2 = tf.nn.dropout(l_pool4, tf.constant(0.25))\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_drop2, [-1, 7*7*64])\n",
    "\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(0.5))\n",
    "    \n",
    "    #l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    l_acol = acol(l_fc1_drop,clustCount, classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper loss funcs\n",
    "def zBar(x):\n",
    "    xshape = x.shape.as_list()\n",
    "    s=[-1,xshape[1]*xshape[2]]\n",
    "    return tf.maximum(tf.reshape(x,s),0)\n",
    "    \n",
    "def bigU(zb):\n",
    "    return tf.matmul(tf.transpose(zb),zb)\n",
    "\n",
    "def selectNonDiag(x):\n",
    "    selection = np.ones(x.shape.as_list()[0],dtype='float32') - np.eye(x.shape.as_list()[0],dtype='float32')\n",
    "    return tf.reduce_sum(tf.multiply(x,selection))\n",
    "\n",
    "def bigV(x):\n",
    "    smallNu=tf.reshape(tf.reduce_sum(x,axis=0),[1,-1])\n",
    "    return tf.multiply(tf.transpose(smallNu),smallNu)\n",
    "\n",
    "def specialNormalise(x):\n",
    "    top = selectNonDiag(x)\n",
    "    bottom = tf.multiply(tf.to_float(x.shape[1]-1),tf.reduce_sum(tf.multiply(x,np.eye(x.shape[1],dtype='float32'))))\n",
    "    return tf.divide(top,bottom)\n",
    "\n",
    "def frobNorm(x):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "\n",
    "tresh = tf.constant(0.03)\n",
    "cc0=1.0\n",
    "cc1=1.0\n",
    "cc2=1.0\n",
    "cc3=0.0003\n",
    "cc4=0.000001\n",
    "cc5=1.0\n",
    "c0 = tf.constant(cc0)\n",
    "c1 = tf.constant(cc1)\n",
    "c2 = tf.constant(cc2)\n",
    "c3val = tf.constant(cc3)\n",
    "c3 = lambda affinity: tf.cond(tf.less(affinity,tresh),lambda: c3val,lambda: tf.constant(0.0))\n",
    "c4 =tf.constant(cc4)\n",
    "c5 = tf.constant(cc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate losses\n",
    "#affinity\n",
    "bZ = zBar(stackedClusts)#softmaxMat)\n",
    "bU = bigU(bZ)\n",
    "coact = selectNonDiag(bU)\n",
    "affinity = specialNormalise(bU)\n",
    "\n",
    "#balance\n",
    "bV=bigV(bZ)\n",
    "balance = specialNormalise(bV)\n",
    "\n",
    "#cluster cross entropy (added if secondary label is set for that input, hard to do with batches?)\n",
    "clust_cross_entropy = tf.reduce_mean(-tf.reduce_sum(y2_ * tf.log(tf.clip_by_value(softmaxMat,1e-10,1.0)), reduction_indices=[1,2]))\n",
    "\n",
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))\n",
    "\n",
    "frob = frobNorm(stackedClusts)#softmaxMat)\n",
    "\n",
    "loss = c0*cross_entropy + c5*clust_cross_entropy + c4*frob #+ c1*affinity + c2*tf.subtract(tf.constant(1.0),balance) + c3(affinity)*coact "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y = {0:[0,1], 1:[1,0]}\n",
    "y = {0:[1,0,0,0,0],\n",
    "     1:[1,0,0,0,0],\n",
    "     2:[0,1,0,0,0],\n",
    "     3:[0,1,0,0,0],\n",
    "     4:[0,0,1,0,0],\n",
    "     5:[0,0,1,0,0],\n",
    "     6:[0,0,0,1,0],\n",
    "     7:[0,0,0,1,0],\n",
    "     8:[0,0,0,0,1],\n",
    "     9:[0,0,0,0,1]}\n",
    "\n",
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][1,0] = 1\n",
    "y2[6][1,1] = 1\n",
    "y2[7][1,2] = 1\n",
    "y2[8][1,3] = 1\n",
    "y2[9][1,4] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "totalSteps = trainsteps\n",
    "stepCount=0\n",
    "batchSize = 128\n",
    "hist = {\n",
    "    'train_acc':[],\n",
    "    'val_acc':[],\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'affinity':[],\n",
    "    'balance':[],\n",
    "    'coactivity':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "step 0/50000 \n",
      " Train: accuracy: 0.578125, loss: 18.7872 \n",
      " Validation: accuracy: 0.539062 loss: 17.6459\n",
      " cross_entropy: 3.55839, clust_cross_entropy: 14.783, affinity: 0.303693, balance: 0.275041, coact: 51.7959, frob: 0.000356784\n",
      "step 100/50000 \n",
      " Train: accuracy: 0.460938, loss: 12.8675 \n",
      " Validation: accuracy: 0.515625 loss: 13.9348\n",
      " cross_entropy: 2.6921, clust_cross_entropy: 11.2972, affinity: 0.340154, balance: 0.015029, coact: 28.3422, frob: 0.000262559\n",
      "step 200/50000 \n",
      " Train: accuracy: 0.601562, loss: 9.67905 \n",
      " Validation: accuracy: 0.609375 loss: 8.74956\n",
      " cross_entropy: 2.40964, clust_cross_entropy: 7.77944, affinity: 0.294233, balance: 0.0179222, coact: 15.0048, frob: 0.00023443\n",
      "step 300/50000 \n",
      " Train: accuracy: 0.640625, loss: 6.37206 \n",
      " Validation: accuracy: 0.632812 loss: 7.21879\n",
      " cross_entropy: 1.39256, clust_cross_entropy: 4.71519, affinity: 0.268284, balance: 0.023835, coact: 9.48593, frob: 0.000188245\n",
      "step 400/50000 \n",
      " Train: accuracy: 0.632812, loss: 5.44639 \n",
      " Validation: accuracy: 0.65625 loss: 6.03272\n",
      " cross_entropy: 1.41249, clust_cross_entropy: 3.38667, affinity: 0.257526, balance: 0.0255815, coact: 5.30186, frob: 0.000168818\n",
      "step 500/50000 \n",
      " Train: accuracy: 0.703125, loss: 3.72971 \n",
      " Validation: accuracy: 0.75 loss: 4.34802\n",
      " cross_entropy: 1.02331, clust_cross_entropy: 3.23566, affinity: 0.195723, balance: 0.0286208, coact: 4.15194, frob: 0.000156181\n",
      "step 600/50000 \n",
      " Train: accuracy: 0.679688, loss: 3.71512 \n",
      " Validation: accuracy: 0.71875 loss: 3.91962\n",
      " cross_entropy: 1.01842, clust_cross_entropy: 1.91269, affinity: 0.190782, balance: 0.0164011, coact: 2.90758, frob: 0.000149986\n",
      "step 700/50000 \n",
      " Train: accuracy: 0.742188, loss: 2.74631 \n",
      " Validation: accuracy: 0.757812 loss: 2.65445\n",
      " cross_entropy: 0.780004, clust_cross_entropy: 1.85282, affinity: 0.160174, balance: 0.0468147, coact: 1.95445, frob: 0.000145371\n",
      "step 800/50000 \n",
      " Train: accuracy: 0.789062, loss: 2.4598 \n",
      " Validation: accuracy: 0.757812 loss: 2.60089\n",
      " cross_entropy: 0.777457, clust_cross_entropy: 1.64236, affinity: 0.144161, balance: 0.0321345, coact: 1.86649, frob: 0.000141315\n",
      "step 900/50000 \n",
      " Train: accuracy: 0.84375, loss: 1.99049 \n",
      " Validation: accuracy: 0.804688 loss: 2.41597\n",
      " cross_entropy: 0.508096, clust_cross_entropy: 1.4546, affinity: 0.144164, balance: 0.0383381, coact: 1.53147, frob: 0.000136526\n",
      "step 1000/50000 \n",
      " Train: accuracy: 0.765625, loss: 2.09829 \n",
      " Validation: accuracy: 0.796875 loss: 2.19901\n",
      " cross_entropy: 0.696157, clust_cross_entropy: 1.45967, affinity: 0.132445, balance: 0.0131601, coact: 1.67471, frob: 0.000135077\n",
      "step 1100/50000 \n",
      " Train: accuracy: 0.78125, loss: 2.40688 \n",
      " Validation: accuracy: 0.78125 loss: 1.96373\n",
      " cross_entropy: 0.592941, clust_cross_entropy: 1.01647, affinity: 0.125368, balance: 0.0245571, coact: 1.19427, frob: 0.00012631\n",
      "step 1200/50000 \n",
      " Train: accuracy: 0.8125, loss: 1.94189 \n",
      " Validation: accuracy: 0.773438 loss: 1.79949\n",
      " cross_entropy: 0.556901, clust_cross_entropy: 1.02026, affinity: 0.142062, balance: 0.0250248, coact: 1.29644, frob: 0.000127141\n",
      "step 1300/50000 \n",
      " Train: accuracy: 0.8125, loss: 1.501 \n",
      " Validation: accuracy: 0.8125 loss: 1.72959\n",
      " cross_entropy: 0.552694, clust_cross_entropy: 0.884386, affinity: 0.114631, balance: 0.0379331, coact: 1.44027, frob: 0.000129637\n",
      "step 1400/50000 \n",
      " Train: accuracy: 0.796875, loss: 1.7615 \n",
      " Validation: accuracy: 0.867188 loss: 1.47646\n",
      " cross_entropy: 0.554644, clust_cross_entropy: 0.837346, affinity: 0.0988604, balance: 0.0392294, coact: 1.21943, frob: 0.00012968\n",
      "step 1500/50000 \n",
      " Train: accuracy: 0.828125, loss: 1.75778 \n",
      " Validation: accuracy: 0.835938 loss: 1.7593\n",
      " cross_entropy: 0.440521, clust_cross_entropy: 0.989034, affinity: 0.111747, balance: 0.062183, coact: 1.18291, frob: 0.00012336\n",
      "step 1600/50000 \n",
      " Train: accuracy: 0.84375, loss: 1.57403 \n",
      " Validation: accuracy: 0.882812 loss: 1.46967\n",
      " cross_entropy: 0.452589, clust_cross_entropy: 0.909894, affinity: 0.105081, balance: 0.0355861, coact: 1.30899, frob: 0.000130226\n",
      "step 1700/50000 \n",
      " Train: accuracy: 0.9375, loss: 1.04519 \n",
      " Validation: accuracy: 0.859375 loss: 1.21806\n",
      " cross_entropy: 0.431717, clust_cross_entropy: 0.608977, affinity: 0.100934, balance: 0.0255824, coact: 1.07899, frob: 0.000132487\n",
      "step 1800/50000 \n",
      " Train: accuracy: 0.835938, loss: 1.40347 \n",
      " Validation: accuracy: 0.882812 loss: 1.22493\n",
      " cross_entropy: 0.425585, clust_cross_entropy: 0.731193, affinity: 0.0981817, balance: 0.0401942, coact: 1.11999, frob: 0.000131555\n",
      "step 1900/50000 \n",
      " Train: accuracy: 0.921875, loss: 1.2028 \n",
      " Validation: accuracy: 0.90625 loss: 1.20555\n",
      " cross_entropy: 0.393643, clust_cross_entropy: 0.494957, affinity: 0.0939776, balance: 0.0420531, coact: 1.15115, frob: 0.000127937\n",
      "step 2000/50000 \n",
      " Train: accuracy: 0.921875, loss: 1.29873 \n",
      " Validation: accuracy: 0.898438 loss: 1.37718\n",
      " cross_entropy: 0.319492, clust_cross_entropy: 0.660558, affinity: 0.101399, balance: 0.0650536, coact: 0.930224, frob: 0.000131508\n",
      "step 2100/50000 \n",
      " Train: accuracy: 0.875, loss: 1.09265 \n",
      " Validation: accuracy: 0.890625 loss: 1.20338\n",
      " cross_entropy: 0.488519, clust_cross_entropy: 0.619738, affinity: 0.0858968, balance: 0.0340844, coact: 1.13462, frob: 0.000131607\n",
      "step 2200/50000 \n",
      " Train: accuracy: 0.90625, loss: 1.08562 \n",
      " Validation: accuracy: 0.898438 loss: 1.15512\n",
      " cross_entropy: 0.382116, clust_cross_entropy: 0.56444, affinity: 0.0883369, balance: 0.0456434, coact: 1.13294, frob: 0.000132514\n",
      "step 2300/50000 \n",
      " Train: accuracy: 0.921875, loss: 1.02303 \n",
      " Validation: accuracy: 0.898438 loss: 1.05672\n",
      " cross_entropy: 0.352536, clust_cross_entropy: 0.609274, affinity: 0.0800897, balance: 0.0406682, coact: 1.08126, frob: 0.000133875\n",
      "step 2400/50000 \n",
      " Train: accuracy: 0.882812, loss: 1.2175 \n",
      " Validation: accuracy: 0.90625 loss: 0.815416\n",
      " cross_entropy: 0.414515, clust_cross_entropy: 0.763488, affinity: 0.082844, balance: 0.0247726, coact: 0.895806, frob: 0.00012893\n",
      "step 2500/50000 \n",
      " Train: accuracy: 0.851562, loss: 1.31675 \n",
      " Validation: accuracy: 0.898438 loss: 1.14891\n",
      " cross_entropy: 0.429247, clust_cross_entropy: 0.919992, affinity: 0.0953204, balance: 0.0650418, coact: 1.1685, frob: 0.000132963\n",
      "step 2600/50000 \n",
      " Train: accuracy: 0.898438, loss: 1.14166 \n",
      " Validation: accuracy: 0.90625 loss: 1.03693\n",
      " cross_entropy: 0.339311, clust_cross_entropy: 0.556661, affinity: 0.090394, balance: 0.0613297, coact: 1.20242, frob: 0.000138968\n",
      "step 2700/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.921579 \n",
      " Validation: accuracy: 0.890625 loss: 1.25692\n",
      " cross_entropy: 0.261439, clust_cross_entropy: 0.47252, affinity: 0.081894, balance: 0.0675038, coact: 1.07733, frob: 0.000135229\n",
      "step 2800/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.914853 \n",
      " Validation: accuracy: 0.882812 loss: 1.03831\n",
      " cross_entropy: 0.21988, clust_cross_entropy: 0.418577, affinity: 0.0722898, balance: 0.0574096, coact: 1.22952, frob: 0.000137428\n",
      "step 2900/50000 \n",
      " Train: accuracy: 0.90625, loss: 0.854718 \n",
      " Validation: accuracy: 0.929688 loss: 0.660043\n",
      " cross_entropy: 0.364039, clust_cross_entropy: 0.436175, affinity: 0.0782223, balance: 0.0574791, coact: 1.42552, frob: 0.0001402\n",
      "step 3000/50000 \n",
      " Train: accuracy: 0.890625, loss: 1.05663 \n",
      " Validation: accuracy: 0.898438 loss: 0.896371\n",
      " cross_entropy: 0.367213, clust_cross_entropy: 0.62718, affinity: 0.0797063, balance: 0.114858, coact: 0.967655, frob: 0.000141903\n",
      "step 3100/50000 \n",
      " Train: accuracy: 0.898438, loss: 0.86739 \n",
      " Validation: accuracy: 0.929688 loss: 0.713796\n",
      " cross_entropy: 0.355619, clust_cross_entropy: 0.417626, affinity: 0.067899, balance: 0.0476719, coact: 1.23519, frob: 0.000145656\n",
      "step 3200/50000 \n",
      " Train: accuracy: 0.90625, loss: 0.938521 \n",
      " Validation: accuracy: 0.929688 loss: 0.900666\n",
      " cross_entropy: 0.286451, clust_cross_entropy: 0.584703, affinity: 0.084096, balance: 0.0735274, coact: 1.14877, frob: 0.000133123\n",
      "step 3300/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.863277 \n",
      " Validation: accuracy: 0.890625 loss: 0.966293\n",
      " cross_entropy: 0.294751, clust_cross_entropy: 0.458424, affinity: 0.0684384, balance: 0.0312716, coact: 1.00958, frob: 0.000138541\n",
      "step 3400/50000 \n",
      " Train: accuracy: 0.882812, loss: 0.928032 \n",
      " Validation: accuracy: 0.90625 loss: 0.957661\n",
      " cross_entropy: 0.265036, clust_cross_entropy: 0.48074, affinity: 0.0851973, balance: 0.0232502, coact: 1.21471, frob: 0.000142235\n",
      "step 3500/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.597736 \n",
      " Validation: accuracy: 0.921875 loss: 0.724715\n",
      " cross_entropy: 0.235449, clust_cross_entropy: 0.294496, affinity: 0.0679861, balance: 0.0452349, coact: 1.06074, frob: 0.000148934\n",
      "step 3600/50000 \n",
      " Train: accuracy: 0.859375, loss: 1.00659 \n",
      " Validation: accuracy: 0.9375 loss: 0.654966\n",
      " cross_entropy: 0.35544, clust_cross_entropy: 0.545348, affinity: 0.068216, balance: 0.0709023, coact: 1.03172, frob: 0.000141948\n",
      "step 3700/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.66245 \n",
      " Validation: accuracy: 0.9375 loss: 0.687492\n",
      " cross_entropy: 0.210905, clust_cross_entropy: 0.251424, affinity: 0.0651775, balance: 0.0259672, coact: 1.19702, frob: 0.000147458\n",
      "step 3800/50000 \n",
      " Train: accuracy: 0.890625, loss: 0.834679 \n",
      " Validation: accuracy: 0.9375 loss: 0.622581\n",
      " cross_entropy: 0.271729, clust_cross_entropy: 0.415783, affinity: 0.0640965, balance: 0.0403117, coact: 1.1016, frob: 0.0001468\n",
      "step 3900/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.840566 \n",
      " Validation: accuracy: 0.960938 loss: 0.558228\n",
      " cross_entropy: 0.276838, clust_cross_entropy: 0.4234, affinity: 0.0758518, balance: 0.0201609, coact: 1.17074, frob: 0.000138364\n",
      "step 4000/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.838233 \n",
      " Validation: accuracy: 0.929688 loss: 0.618922\n",
      " cross_entropy: 0.22182, clust_cross_entropy: 0.471826, affinity: 0.0615924, balance: 0.0443805, coact: 1.22215, frob: 0.000145187\n",
      "step 4100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.588885 \n",
      " Validation: accuracy: 0.945312 loss: 0.850816\n",
      " cross_entropy: 0.176674, clust_cross_entropy: 0.322108, affinity: 0.0666123, balance: 0.0373296, coact: 1.5317, frob: 0.000154796\n",
      "step 4200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.449651 \n",
      " Validation: accuracy: 0.9375 loss: 0.707069\n",
      " cross_entropy: 0.115472, clust_cross_entropy: 0.189998, affinity: 0.0462557, balance: 0.094726, coact: 1.12303, frob: 0.000150716\n",
      "step 4300/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.597282 \n",
      " Validation: accuracy: 0.9375 loss: 0.714368\n",
      " cross_entropy: 0.280768, clust_cross_entropy: 0.394018, affinity: 0.0597454, balance: 0.0323775, coact: 1.04132, frob: 0.000150289\n",
      "step 4400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.546376 \n",
      " Validation: accuracy: 0.953125 loss: 0.752848\n",
      " cross_entropy: 0.156756, clust_cross_entropy: 0.274169, affinity: 0.0570006, balance: 0.015209, coact: 1.29001, frob: 0.000156673\n",
      "step 4500/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.558121 \n",
      " Validation: accuracy: 0.953125 loss: 0.610692\n",
      " cross_entropy: 0.160469, clust_cross_entropy: 0.225423, affinity: 0.0562364, balance: 0.0588983, coact: 1.05917, frob: 0.000151617\n",
      "step 4600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.469422 \n",
      " Validation: accuracy: 0.914062 loss: 1.23942\n",
      " cross_entropy: 0.180322, clust_cross_entropy: 0.270224, affinity: 0.06187, balance: 0.0271322, coact: 1.02004, frob: 0.000152426\n",
      "step 4700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.618768 \n",
      " Validation: accuracy: 0.929688 loss: 0.766114\n",
      " cross_entropy: 0.24493, clust_cross_entropy: 0.371738, affinity: 0.0509794, balance: 0.0541171, coact: 1.11638, frob: 0.000154281\n",
      "step 4800/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.565366 \n",
      " Validation: accuracy: 0.953125 loss: 0.537246\n",
      " cross_entropy: 0.191708, clust_cross_entropy: 0.426776, affinity: 0.0578441, balance: 0.0527343, coact: 0.991681, frob: 0.000156076\n",
      "step 4900/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.905921 \n",
      " Validation: accuracy: 0.929688 loss: 0.634024\n",
      " cross_entropy: 0.25236, clust_cross_entropy: 0.423981, affinity: 0.0479141, balance: 0.0317692, coact: 0.978996, frob: 0.00015884\n",
      "step 5000/50000 \n",
      " Train: accuracy: 0.90625, loss: 0.775752 \n",
      " Validation: accuracy: 0.945312 loss: 0.593468\n",
      " cross_entropy: 0.290922, clust_cross_entropy: 0.395051, affinity: 0.0573759, balance: 0.0407152, coact: 1.19713, frob: 0.00015947\n",
      "step 5100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.808003 \n",
      " Validation: accuracy: 0.960938 loss: 0.541103\n",
      " cross_entropy: 0.205787, clust_cross_entropy: 0.439769, affinity: 0.058917, balance: 0.0756645, coact: 1.05382, frob: 0.0001625\n",
      "step 5200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.508993 \n",
      " Validation: accuracy: 0.945312 loss: 0.570576\n",
      " cross_entropy: 0.190627, clust_cross_entropy: 0.311681, affinity: 0.0531427, balance: 0.0798693, coact: 1.25442, frob: 0.000153477\n",
      "step 5300/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.783308 \n",
      " Validation: accuracy: 0.9375 loss: 0.74274\n",
      " cross_entropy: 0.205288, clust_cross_entropy: 0.42898, affinity: 0.0675764, balance: 0.0599732, coact: 1.02544, frob: 0.000150674\n",
      "step 5400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.584439 \n",
      " Validation: accuracy: 0.9375 loss: 0.787733\n",
      " cross_entropy: 0.208767, clust_cross_entropy: 0.19397, affinity: 0.062478, balance: 0.0259344, coact: 1.16421, frob: 0.000156859\n",
      "step 5500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.551871 \n",
      " Validation: accuracy: 0.921875 loss: 0.562385\n",
      " cross_entropy: 0.226601, clust_cross_entropy: 0.296938, affinity: 0.0566408, balance: 0.096888, coact: 1.07999, frob: 0.000150874\n",
      "step 5600/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.634937 \n",
      " Validation: accuracy: 0.929688 loss: 0.873181\n",
      " cross_entropy: 0.2382, clust_cross_entropy: 0.423578, affinity: 0.0481498, balance: 0.0576804, coact: 1.12278, frob: 0.000159064\n",
      "step 5700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.523349 \n",
      " Validation: accuracy: 0.945312 loss: 0.700177\n",
      " cross_entropy: 0.206617, clust_cross_entropy: 0.276579, affinity: 0.0447012, balance: 0.0388325, coact: 1.33628, frob: 0.000159348\n",
      "step 5800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.496992 \n",
      " Validation: accuracy: 0.953125 loss: 0.470456\n",
      " cross_entropy: 0.170948, clust_cross_entropy: 0.253847, affinity: 0.067401, balance: 0.0372056, coact: 0.773734, frob: 0.000156581\n",
      "step 5900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.572183 \n",
      " Validation: accuracy: 0.945312 loss: 0.677083\n",
      " cross_entropy: 0.193681, clust_cross_entropy: 0.262045, affinity: 0.0582781, balance: 0.0289211, coact: 1.11179, frob: 0.000162159\n",
      "step 6000/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.558531 \n",
      " Validation: accuracy: 0.953125 loss: 0.605522\n",
      " cross_entropy: 0.146243, clust_cross_entropy: 0.205523, affinity: 0.0534566, balance: 0.0851515, coact: 1.11269, frob: 0.000160077\n",
      "step 6100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.649262 \n",
      " Validation: accuracy: 0.953125 loss: 0.659808\n",
      " cross_entropy: 0.129561, clust_cross_entropy: 0.310751, affinity: 0.0592226, balance: 0.0469496, coact: 1.14107, frob: 0.000161851\n",
      "step 6200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.526353 \n",
      " Validation: accuracy: 0.953125 loss: 0.571336\n",
      " cross_entropy: 0.208839, clust_cross_entropy: 0.442247, affinity: 0.0504647, balance: 0.0745445, coact: 0.892076, frob: 0.000163541\n",
      "step 6300/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.635859 \n",
      " Validation: accuracy: 0.953125 loss: 0.454512\n",
      " cross_entropy: 0.247108, clust_cross_entropy: 0.316552, affinity: 0.0655274, balance: 0.020505, coact: 0.992535, frob: 0.000157738\n",
      "step 6400/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.466374 \n",
      " Validation: accuracy: 0.929688 loss: 0.754444\n",
      " cross_entropy: 0.102319, clust_cross_entropy: 0.201768, affinity: 0.0458336, balance: 0.079798, coact: 1.12834, frob: 0.000167003\n",
      "step 6500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.462815 \n",
      " Validation: accuracy: 0.953125 loss: 0.590573\n",
      " cross_entropy: 0.145026, clust_cross_entropy: 0.190733, affinity: 0.0462432, balance: 0.0669018, coact: 1.20139, frob: 0.000162084\n",
      "step 6600/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.469982 \n",
      " Validation: accuracy: 0.929688 loss: 0.648674\n",
      " cross_entropy: 0.188962, clust_cross_entropy: 0.266155, affinity: 0.0557247, balance: 0.050383, coact: 1.01153, frob: 0.000162773\n",
      "step 6700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.512714 \n",
      " Validation: accuracy: 0.96875 loss: 0.5528\n",
      " cross_entropy: 0.14894, clust_cross_entropy: 0.295389, affinity: 0.0494536, balance: 0.0279459, coact: 1.05112, frob: 0.00015918\n",
      "step 6800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.524576 \n",
      " Validation: accuracy: 0.9375 loss: 0.522848\n",
      " cross_entropy: 0.172479, clust_cross_entropy: 0.325072, affinity: 0.0419818, balance: 0.066673, coact: 1.10505, frob: 0.000166801\n",
      "step 6900/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.542392 \n",
      " Validation: accuracy: 0.976562 loss: 0.53986\n",
      " cross_entropy: 0.18324, clust_cross_entropy: 0.267547, affinity: 0.0583799, balance: 0.0431293, coact: 1.11372, frob: 0.000168482\n",
      "step 7000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.4053 \n",
      " Validation: accuracy: 0.96875 loss: 0.566185\n",
      " cross_entropy: 0.125696, clust_cross_entropy: 0.247593, affinity: 0.0380559, balance: 0.0679073, coact: 0.823786, frob: 0.000165841\n",
      "step 7100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.707752 \n",
      " Validation: accuracy: 0.945312 loss: 0.536235\n",
      " cross_entropy: 0.26392, clust_cross_entropy: 0.327099, affinity: 0.0436919, balance: 0.0568963, coact: 0.86934, frob: 0.000158799\n",
      "step 7200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.440889 \n",
      " Validation: accuracy: 0.945312 loss: 0.582006\n",
      " cross_entropy: 0.16819, clust_cross_entropy: 0.268442, affinity: 0.0525766, balance: 0.0434791, coact: 1.06345, frob: 0.000161742\n",
      "step 7300/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.51335 \n",
      " Validation: accuracy: 0.960938 loss: 0.555252\n",
      " cross_entropy: 0.175964, clust_cross_entropy: 0.187093, affinity: 0.0330301, balance: 0.0554331, coact: 0.96522, frob: 0.000168721\n",
      "step 7400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.634713 \n",
      " Validation: accuracy: 0.96875 loss: 0.440574\n",
      " cross_entropy: 0.145678, clust_cross_entropy: 0.199998, affinity: 0.0436039, balance: 0.0774982, coact: 1.09358, frob: 0.000163943\n",
      "step 7500/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.539823 \n",
      " Validation: accuracy: 0.984375 loss: 0.404437\n",
      " cross_entropy: 0.184071, clust_cross_entropy: 0.288388, affinity: 0.0441728, balance: 0.0263748, coact: 0.888587, frob: 0.000167966\n",
      "step 7600/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.523712 \n",
      " Validation: accuracy: 0.960938 loss: 0.441107\n",
      " cross_entropy: 0.184875, clust_cross_entropy: 0.303473, affinity: 0.0424722, balance: 0.0347242, coact: 0.926856, frob: 0.000168914\n",
      "step 7700/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.444096 \n",
      " Validation: accuracy: 0.953125 loss: 0.567478\n",
      " cross_entropy: 0.128111, clust_cross_entropy: 0.231535, affinity: 0.0462387, balance: 0.10269, coact: 0.647568, frob: 0.000165159\n",
      "step 7800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.549675 \n",
      " Validation: accuracy: 0.96875 loss: 0.468998\n",
      " cross_entropy: 0.156548, clust_cross_entropy: 0.229629, affinity: 0.0436344, balance: 0.0157468, coact: 1.12877, frob: 0.000169544\n",
      "step 7900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.468678 \n",
      " Validation: accuracy: 0.976562 loss: 0.326698\n",
      " cross_entropy: 0.187887, clust_cross_entropy: 0.254127, affinity: 0.03933, balance: 0.0296222, coact: 0.983225, frob: 0.000171668\n",
      "step 8000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.514941 \n",
      " Validation: accuracy: 0.984375 loss: 0.389539\n",
      " cross_entropy: 0.21455, clust_cross_entropy: 0.246764, affinity: 0.0470827, balance: 0.046325, coact: 1.06315, frob: 0.000170242\n",
      "step 8100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.719722 \n",
      " Validation: accuracy: 0.929688 loss: 0.678465\n",
      " cross_entropy: 0.20412, clust_cross_entropy: 0.301742, affinity: 0.0467471, balance: 0.0745542, coact: 1.00481, frob: 0.000167424\n",
      "step 8200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.354185 \n",
      " Validation: accuracy: 0.960938 loss: 0.468957\n",
      " cross_entropy: 0.10417, clust_cross_entropy: 0.171038, affinity: 0.0306743, balance: 0.15598, coact: 0.964592, frob: 0.000177593\n",
      "step 8300/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.504122 \n",
      " Validation: accuracy: 0.953125 loss: 0.646425\n",
      " cross_entropy: 0.0938374, clust_cross_entropy: 0.310245, affinity: 0.0440911, balance: 0.0635283, coact: 0.770846, frob: 0.000176946\n",
      "step 8400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.516035 \n",
      " Validation: accuracy: 0.976562 loss: 0.418578\n",
      " cross_entropy: 0.163164, clust_cross_entropy: 0.219591, affinity: 0.0319448, balance: 0.0434155, coact: 0.895711, frob: 0.000171125\n",
      "step 8500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.3862 \n",
      " Validation: accuracy: 0.976562 loss: 0.433279\n",
      " cross_entropy: 0.141561, clust_cross_entropy: 0.254748, affinity: 0.0427733, balance: 0.0584274, coact: 1.04081, frob: 0.00017537\n",
      "step 8600/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.388705 \n",
      " Validation: accuracy: 0.953125 loss: 0.643753\n",
      " cross_entropy: 0.0947082, clust_cross_entropy: 0.274534, affinity: 0.0473125, balance: 0.114552, coact: 0.981967, frob: 0.000175471\n",
      "step 8700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.559373 \n",
      " Validation: accuracy: 0.945312 loss: 0.607222\n",
      " cross_entropy: 0.126102, clust_cross_entropy: 0.309062, affinity: 0.0421042, balance: 0.0618799, coact: 1.00723, frob: 0.000168353\n",
      "step 8800/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.406971 \n",
      " Validation: accuracy: 0.96875 loss: 0.49878\n",
      " cross_entropy: 0.117686, clust_cross_entropy: 0.243282, affinity: 0.0415952, balance: 0.0664698, coact: 0.91546, frob: 0.000177081\n",
      "step 8900/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.694589 \n",
      " Validation: accuracy: 0.960938 loss: 0.787859\n",
      " cross_entropy: 0.132748, clust_cross_entropy: 0.318666, affinity: 0.00665732, balance: 0.120818, coact: 0.132075, frob: 0.000204276\n",
      "step 9000/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.824342 \n",
      " Validation: accuracy: 0.929688 loss: 0.672291\n",
      " cross_entropy: 0.246751, clust_cross_entropy: 0.274513, affinity: 0.00644492, balance: 0.133996, coact: 0.0429511, frob: 0.000212192\n",
      "step 9100/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.494523 \n",
      " Validation: accuracy: 0.945312 loss: 0.823531\n",
      " cross_entropy: 0.116602, clust_cross_entropy: 0.202986, affinity: 0.00376987, balance: 0.121116, coact: 0.0341518, frob: 0.000214901\n",
      "step 9200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.643618 \n",
      " Validation: accuracy: 0.984375 loss: 0.408008\n",
      " cross_entropy: 0.129854, clust_cross_entropy: 0.199011, affinity: 0.0093375, balance: 0.13115, coact: 0.0646084, frob: 0.000211942\n",
      "step 9300/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.705028 \n",
      " Validation: accuracy: 0.953125 loss: 0.568973\n",
      " cross_entropy: 0.189424, clust_cross_entropy: 0.336785, affinity: 0.0131274, balance: 0.166759, coact: 0.0454315, frob: 0.000209963\n",
      "step 9400/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.519906 \n",
      " Validation: accuracy: 0.96875 loss: 0.498225\n",
      " cross_entropy: 0.128717, clust_cross_entropy: 0.135632, affinity: 0.0121011, balance: 0.123547, coact: 0.0714455, frob: 0.000220017\n",
      "step 9500/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.595584 \n",
      " Validation: accuracy: 0.960938 loss: 0.436489\n",
      " cross_entropy: 0.125766, clust_cross_entropy: 0.240105, affinity: 0.00584771, balance: 0.0793335, coact: 0.0459335, frob: 0.000217469\n",
      "step 9600/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.608478 \n",
      " Validation: accuracy: 0.96875 loss: 0.670317\n",
      " cross_entropy: 0.166195, clust_cross_entropy: 0.336392, affinity: 0.00128677, balance: 0.0385472, coact: 0.0710977, frob: 0.000216271\n",
      "step 9700/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.853485 \n",
      " Validation: accuracy: 0.960938 loss: 0.647684\n",
      " cross_entropy: 0.267255, clust_cross_entropy: 0.336335, affinity: 0.00417782, balance: 0.0874634, coact: 0.0319644, frob: 0.000219719\n",
      "step 9800/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.631917 \n",
      " Validation: accuracy: 0.96875 loss: 0.338414\n",
      " cross_entropy: 0.191526, clust_cross_entropy: 0.306049, affinity: 0.00405627, balance: 0.0901348, coact: 0.0462913, frob: 0.000214334\n",
      "step 9900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.699028 \n",
      " Validation: accuracy: 0.945312 loss: 0.697119\n",
      " cross_entropy: 0.230627, clust_cross_entropy: 0.246439, affinity: 0.00780276, balance: 0.131876, coact: 0.0564726, frob: 0.000214015\n",
      "step 10000/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.545271 \n",
      " Validation: accuracy: 0.96875 loss: 0.328488\n",
      " cross_entropy: 0.16133, clust_cross_entropy: 0.384226, affinity: 0.00542731, balance: 0.117774, coact: 0.0534385, frob: 0.000211435\n",
      "step 10100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.551359 \n",
      " Validation: accuracy: 0.96875 loss: 0.453134\n",
      " cross_entropy: 0.311973, clust_cross_entropy: 0.344213, affinity: 0.00754262, balance: 0.0798593, coact: 0.0229374, frob: 0.000215892\n",
      "step 10200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.444308 \n",
      " Validation: accuracy: 0.953125 loss: 0.759948\n",
      " cross_entropy: 0.161897, clust_cross_entropy: 0.200919, affinity: 0.00532156, balance: 0.0480667, coact: 0.0336492, frob: 0.000217558\n",
      "step 10300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.539767 \n",
      " Validation: accuracy: 0.953125 loss: 0.635026\n",
      " cross_entropy: 0.180289, clust_cross_entropy: 0.245377, affinity: 0.00176321, balance: 0.0862405, coact: 0.0370608, frob: 0.000225968\n",
      "step 10400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.551078 \n",
      " Validation: accuracy: 0.96875 loss: 0.288971\n",
      " cross_entropy: 0.125015, clust_cross_entropy: 0.211972, affinity: 0.0036414, balance: 0.0541826, coact: 0.0378205, frob: 0.000226891\n",
      "step 10500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.384442 \n",
      " Validation: accuracy: 0.96875 loss: 0.448919\n",
      " cross_entropy: 0.129477, clust_cross_entropy: 0.197372, affinity: 0.00380431, balance: 0.12785, coact: 0.0226798, frob: 0.000226303\n",
      "step 10600/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.34882 \n",
      " Validation: accuracy: 0.976562 loss: 0.39159\n",
      " cross_entropy: 0.0818677, clust_cross_entropy: 0.144683, affinity: 0.00384638, balance: 0.0801151, coact: 0.028141, frob: 0.000223351\n",
      "step 10700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.538143 \n",
      " Validation: accuracy: 0.960938 loss: 0.518638\n",
      " cross_entropy: 0.138936, clust_cross_entropy: 0.218689, affinity: 0.00526237, balance: 0.0939897, coact: 0.0563744, frob: 0.000230045\n",
      "step 10800/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.417231 \n",
      " Validation: accuracy: 0.953125 loss: 0.671435\n",
      " cross_entropy: 0.0940795, clust_cross_entropy: 0.1742, affinity: 0.00569496, balance: 0.0724236, coact: 0.0353418, frob: 0.000226275\n",
      "step 10900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.379994 \n",
      " Validation: accuracy: 0.96875 loss: 0.515824\n",
      " cross_entropy: 0.0955915, clust_cross_entropy: 0.192036, affinity: 0.00262422, balance: 0.0989999, coact: 0.0523798, frob: 0.000221138\n",
      "step 11000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.61559 \n",
      " Validation: accuracy: 0.96875 loss: 0.529694\n",
      " cross_entropy: 0.117409, clust_cross_entropy: 0.28887, affinity: 0.00301689, balance: 0.105141, coact: 0.0198244, frob: 0.000232517\n",
      "step 11100/50000 \n",
      " Train: accuracy: 1, loss: 0.399913 \n",
      " Validation: accuracy: 0.960938 loss: 0.644028\n",
      " cross_entropy: 0.14634, clust_cross_entropy: 0.184604, affinity: 0.00529681, balance: 0.109956, coact: 0.0220927, frob: 0.000230033\n",
      "step 11200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.389284 \n",
      " Validation: accuracy: 0.992188 loss: 0.284473\n",
      " cross_entropy: 0.134869, clust_cross_entropy: 0.214934, affinity: 0.00670835, balance: 0.0827734, coact: 0.0284402, frob: 0.000223675\n",
      "step 11300/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.482758 \n",
      " Validation: accuracy: 0.953125 loss: 0.531332\n",
      " cross_entropy: 0.153717, clust_cross_entropy: 0.172239, affinity: 0.00785839, balance: 0.082244, coact: 0.0196518, frob: 0.000234982\n",
      "step 11400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.446042 \n",
      " Validation: accuracy: 0.984375 loss: 0.497804\n",
      " cross_entropy: 0.116344, clust_cross_entropy: 0.24795, affinity: 0.00129602, balance: 0.104044, coact: 0.042501, frob: 0.000233316\n",
      "step 11500/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.504957 \n",
      " Validation: accuracy: 0.992188 loss: 0.409306\n",
      " cross_entropy: 0.158468, clust_cross_entropy: 0.184026, affinity: 0.00715434, balance: 0.0842909, coact: 0.0868584, frob: 0.000225406\n",
      "step 11600/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.472392 \n",
      " Validation: accuracy: 1 loss: 0.273226\n",
      " cross_entropy: 0.169427, clust_cross_entropy: 0.216821, affinity: 0.00455762, balance: 0.0362958, coact: 0.0292424, frob: 0.000224274\n",
      "step 11700/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.583842 \n",
      " Validation: accuracy: 0.960938 loss: 0.462321\n",
      " cross_entropy: 0.152818, clust_cross_entropy: 0.211478, affinity: 0.00164616, balance: 0.176756, coact: 0.00948638, frob: 0.000235796\n",
      "step 11800/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.553613 \n",
      " Validation: accuracy: 0.976562 loss: 0.379255\n",
      " cross_entropy: 0.202624, clust_cross_entropy: 0.384027, affinity: 0.00593509, balance: 0.0699329, coact: 0.0216405, frob: 0.000226827\n",
      "step 11900/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.525959 \n",
      " Validation: accuracy: 0.929688 loss: 0.42737\n",
      " cross_entropy: 0.0949903, clust_cross_entropy: 0.23796, affinity: 0.00203419, balance: 0.103343, coact: 0.0208859, frob: 0.000227782\n",
      "step 12000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.321907 \n",
      " Validation: accuracy: 0.976562 loss: 0.476923\n",
      " cross_entropy: 0.0820481, clust_cross_entropy: 0.188365, affinity: 0.00306578, balance: 0.119337, coact: 0.0352817, frob: 0.000228945\n",
      "step 12100/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.564633 \n",
      " Validation: accuracy: 0.984375 loss: 0.403143\n",
      " cross_entropy: 0.121568, clust_cross_entropy: 0.243051, affinity: 0.00332517, balance: 0.136431, coact: 0.0261634, frob: 0.000236087\n",
      "step 12200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.401274 \n",
      " Validation: accuracy: 0.96875 loss: 0.558966\n",
      " cross_entropy: 0.051806, clust_cross_entropy: 0.139205, affinity: 0.00374437, balance: 0.0664258, coact: 0.014407, frob: 0.000231234\n",
      "step 12300/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.703925 \n",
      " Validation: accuracy: 1 loss: 0.232351\n",
      " cross_entropy: 0.20479, clust_cross_entropy: 0.341018, affinity: 0.00131281, balance: 0.139057, coact: 0.031832, frob: 0.000226452\n",
      "step 12400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.449931 \n",
      " Validation: accuracy: 0.96875 loss: 0.410941\n",
      " cross_entropy: 0.134952, clust_cross_entropy: 0.184672, affinity: 0.0039091, balance: 0.110714, coact: 0.0185499, frob: 0.000228792\n",
      "step 12500/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.410484 \n",
      " Validation: accuracy: 0.960938 loss: 0.513616\n",
      " cross_entropy: 0.105231, clust_cross_entropy: 0.139681, affinity: 0.00299105, balance: 0.0205029, coact: 0.0149323, frob: 0.000228758\n",
      "step 12600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.413923 \n",
      " Validation: accuracy: 0.960938 loss: 0.482098\n",
      " cross_entropy: 0.0951934, clust_cross_entropy: 0.165695, affinity: 0.0049279, balance: 0.109167, coact: 0.0229411, frob: 0.000231574\n",
      "step 12700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.578694 \n",
      " Validation: accuracy: 0.992188 loss: 0.296693\n",
      " cross_entropy: 0.162333, clust_cross_entropy: 0.257648, affinity: 0.00253485, balance: 0.100645, coact: 0.0221809, frob: 0.000234092\n",
      "step 12800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.540815 \n",
      " Validation: accuracy: 0.960938 loss: 0.367625\n",
      " cross_entropy: 0.151721, clust_cross_entropy: 0.163408, affinity: 0.0026305, balance: 0.098744, coact: 0.0237845, frob: 0.000235243\n",
      "step 12900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.571913 \n",
      " Validation: accuracy: 0.953125 loss: 0.600981\n",
      " cross_entropy: 0.151386, clust_cross_entropy: 0.272061, affinity: 0.0025, balance: 0.199892, coact: 0.012473, frob: 0.000231719\n",
      "step 13000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.590961 \n",
      " Validation: accuracy: 0.976562 loss: 0.427259\n",
      " cross_entropy: 0.125111, clust_cross_entropy: 0.238292, affinity: 0.00496138, balance: 0.195254, coact: 0.0180194, frob: 0.000240142\n",
      "step 13100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.353666 \n",
      " Validation: accuracy: 0.960938 loss: 0.291537\n",
      " cross_entropy: 0.105496, clust_cross_entropy: 0.122389, affinity: 0.00385739, balance: 0.103877, coact: 0.0286222, frob: 0.000243094\n",
      "step 13200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.450413 \n",
      " Validation: accuracy: 0.945312 loss: 0.450225\n",
      " cross_entropy: 0.170045, clust_cross_entropy: 0.259575, affinity: 0.00209742, balance: 0.0628315, coact: 0.0447656, frob: 0.000241871\n",
      "step 13300/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.57396 \n",
      " Validation: accuracy: 0.984375 loss: 0.453527\n",
      " cross_entropy: 0.168024, clust_cross_entropy: 0.174123, affinity: 0.00205274, balance: 0.171966, coact: 0.0250454, frob: 0.000229478\n",
      "step 13400/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.36838 \n",
      " Validation: accuracy: 0.992188 loss: 0.304378\n",
      " cross_entropy: 0.114917, clust_cross_entropy: 0.180877, affinity: 0.00117141, balance: 0.03795, coact: 0.0307605, frob: 0.000241599\n",
      "step 13500/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.393299 \n",
      " Validation: accuracy: 0.976562 loss: 0.277919\n",
      " cross_entropy: 0.150165, clust_cross_entropy: 0.11565, affinity: 0.00252497, balance: 0.0357231, coact: 0.0205873, frob: 0.000235378\n",
      "step 13600/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.522076 \n",
      " Validation: accuracy: 0.960938 loss: 0.448688\n",
      " cross_entropy: 0.195925, clust_cross_entropy: 0.129451, affinity: 0.00334448, balance: 0.0908552, coact: 0.0285709, frob: 0.000242302\n"
     ]
    }
   ],
   "source": [
    "convy2 = y2\n",
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images, train_labels, train_super_labels,_epochs_completed_train,_index_in_epoch_train)\n",
    "    trainbatch = (trainbatch[0],np.array([y[np.argmax(trainbatch[1][j])] for j in range(len(trainbatch[1]))]),np.array([convy2[np.argmax(trainbatch[1][j])] for j in range(len(trainbatch[1]))]))\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels, validation_super_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    valbatch = (valbatch[0],np.array([y[np.argmax(valbatch[1][j])] for j in range(len(valbatch[1]))]),np.array([convy2[np.argmax(valbatch[1][j])] for j in range(len(valbatch[1]))]))\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2]})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        #hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        #hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        #hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        #frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, frob: %g\"%(cc0*entr, cc5*entr2,cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testSize = 1000\n",
    "testbatch = mnist.test.next_batch(testSize)\n",
    "testbatch = (testbatch[0],np.array([y[np.argmax(testbatch[1][j])] for j in range(len(testbatch[1]))]),np.array([y2[np.argmax(testbatch[1][j])] for j in range(len(testbatch[1]))]))\n",
    "\n",
    "test_loss,test_acc = sess.run([loss,accuracy],{x: testbatch[0], y_: testbatch[1], y2_: testbatch[2]})\n",
    "print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot accuracy and loss\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(211)\n",
    "plt.plot(hist['train_acc'],'-b',label='train_acc')\n",
    "plt.plot(hist['val_acc'],'-r',label='val_acc')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['val_loss'],'-r',label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "#plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['affinity'],'-r',label='affinity')\n",
    "plt.plot(np.subtract(1,hist['balance']),'-y',label='balance')\n",
    "plt.plot(hist['coactivity'],'-g',label='coactivity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digitTrace = np.zeros((classCount*clustCount,784))\n",
    "digitTraceCount = np.zeros((classCount*clustCount))\n",
    "digitCount = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    tb = mnist.test.next_batch(1)\n",
    "    digitCount[np.argmax(tb[1])]+=1\n",
    "    testbatch = (tb[0],np.array([y[np.argmax(tb[1][j])] for j in range(len(tb[1]))]))\n",
    "    smMat, acc = sess.run([softmaxMat,accuracy],feed_dict={x: testbatch[0], y_: testbatch[1]})\n",
    "    ypred = softmaxMat.eval({x: testbatch[0], y_: testbatch[1]})\n",
    "    digitTrace[np.argmax(ypred),:] += tb[0].ravel()\n",
    "    digitTraceCount[np.argmax(ypred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digitCount)\n",
    "print(digitTraceCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stepCount = len(hist['train_acc'])*100\n",
    "with open('./trainlog.txt','ab') as f:\n",
    "    f.write('lr: %g, batchsize: %i, steps: %i, thresh: %g, c1: %g, c2: %g, c3: %g, c4: %g, test_acc: %g, test_loss: %g\\n'%\n",
    "            (lr,batchSize,stepCount,tresh.eval(), cc1, cc2, cc3, cc4, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = mnist.test.next_batch(10000)\n",
    "#tb[0][:,:] = threshold(tb[0][:,:],threshmin=0.5,newval=0)\n",
    "#tb[0][:,:] = threshold(tb[0][:,:],threshmax=0.49,newval=1)\n",
    "testbatch = (tb[0],np.array([y[np.argmax(tb[1][j])>4] for j in range(len(tb[1]))]))\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1]}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((tb[0].shape[0],clustCount*classCount))\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(tb[1][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(tb[1],1).astype('int32'))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(accuracy))\n",
    "print(ylookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it to k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb0 = [tb[0][np.argmax(tb[1],1)<5],tb[1][np.argmax(tb[1],1)<5]]\n",
    "tb1 = [tb[0][np.argmax(tb[1],1)>4],tb[1][np.argmax(tb[1],1)>4]]\n",
    "#<5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km0_ypred = kmeans.fit_transform(tb0[0])\n",
    "km0_ypred = np.argmax(km0_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb0[1][km0_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km0_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb0[1],1).astype('int32'))\n",
    "km0_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "#>4\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km1_ypred = kmeans.fit_transform(tb1[0])\n",
    "km1_ypred = np.argmax(km1_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb1[1][km1_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km1_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb1[1],1).astype('int32'))\n",
    "km1_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "print('ACOL Accuracy: %g'%(accuracy))\n",
    "print('KMeans Accuracy: %g'%((km0_accuracy+km1_accuracy)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualise kmeans\n",
    "digitTrace = np.concatenate([[np.sum(tb0[0][km0_ypred==i,:],axis=0) for i in range(clustCount)],\n",
    "                       [np.sum(tb1[0][km1_ypred==i,:],axis=0) for i in range(clustCount)]])\n",
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
