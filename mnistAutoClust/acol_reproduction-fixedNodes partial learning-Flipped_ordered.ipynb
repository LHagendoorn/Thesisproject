{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACOL replication tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perc = 1.0\n",
    "#balanced = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from notifiers import notify\n",
    "#imports and settings:\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from jupyterthemes import jtplot\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import threshold\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "#jtplot.style()\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "\n",
    "local_file = base.maybe_download(TRAIN_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_images = mnist.extract_images(f)\n",
    "    \n",
    "local_file = base.maybe_download(TRAIN_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_labels = mnist.extract_labels(f, one_hot=True)\n",
    "\n",
    "local_file = base.maybe_download(TEST_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_images = mnist.extract_images(f)\n",
    "\n",
    "local_file = base.maybe_download(TEST_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_labels = mnist.extract_labels(f, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustCount = 10\n",
    "classCount = 2\n",
    "net = 0\n",
    "#trainsteps = 50000\n",
    "trainsteps = 30000\n",
    "#perc = 0.1\n",
    "#balanced = True\n",
    "validation_size=5000*2\n",
    "_epochs_completed_train = 0\n",
    "_index_in_epoch_train = 0\n",
    "_epochs_completed_val = 0\n",
    "_index_in_epoch_val = 0\n",
    "_epochs_completed_test = 0\n",
    "_index_in_epoch_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][0,5] = 1\n",
    "y2[6][0,6] = 1\n",
    "y2[7][0,7] = 1\n",
    "y2[8][0,8] = 1\n",
    "y2[9][0,9] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_super_labels = np.array([y[np.argmax(train_labels[j])] for j in range(train_labels.shape[0])])\n",
    "#test_super_labels = np.array([y[np.argmax(test_labels[j])] for j in range(test_labels.shape[0])])\n",
    "\n",
    "#train_labels = np.array([y2[np.argmax(train_labels[j])] for j in range(train_labels.shape[0])])\n",
    "#test_labels = np.array([y2[np.argmax(test_labels[j])] for j in range(test_labels.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imFlipper = [slice(None)] * 3\n",
    "imFlipper[2] = slice(None, None, -1)\n",
    "\n",
    "lblFlipper = [slice(None)] * 3\n",
    "lblFlipper[1] = slice(None, None, -1)\n",
    "#train_l = train_images.shape[0]\n",
    "#test_l = test_images.shape[0]\n",
    "#print train_images.shape\n",
    "#train_images = np.vstack([train_images,train_images[tuple(indexer)]])\n",
    "#test_images = np.vstack([test_images,test_images[tuple(indexer)]])\n",
    "\n",
    "#train_super_labels = np.vstack([np.hstack([np.zeros(train_l),np.ones(train_l)]),np.hstack([np.ones(train_l),np.zeros(train_l)])])\n",
    "#test_super_labels = np.vstack([np.hstack([np.zeros(test_l),np.ones(test_l)]),np.hstack([np.ones(test_l),np.zeros(test_l)])])\n",
    "\n",
    "#train_labels = np.vstack([train_labels,train_labels])\n",
    "#test_labels = np.vstack([test_labels,test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle before selecting validation and test subsets\n",
    "#perm0 = np.arange(train_l*2)\n",
    "#np.random.shuffle(perm0)\n",
    "#train_images = train_images[perm0]\n",
    "#train_labels = train_labels[perm0]\n",
    "#train_super_labels = train_super_labels[perm0]\n",
    "\n",
    "#perm1 = np.arange(test_l*2)\n",
    "#np.random.shuffle(perm1)\n",
    "#test_images = test_images[perm1]\n",
    "#test_labels = test_labels[perm1]\n",
    "#test_super_labels = test_super_labels[perm1]\n",
    "\n",
    "train_labels = np.array([y2[np.argmax(train_labels[j])] for j in range(train_labels.shape[0])])\n",
    "test_labels = np.array([y2[np.argmax(test_labels[j])] for j in range(test_labels.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not 0 <= validation_size <= len(train_images):\n",
    "    raise ValueError(\n",
    "        'Validation size should be between 0 and {}. Received: {}.'\n",
    "        .format(len(train_images), validation_size))\n",
    "\n",
    "validation_images = train_images[:validation_size]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "#validation_labels_clipped = train_labels_clipped[:validation_size]\n",
    "train_images = train_images[validation_size:]\n",
    "train_labels = train_labels[validation_size:]\n",
    "#train_labels_clipped = train_labels_clipped[validation_size:]\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1] * train_images.shape[2])\n",
    "train_images = train_images.astype(np.float32)\n",
    "train_images = np.multiply(train_images, 1.0 / 255.0)\n",
    "\n",
    "validation_images = validation_images.reshape(validation_images.shape[0],validation_images.shape[1] * validation_images.shape[2])\n",
    "validation_images = validation_images.astype(np.float32)\n",
    "validation_images = np.multiply(validation_images, 1.0 / 255.0)\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1] * test_images.shape[2])\n",
    "test_images = test_images.astype(np.float32)\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "trainCount=len(train_images)\n",
    "if balanced:\n",
    "    inds = []\n",
    "    classSize = int(np.ceil(trainCount*perc/10))\n",
    "    for j in range(10):\n",
    "        inds.extend([i for i, x in enumerate(np.argmax(np.sum(train_labels,1),1)) if x == j][:classSize])\n",
    "    random.shuffle(inds)\n",
    "\n",
    "    train_labels_clipped = np.array([train_labels[j,:,:] for j in inds])\n",
    "    train_labels_clipped = np.concatenate([train_labels_clipped,np.array([emptyy2[np.argmax(train_labels[j])] for j in range(trainCount) if j not in inds])])\n",
    "    \n",
    "    train_images_labelled_only = train_images[inds,:]\n",
    "    #train_super_labels_labelled_only = train_super_labels[inds]\n",
    "    train_labels_labelled_only = np.array([train_labels[j,:,:] for j in inds])\n",
    "else:\n",
    "    train_labels_clipped = np.array([y2[np.argmax(train_labels[j])] for j in range(int(train_labels.shape[0]*perc))])\n",
    "    train_labels_clipped = np.concatenate([train_labels_clipped,np.array([emptyy2[np.argmax(train_labels[j])] for j in range(int(train_labels.shape[0]*perc),train_labels.shape[0])])])\n",
    "    \n",
    "    train_images_labelled_only = train_images[range(int(train_labels.shape[0]*perc)),:]\n",
    "    #train_super_labels_labelled_only = train_super_labels[range(int(train_labels.shape[0]*perc))]\n",
    "    train_labels_labelled_only = np.array([y2[np.argmax(train_labels[j])] for j in range(int(train_labels.shape[0]*perc))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, shuffle, images, labels, ep_compl, ep_ind):\n",
    "    if batch_size/2.0 < 1:\n",
    "        if np.random.random() < 0.5:\n",
    "            flipped = np.array([1,0]).reshape((1,2))\n",
    "        else:\n",
    "            flipped = np.array([0,1]).reshape((1,2))\n",
    "    _epochs_completed = ep_compl\n",
    "    _index_in_epoch = ep_ind\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = _index_in_epoch\n",
    "    _num_examples = images.shape[0]\n",
    "    #Flip half\n",
    "    # Shuffle for the first epoch   \n",
    "    if _epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      _images = images[perm0]\n",
    "      _labels = labels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = _num_examples - start\n",
    "      images_rest_part = _images[start:_num_examples]\n",
    "      labels_rest_part = _labels[start:_num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(_num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        _images = images[perm]\n",
    "        #print(_images)\n",
    "        _labels = labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size - rest_num_examples\n",
    "      end = _index_in_epoch\n",
    "      images_new_part = _images[start:end]\n",
    "      labels_new_part = _labels[start:end]\n",
    "      #super_labels_new_part = _super_labels[start:end]\n",
    "      im = np.concatenate((images_rest_part, images_new_part), axis=0)                 \n",
    "      lbl = np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "      #flip half then reshuffle batch\n",
    "      if batch_size>1:\n",
    "          im = np.vstack([im[:(batch_size/2),:],im[(batch_size/2):,:].reshape((-1,28,28))[tuple(imFlipper)].reshape(-1,28*28)])\n",
    "          lbl = np.vstack([lbl[:(batch_size/2),:,:],lbl[(batch_size/2):,:,:][tuple(lblFlipper)]])\n",
    "          suplbl = np.vstack([[[1,0]]*(batch_size/2), [[0,1]]*(batch_size/2)])\n",
    "          perm1 = np.arange(_num_examples)\n",
    "          np.random.shuffle(perm1)\n",
    "          im = im[perm1]\n",
    "          lbl = lbl[perm1]\n",
    "          suplbl = suplbl[perm1]\n",
    "      else:\n",
    "          if flipped[0,0]: #not flipped\n",
    "            suplbl = flipped\n",
    "            pass\n",
    "          else:\n",
    "            im = im.reshape((-1,28,28))[tuple(imFlipper)].reshape(-1,28*28)\n",
    "            lbl = lbl[tuple(lblFlipper)]\n",
    "            suplbl = flipped\n",
    "            perm1 = np.arange(batch_size)\n",
    "      return im, suplbl, lbl\n",
    "    else:\n",
    "      _index_in_epoch += batch_size\n",
    "      end = _index_in_epoch\n",
    "      im = _images[start:end]\n",
    "      lbl = _labels[start:end]\n",
    "      if batch_size>1:\n",
    "          im = np.vstack([im[:(batch_size/2),:],im[(batch_size/2):,:].reshape((-1,28,28))[tuple(imFlipper)].reshape(-1,28*28)])\n",
    "          lbl = np.vstack([lbl[:(batch_size/2),:,:],lbl[(batch_size/2):,:,:][tuple(lblFlipper)]])\n",
    "          suplbl = np.vstack([[[1,0]]*(batch_size/2), [[0,1]]*(batch_size/2)])\n",
    "          perm1 = np.arange(batch_size)\n",
    "          np.random.shuffle(perm1)\n",
    "          im = im[perm1]\n",
    "          lbl = lbl[perm1]\n",
    "          suplbl = suplbl[perm1]\n",
    "      else:\n",
    "          if flipped[0,0]: #not flipped\n",
    "            suplbl = flipped\n",
    "            pass\n",
    "          else:\n",
    "            im = im.reshape((-1,28,28))[tuple(imFlipper)].reshape(-1,28*28)\n",
    "            lbl = lbl[tuple(lblFlipper)]\n",
    "            suplbl = flipped\n",
    "            perm1 = np.arange(batch_size)\n",
    "      return im, suplbl, lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper funcs\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def matrix_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    return tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "\n",
    "def avg_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_sum(totalSoft,2)\n",
    "\n",
    "def max_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_max(totalSoft,2)\n",
    "\n",
    "def initACOL(in_size,clust,clss):\n",
    "    acolLayers = []\n",
    "    for i in range(clss):\n",
    "        acolLayers.append([\n",
    "            weight_variable([in_size, clustCount]),\n",
    "            bias_variable([clustCount])\n",
    "        ])\n",
    "    return acolLayers\n",
    "        \n",
    "def connectACOL(inLayer,acol):\n",
    "    clust = []\n",
    "    for l in range(0,len(acol)):\n",
    "        clust.append(tf.matmul(inLayer, acol[l][0]) + acol[l][1])\n",
    "    return clust\n",
    "        \n",
    "def acol(input,clust_count, class_count):\n",
    "    acolLayers = []\n",
    "    for i in range(class_count):\n",
    "        if isinstance(input, tuple):\n",
    "                input = input[0]\n",
    "\n",
    "        #I don't know what this bit does, but I don't think it'll hurt anything\n",
    "        #Or maybe it does, who knows\n",
    "        input_shape = input.get_shape()\n",
    "        if input_shape.ndims == 4:\n",
    "            dim = 1\n",
    "            for d in input_shape[1:].as_list():\n",
    "                dim *= d\n",
    "        #    feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n",
    "        else:\n",
    "            feed_in, dim = (input, int(input_shape[-1]))\n",
    "\n",
    "        init_weights = tf.truncated_normal_initializer(0.0, stddev=0.1)#(0.0, stddev=0.01)\n",
    "        init_biases = tf.constant_initializer(1.0)#(0.1)\n",
    "\n",
    "        weights = weight_variable([dim, clust_count])\n",
    "        biases = bias_variable([clust_count])\n",
    "\n",
    "        acoll = tf.nn.xw_plus_b(input,weights,biases)\n",
    "        acolLayers.append(acol)\n",
    "    return acolLayers    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders (weights&biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    acol = initACOL(1024,clustCount,classCount)\n",
    "\n",
    "    #final fc layer\n",
    "    W_fc2 = weight_variable([1024, classCount])\n",
    "    b_fc2 = bias_variable([classCount])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    l_pool1 = max_pool_2x2(l_conv1)\n",
    "\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_pool1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_pool2, [-1, 7*7*64])\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, keep_prob)\n",
    "\n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([3,3,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([3,3,32,32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "\n",
    "    #conv_layer3\n",
    "    W_conv3 = weight_variable([3,3,32,64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "\n",
    "    #conv_layer4\n",
    "    W_conv4 = weight_variable([3,3,64,64])\n",
    "    b_conv4 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    acol = initACOL(2048,clustCount,classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_conv1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    l_drop1 = tf.nn.dropout(l_pool2, tf.constant(0.25))\n",
    "\n",
    "    #conv 3\n",
    "    l_conv3 = tf.nn.relu(conv2d(l_drop1, W_conv3) + b_conv3)\n",
    "    #conv 4\n",
    "    l_conv4 = tf.nn.relu(conv2d(l_conv3, W_conv4) + b_conv4)\n",
    "    l_pool4 = max_pool_2x2(l_conv4)\n",
    "\n",
    "    l_drop2 = tf.nn.dropout(l_pool4, tf.constant(0.25))\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_drop2, [-1, 7*7*64])\n",
    "\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(0.5))\n",
    "    \n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper loss funcs\n",
    "def zBar(x):\n",
    "    xshape = x.shape.as_list()\n",
    "    s=[-1,xshape[1]*xshape[2]]\n",
    "    return tf.maximum(tf.reshape(x,s),0)\n",
    "    \n",
    "def bigU(zb):\n",
    "    return tf.matmul(tf.transpose(zb),zb)\n",
    "\n",
    "def selectNonDiag(x):\n",
    "    selection = np.ones(x.shape.as_list()[0],dtype='float32') - np.eye(x.shape.as_list()[0],dtype='float32')\n",
    "    return tf.reduce_sum(tf.multiply(x,selection))\n",
    "\n",
    "def bigV(x):\n",
    "    smallNu=tf.reshape(tf.reduce_sum(x,axis=0),[1,-1])\n",
    "    return tf.multiply(tf.transpose(smallNu),smallNu)\n",
    "\n",
    "def specialNormalise(x):\n",
    "    top = selectNonDiag(x)\n",
    "    bottom = tf.multiply(tf.to_float(x.shape[1]-1),tf.reduce_sum(tf.multiply(x,np.eye(x.shape[1],dtype='float32'))))\n",
    "    return tf.divide(top,bottom)\n",
    "\n",
    "def frobNorm(x):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "\n",
    "tresh = tf.constant(0.06)\n",
    "cc0=1.0\n",
    "cc1=1.0\n",
    "cc2=1.0\n",
    "cc3=0.0003\n",
    "cc4=0.000001\n",
    "cc5=1.0\n",
    "c0 = tf.constant(cc0)\n",
    "c1 = tf.constant(cc1)\n",
    "c2 = tf.constant(cc2)\n",
    "c3val = tf.constant(cc3)\n",
    "c3 = lambda affinity: tf.cond(tf.less(affinity,tresh),lambda: c3val,lambda: tf.constant(0.0))\n",
    "c4 =tf.constant(cc4)\n",
    "c5 = tf.constant(cc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate losses\n",
    "#affinity\n",
    "bZ = zBar(stackedClusts)#softmaxMat)\n",
    "bU = bigU(bZ)\n",
    "coact = selectNonDiag(bU)\n",
    "affinity = specialNormalise(bU)\n",
    "\n",
    "#balance\n",
    "bV=bigV(bZ)\n",
    "balance = specialNormalise(bV)\n",
    "\n",
    "#cluster cross entropy (added if secondary label is set for that input, hard to do with batches?)\n",
    "clust_cross_entropy = tf.reduce_mean(-tf.reduce_sum(y2_ * tf.log(tf.clip_by_value(softmaxMat,1e-10,1.0)), reduction_indices=[1,2]))\n",
    "\n",
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))\n",
    "\n",
    "frob = frobNorm(stackedClusts)#softmaxMat)\n",
    "\n",
    "loss = c0*cross_entropy + c5*clust_cross_entropy + c1*affinity + c2*tf.subtract(tf.constant(1.0),balance) + c3(affinity)*coact + c4*frob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalSteps = trainsteps\n",
    "stepCount=0\n",
    "batchSize = 128\n",
    "hist = {\n",
    "    'train_acc':[],\n",
    "    'val_acc':[],\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'affinity':[],\n",
    "    'balance':[],\n",
    "    'coactivity':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "step 0/30000 \n",
      " Train: accuracy: 0.484375, loss: 15.0745 \n",
      " Validation: accuracy: 0.5625 loss: 14.8162\n",
      " cross_entropy: 2.30004, clust_cross_entropy: 12.5574, affinity: 0.347954, balance: 0.265068, coact: 169.664, frob: 0.00035574\n",
      "step 100/30000 \n",
      " Train: accuracy: 0.46875, loss: 11.4154 \n",
      " Validation: accuracy: 0.570312 loss: 11.1889\n",
      " cross_entropy: 2.10945, clust_cross_entropy: 8.99044, affinity: 0.347577, balance: 0.0256834, coact: 76.2929, frob: 0.000252106\n",
      "step 200/30000 \n",
      " Train: accuracy: 0.632812, loss: 8.19409 \n",
      " Validation: accuracy: 0.46875 loss: 9.17361\n",
      " cross_entropy: 1.79734, clust_cross_entropy: 6.62282, affinity: 0.334785, balance: 0.0227004, coact: 42.2253, frob: 0.000201774\n",
      "step 300/30000 \n",
      " Train: accuracy: 0.59375, loss: 7.03552 \n",
      " Validation: accuracy: 0.601562 loss: 6.74506\n",
      " cross_entropy: 1.21496, clust_cross_entropy: 5.7148, affinity: 0.325252, balance: 0.0151083, coact: 27.3538, frob: 0.000168797\n",
      "step 400/30000 \n",
      " Train: accuracy: 0.648438, loss: 5.58898 \n",
      " Validation: accuracy: 0.640625 loss: 5.84649\n",
      " cross_entropy: 1.30254, clust_cross_entropy: 4.68723, affinity: 0.301829, balance: 0.0240551, coact: 15.7423, frob: 0.000141901\n",
      "step 500/30000 \n",
      " Train: accuracy: 0.601562, loss: 5.03246 \n",
      " Validation: accuracy: 0.664062 loss: 5.02411\n",
      " cross_entropy: 1.20166, clust_cross_entropy: 3.23167, affinity: 0.281841, balance: 0.0140392, coact: 11.5308, frob: 0.000131881\n",
      "step 600/30000 \n",
      " Train: accuracy: 0.632812, loss: 4.67535 \n",
      " Validation: accuracy: 0.65625 loss: 4.79946\n",
      " cross_entropy: 1.13849, clust_cross_entropy: 3.25792, affinity: 0.253772, balance: 0.0143547, coact: 6.67869, frob: 0.000121955\n",
      "step 700/30000 \n",
      " Train: accuracy: 0.648438, loss: 4.76805 \n",
      " Validation: accuracy: 0.75 loss: 4.09948\n",
      " cross_entropy: 1.24022, clust_cross_entropy: 2.68184, affinity: 0.230236, balance: 0.0320361, coact: 6.45357, frob: 0.000122815\n",
      "step 800/30000 \n",
      " Train: accuracy: 0.726562, loss: 3.81825 \n",
      " Validation: accuracy: 0.6875 loss: 4.24622\n",
      " cross_entropy: 1.08326, clust_cross_entropy: 2.64274, affinity: 0.218942, balance: 0.0465409, coact: 5.4083, frob: 0.000120729\n",
      "step 900/30000 \n",
      " Train: accuracy: 0.804688, loss: 3.39525 \n",
      " Validation: accuracy: 0.75 loss: 3.53163\n",
      " cross_entropy: 0.915124, clust_cross_entropy: 2.25011, affinity: 0.209991, balance: 0.0322493, coact: 4.6048, frob: 0.000120533\n",
      "step 1000/30000 \n",
      " Train: accuracy: 0.765625, loss: 3.0622 \n",
      " Validation: accuracy: 0.75 loss: 3.21764\n",
      " cross_entropy: 1.02591, clust_cross_entropy: 1.78923, affinity: 0.182328, balance: 0.0247294, coact: 4.3053, frob: 0.000123398\n",
      "step 1100/30000 \n",
      " Train: accuracy: 0.742188, loss: 3.0844 \n",
      " Validation: accuracy: 0.882812 loss: 2.86107\n",
      " cross_entropy: 0.983135, clust_cross_entropy: 1.88347, affinity: 0.19592, balance: 0.0418079, coact: 4.47076, frob: 0.000119744\n",
      "step 1200/30000 \n",
      " Train: accuracy: 0.804688, loss: 2.68223 \n",
      " Validation: accuracy: 0.796875 loss: 3.11986\n",
      " cross_entropy: 0.900518, clust_cross_entropy: 1.51399, affinity: 0.187533, balance: 0.0298224, coact: 4.40356, frob: 0.000124818\n",
      "step 1300/30000 \n",
      " Train: accuracy: 0.835938, loss: 2.84316 \n",
      " Validation: accuracy: 0.789062 loss: 2.81664\n",
      " cross_entropy: 0.925668, clust_cross_entropy: 1.90044, affinity: 0.196125, balance: 0.0383393, coact: 4.72958, frob: 0.000124347\n",
      "step 1400/30000 \n",
      " Train: accuracy: 0.84375, loss: 2.66117 \n",
      " Validation: accuracy: 0.867188 loss: 2.63266\n",
      " cross_entropy: 0.82578, clust_cross_entropy: 1.64411, affinity: 0.169848, balance: 0.0136757, coact: 4.31097, frob: 0.000129421\n",
      "step 1500/30000 \n",
      " Train: accuracy: 0.820312, loss: 2.70013 \n",
      " Validation: accuracy: 0.867188 loss: 2.27228\n",
      " cross_entropy: 0.853995, clust_cross_entropy: 1.67578, affinity: 0.166489, balance: 0.0570679, coact: 4.84808, frob: 0.000131757\n",
      "step 1600/30000 \n",
      " Train: accuracy: 0.820312, loss: 2.4925 \n",
      " Validation: accuracy: 0.882812 loss: 2.17066\n",
      " cross_entropy: 0.765658, clust_cross_entropy: 1.58663, affinity: 0.168609, balance: 0.0202314, coact: 5.55972, frob: 0.00013094\n",
      "step 1700/30000 \n",
      " Train: accuracy: 0.835938, loss: 2.61102 \n",
      " Validation: accuracy: 0.882812 loss: 2.30673\n",
      " cross_entropy: 0.83383, clust_cross_entropy: 1.59168, affinity: 0.158678, balance: 0.0325701, coact: 3.88935, frob: 0.000135777\n",
      "step 1800/30000 \n",
      " Train: accuracy: 0.867188, loss: 2.09155 \n",
      " Validation: accuracy: 0.882812 loss: 2.19667\n",
      " cross_entropy: 0.613323, clust_cross_entropy: 1.28992, affinity: 0.163675, balance: 0.0383793, coact: 5.32992, frob: 0.000134783\n",
      "step 1900/30000 \n",
      " Train: accuracy: 0.882812, loss: 1.90448 \n",
      " Validation: accuracy: 0.890625 loss: 2.1968\n",
      " cross_entropy: 0.611652, clust_cross_entropy: 1.28018, affinity: 0.17215, balance: 0.0272152, coact: 4.05545, frob: 0.000139963\n",
      "step 2000/30000 \n",
      " Train: accuracy: 0.851562, loss: 2.10123 \n",
      " Validation: accuracy: 0.851562 loss: 2.49377\n",
      " cross_entropy: 0.576652, clust_cross_entropy: 1.11268, affinity: 0.14483, balance: 0.0386071, coact: 4.63676, frob: 0.000138049\n",
      "step 2100/30000 \n",
      " Train: accuracy: 0.875, loss: 2.0354 \n",
      " Validation: accuracy: 0.882812 loss: 1.92053\n",
      " cross_entropy: 0.590526, clust_cross_entropy: 1.04927, affinity: 0.1457, balance: 0.0164911, coact: 4.49851, frob: 0.000141714\n",
      "step 2200/30000 \n",
      " Train: accuracy: 0.898438, loss: 1.92365 \n",
      " Validation: accuracy: 0.90625 loss: 1.56559\n",
      " cross_entropy: 0.597952, clust_cross_entropy: 1.16912, affinity: 0.142659, balance: 0.0329751, coact: 4.26658, frob: 0.000143177\n",
      "step 2300/30000 \n",
      " Train: accuracy: 0.875, loss: 1.83658 \n",
      " Validation: accuracy: 0.90625 loss: 1.681\n",
      " cross_entropy: 0.641178, clust_cross_entropy: 1.21208, affinity: 0.143734, balance: 0.0412912, coact: 5.14103, frob: 0.000144319\n",
      "step 2400/30000 \n",
      " Train: accuracy: 0.859375, loss: 2.0344 \n",
      " Validation: accuracy: 0.875 loss: 1.76179\n",
      " cross_entropy: 0.558204, clust_cross_entropy: 1.11964, affinity: 0.14613, balance: 0.0394081, coact: 5.21047, frob: 0.000142686\n",
      "step 2500/30000 \n",
      " Train: accuracy: 0.882812, loss: 1.99309 \n",
      " Validation: accuracy: 0.890625 loss: 1.50667\n",
      " cross_entropy: 0.570511, clust_cross_entropy: 0.976614, affinity: 0.142814, balance: 0.0292404, coact: 5.81007, frob: 0.000149507\n",
      "step 2600/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.63707 \n",
      " Validation: accuracy: 0.914062 loss: 1.6692\n",
      " cross_entropy: 0.534332, clust_cross_entropy: 0.868987, affinity: 0.138292, balance: 0.0292243, coact: 5.39537, frob: 0.000151007\n",
      "step 2700/30000 \n",
      " Train: accuracy: 0.890625, loss: 1.76164 \n",
      " Validation: accuracy: 0.867188 loss: 1.90664\n",
      " cross_entropy: 0.508017, clust_cross_entropy: 0.876657, affinity: 0.139836, balance: 0.0568151, coact: 5.69175, frob: 0.000152446\n",
      "step 2800/30000 \n",
      " Train: accuracy: 0.859375, loss: 1.74964 \n",
      " Validation: accuracy: 0.898438 loss: 1.66587\n",
      " cross_entropy: 0.661023, clust_cross_entropy: 1.15216, affinity: 0.126351, balance: 0.0374845, coact: 5.25886, frob: 0.00015206\n",
      "step 2900/30000 \n",
      " Train: accuracy: 0.90625, loss: 1.64791 \n",
      " Validation: accuracy: 0.859375 loss: 1.81396\n",
      " cross_entropy: 0.569318, clust_cross_entropy: 1.05352, affinity: 0.116556, balance: 0.025641, coact: 4.94517, frob: 0.000156606\n",
      "step 3000/30000 \n",
      " Train: accuracy: 0.914062, loss: 1.59715 \n",
      " Validation: accuracy: 0.898438 loss: 1.87396\n",
      " cross_entropy: 0.451483, clust_cross_entropy: 0.910382, affinity: 0.126109, balance: 0.0144703, coact: 5.76155, frob: 0.000160625\n",
      "step 3100/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.4636 \n",
      " Validation: accuracy: 0.9375 loss: 1.45734\n",
      " cross_entropy: 0.522276, clust_cross_entropy: 0.776554, affinity: 0.132725, balance: 0.0317667, coact: 6.16543, frob: 0.000164225\n",
      "step 3200/30000 \n",
      " Train: accuracy: 0.890625, loss: 1.62449 \n",
      " Validation: accuracy: 0.914062 loss: 1.36469\n",
      " cross_entropy: 0.598105, clust_cross_entropy: 0.891378, affinity: 0.137912, balance: 0.0448576, coact: 5.36845, frob: 0.000158654\n",
      "step 3300/30000 \n",
      " Train: accuracy: 0.960938, loss: 1.61139 \n",
      " Validation: accuracy: 0.90625 loss: 1.55572\n",
      " cross_entropy: 0.513256, clust_cross_entropy: 1.00089, affinity: 0.1365, balance: 0.0229702, coact: 5.00754, frob: 0.000156527\n",
      "step 3400/30000 \n",
      " Train: accuracy: 0.90625, loss: 1.62623 \n",
      " Validation: accuracy: 0.898438 loss: 1.43356\n",
      " cross_entropy: 0.550653, clust_cross_entropy: 0.920594, affinity: 0.129263, balance: 0.0169269, coact: 5.63563, frob: 0.000162032\n",
      "step 3500/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.344 \n",
      " Validation: accuracy: 0.953125 loss: 1.42775\n",
      " cross_entropy: 0.365252, clust_cross_entropy: 0.673945, affinity: 0.121333, balance: 0.0347753, coact: 6.16763, frob: 0.000161512\n",
      "step 3600/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.56041 \n",
      " Validation: accuracy: 0.890625 loss: 1.47172\n",
      " cross_entropy: 0.392813, clust_cross_entropy: 0.793604, affinity: 0.126722, balance: 0.0183651, coact: 5.89353, frob: 0.0001632\n",
      "step 3700/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.50085 \n",
      " Validation: accuracy: 0.90625 loss: 1.33257\n",
      " cross_entropy: 0.429698, clust_cross_entropy: 0.897393, affinity: 0.131235, balance: 0.055346, coact: 6.13433, frob: 0.000160717\n",
      "step 3800/30000 \n",
      " Train: accuracy: 0.914062, loss: 1.68221 \n",
      " Validation: accuracy: 0.898438 loss: 1.69471\n",
      " cross_entropy: 0.415082, clust_cross_entropy: 1.01315, affinity: 0.124132, balance: 0.0406416, coact: 5.51483, frob: 0.000165959\n",
      "step 3900/30000 \n",
      " Train: accuracy: 0.90625, loss: 1.21663 \n",
      " Validation: accuracy: 0.914062 loss: 1.42015\n",
      " cross_entropy: 0.302123, clust_cross_entropy: 0.863623, affinity: 0.126209, balance: 0.0478955, coact: 6.05177, frob: 0.00017295\n",
      "step 4000/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.21901 \n",
      " Validation: accuracy: 0.914062 loss: 1.1086\n",
      " cross_entropy: 0.490142, clust_cross_entropy: 0.756479, affinity: 0.119846, balance: 0.0613666, coact: 5.37504, frob: 0.000166764\n",
      "step 4100/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.51626 \n",
      " Validation: accuracy: 0.90625 loss: 1.07887\n",
      " cross_entropy: 0.389606, clust_cross_entropy: 0.952665, affinity: 0.124394, balance: 0.0359603, coact: 6.68008, frob: 0.000170385\n",
      "step 4200/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.25639 \n",
      " Validation: accuracy: 0.9375 loss: 1.29996\n",
      " cross_entropy: 0.379351, clust_cross_entropy: 0.922767, affinity: 0.116625, balance: 0.0387021, coact: 6.00239, frob: 0.000175219\n",
      "step 4300/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.38412 \n",
      " Validation: accuracy: 0.945312 loss: 1.1147\n",
      " cross_entropy: 0.455633, clust_cross_entropy: 0.769884, affinity: 0.118269, balance: 0.0514714, coact: 5.99281, frob: 0.000171009\n",
      "step 4400/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.546 \n",
      " Validation: accuracy: 0.9375 loss: 1.36363\n",
      " cross_entropy: 0.360809, clust_cross_entropy: 0.823301, affinity: 0.11408, balance: 0.045113, coact: 6.28406, frob: 0.000172682\n",
      "step 4500/30000 \n",
      " Train: accuracy: 0.914062, loss: 1.32524 \n",
      " Validation: accuracy: 0.914062 loss: 1.18647\n",
      " cross_entropy: 0.447232, clust_cross_entropy: 0.809552, affinity: 0.118139, balance: 0.0559763, coact: 6.26495, frob: 0.000180641\n",
      "step 4600/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.04155 \n",
      " Validation: accuracy: 0.960938 loss: 1.43226\n",
      " cross_entropy: 0.330677, clust_cross_entropy: 0.704021, affinity: 0.11974, balance: 0.0565973, coact: 5.91976, frob: 0.00017643\n",
      "step 4700/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.29162 \n",
      " Validation: accuracy: 0.921875 loss: 1.09444\n",
      " cross_entropy: 0.385206, clust_cross_entropy: 0.764073, affinity: 0.118427, balance: 0.0448092, coact: 6.75983, frob: 0.000176806\n",
      "step 4800/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.40522 \n",
      " Validation: accuracy: 0.945312 loss: 0.96756\n",
      " cross_entropy: 0.405874, clust_cross_entropy: 0.916643, affinity: 0.111458, balance: 0.0495014, coact: 6.32442, frob: 0.000182411\n",
      "step 4900/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.987747 \n",
      " Validation: accuracy: 0.929688 loss: 1.07226\n",
      " cross_entropy: 0.306601, clust_cross_entropy: 0.560474, affinity: 0.109189, balance: 0.0548224, coact: 6.62254, frob: 0.00018012\n",
      "step 5000/30000 \n",
      " Train: accuracy: 0.945312, loss: 1.01995 \n",
      " Validation: accuracy: 0.953125 loss: 1.26717\n",
      " cross_entropy: 0.35, clust_cross_entropy: 0.677875, affinity: 0.108033, balance: 0.045462, coact: 5.89498, frob: 0.000189059\n",
      "step 5100/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.24906 \n",
      " Validation: accuracy: 0.953125 loss: 0.927084\n",
      " cross_entropy: 0.414239, clust_cross_entropy: 0.927794, affinity: 0.111649, balance: 0.0431125, coact: 6.59321, frob: 0.000189705\n",
      "step 5200/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.24402 \n",
      " Validation: accuracy: 0.929688 loss: 1.1126\n",
      " cross_entropy: 0.378722, clust_cross_entropy: 0.809913, affinity: 0.113718, balance: 0.0483109, coact: 6.46162, frob: 0.000178403\n",
      "step 5300/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.02104 \n",
      " Validation: accuracy: 0.960938 loss: 0.942954\n",
      " cross_entropy: 0.349476, clust_cross_entropy: 0.517887, affinity: 0.103635, balance: 0.0340062, coact: 6.43621, frob: 0.000182006\n",
      "step 5400/30000 \n",
      " Train: accuracy: 0.945312, loss: 1.0791 \n",
      " Validation: accuracy: 0.9375 loss: 1.08142\n",
      " cross_entropy: 0.328587, clust_cross_entropy: 0.670836, affinity: 0.103626, balance: 0.0564793, coact: 6.59623, frob: 0.000187342\n",
      "step 5500/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.971199 \n",
      " Validation: accuracy: 0.898438 loss: 1.06761\n",
      " cross_entropy: 0.265873, clust_cross_entropy: 0.646311, affinity: 0.114226, balance: 0.0346509, coact: 7.209, frob: 0.00019051\n",
      "step 5600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.759857 \n",
      " Validation: accuracy: 0.929688 loss: 1.12608\n",
      " cross_entropy: 0.34839, clust_cross_entropy: 0.493344, affinity: 0.103944, balance: 0.028313, coact: 6.18555, frob: 0.000192363\n",
      "step 5700/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.02858 \n",
      " Validation: accuracy: 0.945312 loss: 0.758327\n",
      " cross_entropy: 0.258909, clust_cross_entropy: 0.565094, affinity: 0.0983693, balance: 0.0384986, coact: 6.528, frob: 0.000185576\n",
      "step 5800/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.984341 \n",
      " Validation: accuracy: 0.945312 loss: 1.04802\n",
      " cross_entropy: 0.270133, clust_cross_entropy: 0.526288, affinity: 0.103135, balance: 0.0371619, coact: 6.5502, frob: 0.000188717\n",
      "step 5900/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.857782 \n",
      " Validation: accuracy: 0.953125 loss: 0.980548\n",
      " cross_entropy: 0.228731, clust_cross_entropy: 0.466535, affinity: 0.103292, balance: 0.0307612, coact: 7.15385, frob: 0.000195461\n",
      "step 6000/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.11678 \n",
      " Validation: accuracy: 0.945312 loss: 1.07237\n",
      " cross_entropy: 0.454175, clust_cross_entropy: 0.756445, affinity: 0.110952, balance: 0.0528351, coact: 7.04302, frob: 0.000188233\n",
      "step 6100/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.980956 \n",
      " Validation: accuracy: 0.96875 loss: 0.89483\n",
      " cross_entropy: 0.39087, clust_cross_entropy: 0.641327, affinity: 0.0956561, balance: 0.0625283, coact: 6.15779, frob: 0.000196249\n",
      "step 6200/30000 \n",
      " Train: accuracy: 0.96875, loss: 1.08139 \n",
      " Validation: accuracy: 0.945312 loss: 1.12302\n",
      " cross_entropy: 0.221135, clust_cross_entropy: 0.634302, affinity: 0.104131, balance: 0.0450599, coact: 5.78115, frob: 0.000193204\n",
      "step 6300/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.03663 \n",
      " Validation: accuracy: 0.960938 loss: 0.937321\n",
      " cross_entropy: 0.225051, clust_cross_entropy: 0.555345, affinity: 0.0967363, balance: 0.0324218, coact: 5.94652, frob: 0.000191609\n",
      "step 6400/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.06184 \n",
      " Validation: accuracy: 0.945312 loss: 1.15799\n",
      " cross_entropy: 0.354901, clust_cross_entropy: 0.587524, affinity: 0.0952192, balance: 0.0350929, coact: 6.18367, frob: 0.000199848\n",
      "step 6500/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.13663 \n",
      " Validation: accuracy: 0.9375 loss: 0.865926\n",
      " cross_entropy: 0.32808, clust_cross_entropy: 0.624169, affinity: 0.091707, balance: 0.0556768, coact: 6.49658, frob: 0.000196881\n",
      "step 6600/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.931199 \n",
      " Validation: accuracy: 0.96875 loss: 0.862065\n",
      " cross_entropy: 0.219377, clust_cross_entropy: 0.601673, affinity: 0.0991741, balance: 0.0437954, coact: 6.8831, frob: 0.000200859\n",
      "step 6700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.997144 \n",
      " Validation: accuracy: 0.9375 loss: 0.910026\n",
      " cross_entropy: 0.27756, clust_cross_entropy: 0.499791, affinity: 0.100378, balance: 0.0551426, coact: 6.6549, frob: 0.000201517\n",
      "step 6800/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.750547 \n",
      " Validation: accuracy: 0.9375 loss: 1.1651\n",
      " cross_entropy: 0.19774, clust_cross_entropy: 0.394712, affinity: 0.0918283, balance: 0.0771375, coact: 6.87971, frob: 0.000200676\n",
      "step 6900/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.790598 \n",
      " Validation: accuracy: 0.9375 loss: 1.06784\n",
      " cross_entropy: 0.236095, clust_cross_entropy: 0.482053, affinity: 0.094128, balance: 0.0400116, coact: 6.28976, frob: 0.000205791\n",
      "step 7000/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.821146 \n",
      " Validation: accuracy: 0.945312 loss: 0.837917\n",
      " cross_entropy: 0.234897, clust_cross_entropy: 0.522607, affinity: 0.0951701, balance: 0.0435393, coact: 5.92766, frob: 0.000196331\n",
      "step 7100/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.896161 \n",
      " Validation: accuracy: 0.976562 loss: 0.720215\n",
      " cross_entropy: 0.373584, clust_cross_entropy: 0.565935, affinity: 0.0958702, balance: 0.0515486, coact: 6.29034, frob: 0.00019744\n",
      "step 7200/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.11644 \n",
      " Validation: accuracy: 0.921875 loss: 1.0517\n",
      " cross_entropy: 0.341001, clust_cross_entropy: 0.635045, affinity: 0.109277, balance: 0.0664263, coact: 6.55475, frob: 0.000197272\n",
      "step 7300/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.719321 \n",
      " Validation: accuracy: 0.960938 loss: 0.888056\n",
      " cross_entropy: 0.262093, clust_cross_entropy: 0.469552, affinity: 0.0871505, balance: 0.0557177, coact: 6.963, frob: 0.000207192\n",
      "step 7400/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.878839 \n",
      " Validation: accuracy: 0.953125 loss: 0.772817\n",
      " cross_entropy: 0.251082, clust_cross_entropy: 0.563667, affinity: 0.0906106, balance: 0.0305362, coact: 5.79518, frob: 0.000207708\n",
      "step 7500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.981059 \n",
      " Validation: accuracy: 0.96875 loss: 0.836988\n",
      " cross_entropy: 0.21259, clust_cross_entropy: 0.60015, affinity: 0.0881549, balance: 0.0557916, coact: 6.81183, frob: 0.000209233\n",
      "step 7600/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.849723 \n",
      " Validation: accuracy: 0.96875 loss: 0.754398\n",
      " cross_entropy: 0.187761, clust_cross_entropy: 0.662897, affinity: 0.100059, balance: 0.0733213, coact: 6.42554, frob: 0.00020843\n",
      "step 7700/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.898168 \n",
      " Validation: accuracy: 0.929688 loss: 0.955892\n",
      " cross_entropy: 0.243611, clust_cross_entropy: 0.463572, affinity: 0.0810811, balance: 0.0728106, coact: 7.08574, frob: 0.000213112\n",
      "step 7800/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.775689 \n",
      " Validation: accuracy: 0.96875 loss: 0.732297\n",
      " cross_entropy: 0.207746, clust_cross_entropy: 0.507762, affinity: 0.0831702, balance: 0.0432495, coact: 6.92968, frob: 0.000218101\n",
      "step 7900/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.813603 \n",
      " Validation: accuracy: 0.953125 loss: 0.835121\n",
      " cross_entropy: 0.258831, clust_cross_entropy: 0.43443, affinity: 0.0909466, balance: 0.0693015, coact: 5.52071, frob: 0.000207424\n",
      "step 8000/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.887405 \n",
      " Validation: accuracy: 0.960938 loss: 0.906317\n",
      " cross_entropy: 0.257778, clust_cross_entropy: 0.409352, affinity: 0.093123, balance: 0.073222, coact: 5.9244, frob: 0.000201264\n",
      "step 8100/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.839453 \n",
      " Validation: accuracy: 0.960938 loss: 0.956912\n",
      " cross_entropy: 0.225251, clust_cross_entropy: 0.419562, affinity: 0.0908361, balance: 0.0600641, coact: 6.26713, frob: 0.000208749\n",
      "step 8200/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.73665 \n",
      " Validation: accuracy: 0.953125 loss: 0.988491\n",
      " cross_entropy: 0.161066, clust_cross_entropy: 0.326826, affinity: 0.093385, balance: 0.0790042, coact: 7.09859, frob: 0.000206927\n",
      "step 8300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.553168 \n",
      " Validation: accuracy: 0.960938 loss: 0.862572\n",
      " cross_entropy: 0.163712, clust_cross_entropy: 0.268546, affinity: 0.086019, balance: 0.0518954, coact: 7.98062, frob: 0.000216426\n",
      "step 8400/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.872958 \n",
      " Validation: accuracy: 0.945312 loss: 0.837839\n",
      " cross_entropy: 0.190307, clust_cross_entropy: 0.459928, affinity: 0.0929923, balance: 0.0524758, coact: 5.87884, frob: 0.000206582\n",
      "step 8500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.901785 \n",
      " Validation: accuracy: 0.976562 loss: 0.679433\n",
      " cross_entropy: 0.166604, clust_cross_entropy: 0.602259, affinity: 0.0914404, balance: 0.0428377, coact: 7.44853, frob: 0.000216861\n",
      "step 8600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.734654 \n",
      " Validation: accuracy: 0.960938 loss: 0.750245\n",
      " cross_entropy: 0.18376, clust_cross_entropy: 0.33483, affinity: 0.0850262, balance: 0.0686672, coact: 6.16513, frob: 0.00021475\n",
      "step 8700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.682855 \n",
      " Validation: accuracy: 0.953125 loss: 0.638456\n",
      " cross_entropy: 0.17142, clust_cross_entropy: 0.476904, affinity: 0.0889604, balance: 0.0415093, coact: 6.98385, frob: 0.000216754\n",
      "step 8800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.943848 \n",
      " Validation: accuracy: 0.96875 loss: 0.795383\n",
      " cross_entropy: 0.236192, clust_cross_entropy: 0.549752, affinity: 0.0860296, balance: 0.0361751, coact: 6.41318, frob: 0.000209878\n",
      "step 8900/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.887546 \n",
      " Validation: accuracy: 0.953125 loss: 0.630375\n",
      " cross_entropy: 0.240143, clust_cross_entropy: 0.328861, affinity: 0.0920671, balance: 0.0961155, coact: 7.18615, frob: 0.000220937\n",
      "step 9000/30000 \n",
      " Train: accuracy: 0.914062, loss: 1.11932 \n",
      " Validation: accuracy: 0.976562 loss: 0.5824\n",
      " cross_entropy: 0.206822, clust_cross_entropy: 0.594788, affinity: 0.0848994, balance: 0.0482234, coact: 7.25295, frob: 0.000216052\n",
      "step 9100/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.836834 \n",
      " Validation: accuracy: 0.953125 loss: 0.711029\n",
      " cross_entropy: 0.244792, clust_cross_entropy: 0.450368, affinity: 0.0867826, balance: 0.0763966, coact: 5.82658, frob: 0.000214857\n",
      "step 9200/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.608411 \n",
      " Validation: accuracy: 0.921875 loss: 0.854181\n",
      " cross_entropy: 0.152859, clust_cross_entropy: 0.284369, affinity: 0.0867956, balance: 0.0597625, coact: 6.2004, frob: 0.000229073\n",
      "step 9300/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.831757 \n",
      " Validation: accuracy: 0.992188 loss: 0.906692\n",
      " cross_entropy: 0.241746, clust_cross_entropy: 0.389214, affinity: 0.0719121, balance: 0.111589, coact: 6.17192, frob: 0.000221475\n",
      "step 9400/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.842834 \n",
      " Validation: accuracy: 0.96875 loss: 0.64365\n",
      " cross_entropy: 0.190599, clust_cross_entropy: 0.570565, affinity: 0.0811387, balance: 0.0599625, coact: 6.77642, frob: 0.000220256\n",
      "step 9500/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.865352 \n",
      " Validation: accuracy: 0.984375 loss: 0.731169\n",
      " cross_entropy: 0.214886, clust_cross_entropy: 0.449198, affinity: 0.0801548, balance: 0.0885, coact: 6.93877, frob: 0.000226941\n",
      "step 9600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.782712 \n",
      " Validation: accuracy: 0.953125 loss: 0.610625\n",
      " cross_entropy: 0.26583, clust_cross_entropy: 0.497202, affinity: 0.0826983, balance: 0.0407394, coact: 6.68054, frob: 0.000215265\n",
      "step 9700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.70071 \n",
      " Validation: accuracy: 0.984375 loss: 0.608722\n",
      " cross_entropy: 0.143393, clust_cross_entropy: 0.35445, affinity: 0.0735481, balance: 0.0623866, coact: 6.07142, frob: 0.000217963\n",
      "step 9800/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.827056 \n",
      " Validation: accuracy: 0.976562 loss: 0.611907\n",
      " cross_entropy: 0.190399, clust_cross_entropy: 0.326833, affinity: 0.0848429, balance: 0.0663571, coact: 6.72011, frob: 0.000222878\n",
      "step 9900/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.70264 \n",
      " Validation: accuracy: 0.945312 loss: 1.08297\n",
      " cross_entropy: 0.181833, clust_cross_entropy: 0.317647, affinity: 0.0762779, balance: 0.054595, coact: 5.83037, frob: 0.000221454\n",
      "step 10000/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.69677 \n",
      " Validation: accuracy: 0.945312 loss: 0.757214\n",
      " cross_entropy: 0.229252, clust_cross_entropy: 0.407241, affinity: 0.0776582, balance: 0.0811185, coact: 6.27661, frob: 0.000213841\n",
      "step 10100/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.740448 \n",
      " Validation: accuracy: 0.96875 loss: 0.681759\n",
      " cross_entropy: 0.189226, clust_cross_entropy: 0.373383, affinity: 0.0890015, balance: 0.0824494, coact: 6.5605, frob: 0.00022613\n",
      "step 10200/30000 \n",
      " Train: accuracy: 0.96875, loss: 1.07554 \n",
      " Validation: accuracy: 0.953125 loss: 0.836834\n",
      " cross_entropy: 0.245355, clust_cross_entropy: 0.664819, affinity: 0.0830612, balance: 0.0440051, coact: 6.95541, frob: 0.000218946\n",
      "step 10300/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.787662 \n",
      " Validation: accuracy: 0.96875 loss: 0.685241\n",
      " cross_entropy: 0.211348, clust_cross_entropy: 0.419971, affinity: 0.0829967, balance: 0.0525479, coact: 6.10249, frob: 0.000223737\n",
      "step 10400/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.776317 \n",
      " Validation: accuracy: 0.976562 loss: 0.819328\n",
      " cross_entropy: 0.269425, clust_cross_entropy: 0.398915, affinity: 0.0792632, balance: 0.0805761, coact: 6.76034, frob: 0.000224032\n",
      "step 10500/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.671631 \n",
      " Validation: accuracy: 0.976562 loss: 0.632195\n",
      " cross_entropy: 0.229076, clust_cross_entropy: 0.390982, affinity: 0.0780436, balance: 0.0675752, coact: 6.66234, frob: 0.000227955\n",
      "step 10600/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.593475 \n",
      " Validation: accuracy: 0.945312 loss: 0.957387\n",
      " cross_entropy: 0.181095, clust_cross_entropy: 0.333138, affinity: 0.0737858, balance: 0.0533525, coact: 6.0619, frob: 0.000218134\n",
      "step 10700/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.67709 \n",
      " Validation: accuracy: 0.96875 loss: 0.65634\n",
      " cross_entropy: 0.186547, clust_cross_entropy: 0.393672, affinity: 0.0847636, balance: 0.0358888, coact: 5.51772, frob: 0.000219137\n",
      "step 10800/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.55264 \n",
      " Validation: accuracy: 1 loss: 0.559438\n",
      " cross_entropy: 0.180564, clust_cross_entropy: 0.392326, affinity: 0.0824375, balance: 0.0252739, coact: 5.1282, frob: 0.000219709\n",
      "step 10900/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.586081 \n",
      " Validation: accuracy: 0.984375 loss: 0.691096\n",
      " cross_entropy: 0.161344, clust_cross_entropy: 0.367902, affinity: 0.0868581, balance: 0.0474567, coact: 6.66139, frob: 0.00022609\n",
      "step 11000/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.778962 \n",
      " Validation: accuracy: 0.984375 loss: 0.656854\n",
      " cross_entropy: 0.174542, clust_cross_entropy: 0.44217, affinity: 0.0738581, balance: 0.0458104, coact: 5.78898, frob: 0.000227903\n",
      "step 11100/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.746752 \n",
      " Validation: accuracy: 0.992188 loss: 0.477207\n",
      " cross_entropy: 0.167682, clust_cross_entropy: 0.291547, affinity: 0.0794139, balance: 0.038589, coact: 7.50828, frob: 0.000232642\n",
      "step 11200/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.917535 \n",
      " Validation: accuracy: 0.945312 loss: 0.78821\n",
      " cross_entropy: 0.199053, clust_cross_entropy: 0.391343, affinity: 0.0781658, balance: 0.0731024, coact: 6.41553, frob: 0.000231681\n",
      "step 11300/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.767425 \n",
      " Validation: accuracy: 0.96875 loss: 0.650088\n",
      " cross_entropy: 0.247427, clust_cross_entropy: 0.462396, affinity: 0.0809414, balance: 0.0614908, coact: 6.55861, frob: 0.00022034\n",
      "step 11400/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.446846 \n",
      " Validation: accuracy: 0.960938 loss: 0.849598\n",
      " cross_entropy: 0.0939447, clust_cross_entropy: 0.154129, affinity: 0.0781344, balance: 0.073285, coact: 6.72223, frob: 0.000230916\n",
      "step 11500/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.704043 \n",
      " Validation: accuracy: 0.96875 loss: 0.536497\n",
      " cross_entropy: 0.208833, clust_cross_entropy: 0.329636, affinity: 0.0787151, balance: 0.0474928, coact: 6.5857, frob: 0.000234436\n",
      "step 11600/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.892066 \n",
      " Validation: accuracy: 0.960938 loss: 0.832028\n",
      " cross_entropy: 0.162372, clust_cross_entropy: 0.448174, affinity: 0.0842604, balance: 0.142034, coact: 6.71165, frob: 0.000227487\n",
      "step 11700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.513105 \n",
      " Validation: accuracy: 0.96875 loss: 0.79474\n",
      " cross_entropy: 0.108782, clust_cross_entropy: 0.243879, affinity: 0.0733646, balance: 0.0280619, coact: 7.4445, frob: 0.000236097\n",
      "step 11800/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.746192 \n",
      " Validation: accuracy: 0.992188 loss: 0.550731\n",
      " cross_entropy: 0.259316, clust_cross_entropy: 0.497891, affinity: 0.0836529, balance: 0.0312179, coact: 5.87995, frob: 0.00023503\n",
      "step 11900/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.703804 \n",
      " Validation: accuracy: 0.976562 loss: 0.598869\n",
      " cross_entropy: 0.19455, clust_cross_entropy: 0.26671, affinity: 0.0740519, balance: 0.0769469, coact: 5.87114, frob: 0.000224792\n",
      "step 12000/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.751536 \n",
      " Validation: accuracy: 0.976562 loss: 0.583856\n",
      " cross_entropy: 0.167399, clust_cross_entropy: 0.411447, affinity: 0.0784049, balance: 0.0803491, coact: 6.70856, frob: 0.000231697\n",
      "step 12100/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.66943 \n",
      " Validation: accuracy: 0.953125 loss: 0.812611\n",
      " cross_entropy: 0.121571, clust_cross_entropy: 0.314922, affinity: 0.0714724, balance: 0.0619734, coact: 5.91771, frob: 0.00023283\n",
      "step 12200/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.415975 \n",
      " Validation: accuracy: 0.929688 loss: 0.816022\n",
      " cross_entropy: 0.137927, clust_cross_entropy: 0.251936, affinity: 0.0721, balance: 0.0393069, coact: 6.74183, frob: 0.000232875\n",
      "step 12300/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.50307 \n",
      " Validation: accuracy: 0.953125 loss: 0.769085\n",
      " cross_entropy: 0.174135, clust_cross_entropy: 0.244448, affinity: 0.0658898, balance: 0.0507509, coact: 5.47818, frob: 0.000235431\n",
      "step 12400/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.931429 \n",
      " Validation: accuracy: 0.960938 loss: 1.32396\n",
      " cross_entropy: 0.248308, clust_cross_entropy: 0.495499, affinity: 0.0143981, balance: 0.100011, coact: 0.149136, frob: 0.00033127\n",
      "step 12500/30000 \n",
      " Train: accuracy: 0.90625, loss: 1.28213 \n",
      " Validation: accuracy: 0.9375 loss: 1.13223\n",
      " cross_entropy: 0.392921, clust_cross_entropy: 0.739733, affinity: 0.0155056, balance: 0.112806, coact: 0.163513, frob: 0.00032909\n",
      "step 12600/30000 \n",
      " Train: accuracy: 0.921875, loss: 1.22815 \n",
      " Validation: accuracy: 0.914062 loss: 1.15494\n",
      " cross_entropy: 0.261092, clust_cross_entropy: 0.633297, affinity: 0.011194, balance: 0.0962875, coact: 0.179486, frob: 0.000338733\n",
      "step 12700/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.01494 \n",
      " Validation: accuracy: 0.984375 loss: 0.921461\n",
      " cross_entropy: 0.204681, clust_cross_entropy: 0.352324, affinity: 0.00946695, balance: 0.149074, coact: 0.150682, frob: 0.000322312\n",
      "step 12800/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.914582 \n",
      " Validation: accuracy: 0.945312 loss: 0.957924\n",
      " cross_entropy: 0.148543, clust_cross_entropy: 0.472863, affinity: 0.0121088, balance: 0.154766, coact: 0.171988, frob: 0.000331149\n",
      "step 12900/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.16126 \n",
      " Validation: accuracy: 0.96875 loss: 1.00195\n",
      " cross_entropy: 0.282503, clust_cross_entropy: 0.489443, affinity: 0.0116195, balance: 0.213398, coact: 0.176002, frob: 0.000342441\n",
      "step 13000/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.918641 \n",
      " Validation: accuracy: 0.96875 loss: 1.39093\n",
      " cross_entropy: 0.23688, clust_cross_entropy: 0.46196, affinity: 0.0100042, balance: 0.10693, coact: 0.154716, frob: 0.000343862\n",
      "step 13100/30000 \n",
      " Train: accuracy: 0.976562, loss: 1.11617 \n",
      " Validation: accuracy: 0.96875 loss: 1.13429\n",
      " cross_entropy: 0.216322, clust_cross_entropy: 0.415458, affinity: 0.00823669, balance: 0.17172, coact: 0.11282, frob: 0.000348736\n",
      "step 13200/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.03876 \n",
      " Validation: accuracy: 0.921875 loss: 1.04773\n",
      " cross_entropy: 0.273176, clust_cross_entropy: 0.490767, affinity: 0.00800891, balance: 0.137945, coact: 0.12776, frob: 0.000338437\n",
      "step 13300/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.979803 \n",
      " Validation: accuracy: 0.976562 loss: 0.837211\n",
      " cross_entropy: 0.260541, clust_cross_entropy: 0.411448, affinity: 0.00535986, balance: 0.227598, coact: 0.183253, frob: 0.000335886\n",
      "step 13400/30000 \n",
      " Train: accuracy: 0.945312, loss: 1.00836 \n",
      " Validation: accuracy: 0.96875 loss: 0.940246\n",
      " cross_entropy: 0.233215, clust_cross_entropy: 0.647097, affinity: 0.00711786, balance: 0.140861, coact: 0.171342, frob: 0.00034815\n",
      "step 13500/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.14286 \n",
      " Validation: accuracy: 0.96875 loss: 0.782232\n",
      " cross_entropy: 0.267138, clust_cross_entropy: 0.381891, affinity: 0.00691376, balance: 0.242823, coact: 0.107864, frob: 0.000349246\n",
      "step 13600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.852971 \n",
      " Validation: accuracy: 0.976562 loss: 0.865295\n",
      " cross_entropy: 0.197859, clust_cross_entropy: 0.481796, affinity: 0.00848848, balance: 0.186054, coact: 0.161672, frob: 0.000335048\n",
      "step 13700/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.10277 \n",
      " Validation: accuracy: 0.953125 loss: 1.15572\n",
      " cross_entropy: 0.221093, clust_cross_entropy: 0.45468, affinity: 0.00537701, balance: 0.205796, coact: 0.124759, frob: 0.000345651\n",
      "step 13800/30000 \n",
      " Train: accuracy: 0.953125, loss: 1.03875 \n",
      " Validation: accuracy: 0.953125 loss: 1.01902\n",
      " cross_entropy: 0.217805, clust_cross_entropy: 0.401566, affinity: 0.00865497, balance: 0.214142, coact: 0.16404, frob: 0.000344382\n",
      "step 13900/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.968796 \n",
      " Validation: accuracy: 0.96875 loss: 1.06583\n",
      " cross_entropy: 0.253914, clust_cross_entropy: 0.447868, affinity: 0.0102448, balance: 0.189649, coact: 0.155583, frob: 0.000350375\n",
      "step 14000/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.975794 \n",
      " Validation: accuracy: 0.945312 loss: 0.971622\n",
      " cross_entropy: 0.27536, clust_cross_entropy: 0.486544, affinity: 0.00497036, balance: 0.0711381, coact: 0.102963, frob: 0.000350642\n",
      "step 14100/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.71627 \n",
      " Validation: accuracy: 0.96875 loss: 0.942365\n",
      " cross_entropy: 0.221151, clust_cross_entropy: 0.437842, affinity: 0.00547169, balance: 0.0850933, coact: 0.0666864, frob: 0.000349093\n",
      "step 14200/30000 \n",
      " Train: accuracy: 1, loss: 0.660736 \n",
      " Validation: accuracy: 0.960938 loss: 0.953517\n",
      " cross_entropy: 0.158856, clust_cross_entropy: 0.279356, affinity: 0.00906339, balance: 0.165518, coact: 0.0857156, frob: 0.000351547\n",
      "step 14300/30000 \n",
      " Train: accuracy: 0.9375, loss: 1.02705 \n",
      " Validation: accuracy: 0.953125 loss: 0.708654\n",
      " cross_entropy: 0.190054, clust_cross_entropy: 0.461738, affinity: 0.00504051, balance: 0.0996829, coact: 0.128448, frob: 0.000343022\n",
      "step 14400/30000 \n",
      " Train: accuracy: 0.945312, loss: 1.1051 \n",
      " Validation: accuracy: 0.984375 loss: 0.685607\n",
      " cross_entropy: 0.198824, clust_cross_entropy: 0.402427, affinity: 0.00580819, balance: 0.218648, coact: 0.0962106, frob: 0.0003464\n",
      "step 14500/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.931752 \n",
      " Validation: accuracy: 0.984375 loss: 0.895814\n",
      " cross_entropy: 0.203081, clust_cross_entropy: 0.429376, affinity: 0.00579817, balance: 0.153938, coact: 0.137359, frob: 0.000352387\n",
      "step 14600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.873504 \n",
      " Validation: accuracy: 0.984375 loss: 0.737183\n",
      " cross_entropy: 0.214407, clust_cross_entropy: 0.516099, affinity: 0.00582698, balance: 0.111915, coact: 0.119801, frob: 0.000352693\n",
      "step 14700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.681894 \n",
      " Validation: accuracy: 0.984375 loss: 0.775597\n",
      " cross_entropy: 0.167317, clust_cross_entropy: 0.284325, affinity: 0.00673598, balance: 0.106214, coact: 0.148214, frob: 0.000347806\n",
      "step 14800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.931694 \n",
      " Validation: accuracy: 0.953125 loss: 0.934001\n",
      " cross_entropy: 0.178241, clust_cross_entropy: 0.410224, affinity: 0.00753596, balance: 0.176166, coact: 0.102465, frob: 0.000362346\n",
      "step 14900/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.974296 \n",
      " Validation: accuracy: 1 loss: 0.916177\n",
      " cross_entropy: 0.245934, clust_cross_entropy: 0.556758, affinity: 0.00743032, balance: 0.139423, coact: 0.0707506, frob: 0.000360309\n",
      "step 15000/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.991922 \n",
      " Validation: accuracy: 0.945312 loss: 0.877271\n",
      " cross_entropy: 0.304806, clust_cross_entropy: 0.492669, affinity: 0.00440117, balance: 0.160625, coact: 0.057293, frob: 0.000356551\n",
      "step 15100/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.02247 \n",
      " Validation: accuracy: 0.96875 loss: 0.990824\n",
      " cross_entropy: 0.266383, clust_cross_entropy: 0.434103, affinity: 0.00386554, balance: 0.158599, coact: 0.0901054, frob: 0.000360013\n",
      "step 15200/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.714804 \n",
      " Validation: accuracy: 0.976562 loss: 0.812785\n",
      " cross_entropy: 0.159477, clust_cross_entropy: 0.416893, affinity: 0.00864617, balance: 0.136102, coact: 0.126884, frob: 0.000362318\n",
      "step 15300/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.933313 \n",
      " Validation: accuracy: 0.960938 loss: 0.981943\n",
      " cross_entropy: 0.228552, clust_cross_entropy: 0.428499, affinity: 0.00567601, balance: 0.148053, coact: 0.0755624, frob: 0.000353168\n",
      "step 15400/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.919672 \n",
      " Validation: accuracy: 0.96875 loss: 0.831625\n",
      " cross_entropy: 0.211332, clust_cross_entropy: 0.365679, affinity: 0.003295, balance: 0.193074, coact: 0.0966051, frob: 0.000350803\n",
      "step 15500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.923142 \n",
      " Validation: accuracy: 0.953125 loss: 1.00499\n",
      " cross_entropy: 0.233808, clust_cross_entropy: 0.492768, affinity: 0.005947, balance: 0.145797, coact: 0.0917236, frob: 0.000361975\n",
      "step 15600/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.70392 \n",
      " Validation: accuracy: 0.945312 loss: 0.95053\n",
      " cross_entropy: 0.120879, clust_cross_entropy: 0.267482, affinity: 0.0072569, balance: 0.127343, coact: 0.16459, frob: 0.000359187\n",
      "step 15700/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.788204 \n",
      " Validation: accuracy: 0.984375 loss: 0.66828\n",
      " cross_entropy: 0.185576, clust_cross_entropy: 0.306579, affinity: 0.00485768, balance: 0.171021, coact: 0.049798, frob: 0.000362159\n",
      "step 15800/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.950276 \n",
      " Validation: accuracy: 0.953125 loss: 0.819807\n",
      " cross_entropy: 0.190256, clust_cross_entropy: 0.394835, affinity: 0.0048502, balance: 0.195394, coact: 0.0922376, frob: 0.00036486\n",
      "step 15900/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.943124 \n",
      " Validation: accuracy: 0.960938 loss: 1.06443\n",
      " cross_entropy: 0.189127, clust_cross_entropy: 0.388208, affinity: 0.00681752, balance: 0.18297, coact: 0.128577, frob: 0.000354174\n",
      "step 16000/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.766747 \n",
      " Validation: accuracy: 0.976562 loss: 0.790112\n",
      " cross_entropy: 0.131766, clust_cross_entropy: 0.29157, affinity: 0.00557004, balance: 0.155803, coact: 0.0686944, frob: 0.00036782\n",
      "step 16100/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.791971 \n",
      " Validation: accuracy: 0.992188 loss: 0.707123\n",
      " cross_entropy: 0.170851, clust_cross_entropy: 0.243058, affinity: 0.00562148, balance: 0.137844, coact: 0.0744128, frob: 0.00034927\n",
      "step 16200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.976745 \n",
      " Validation: accuracy: 0.984375 loss: 0.684069\n",
      " cross_entropy: 0.207638, clust_cross_entropy: 0.465248, affinity: 0.00757293, balance: 0.278477, coact: 0.09301, frob: 0.000372549\n",
      "step 16300/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.791722 \n",
      " Validation: accuracy: 0.953125 loss: 0.961811\n",
      " cross_entropy: 0.154155, clust_cross_entropy: 0.317491, affinity: 0.00586432, balance: 0.139842, coact: 0.0958855, frob: 0.0003757\n",
      "step 16400/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.712048 \n",
      " Validation: accuracy: 0.96875 loss: 0.826482\n",
      " cross_entropy: 0.144746, clust_cross_entropy: 0.255765, affinity: 0.00362259, balance: 0.138782, coact: 0.0986823, frob: 0.000370569\n",
      "step 16500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.927003 \n",
      " Validation: accuracy: 0.953125 loss: 0.914936\n",
      " cross_entropy: 0.214405, clust_cross_entropy: 0.43574, affinity: 0.00476125, balance: 0.181655, coact: 0.0575874, frob: 0.000372435\n",
      "step 16600/30000 \n",
      " Train: accuracy: 0.976562, loss: 1.00244 \n",
      " Validation: accuracy: 0.96875 loss: 0.914177\n",
      " cross_entropy: 0.249611, clust_cross_entropy: 0.439613, affinity: 0.00356074, balance: 0.191867, coact: 0.096112, frob: 0.00035841\n",
      "step 16700/30000 \n",
      " Train: accuracy: 0.90625, loss: 0.950492 \n",
      " Validation: accuracy: 0.953125 loss: 0.84265\n",
      " cross_entropy: 0.172769, clust_cross_entropy: 0.395661, affinity: 0.00321036, balance: 0.175237, coact: 0.0695379, frob: 0.000364836\n",
      "step 16800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.752037 \n",
      " Validation: accuracy: 0.976562 loss: 0.735187\n",
      " cross_entropy: 0.175479, clust_cross_entropy: 0.401596, affinity: 0.00513433, balance: 0.152746, coact: 0.0651405, frob: 0.000368796\n",
      "step 16900/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.753919 \n",
      " Validation: accuracy: 0.953125 loss: 0.976189\n",
      " cross_entropy: 0.1802, clust_cross_entropy: 0.290423, affinity: 0.00465862, balance: 0.219796, coact: 0.0620204, frob: 0.000366198\n",
      "step 17000/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.685539 \n",
      " Validation: accuracy: 0.992188 loss: 0.476456\n",
      " cross_entropy: 0.136037, clust_cross_entropy: 0.225912, affinity: 0.00616375, balance: 0.195277, coact: 0.0791191, frob: 0.000376089\n",
      "step 17100/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.706463 \n",
      " Validation: accuracy: 0.976562 loss: 0.905884\n",
      " cross_entropy: 0.156605, clust_cross_entropy: 0.254254, affinity: 0.00362408, balance: 0.147882, coact: 0.113819, frob: 0.000373069\n",
      "step 17200/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.816477 \n",
      " Validation: accuracy: 0.96875 loss: 0.73064\n",
      " cross_entropy: 0.1831, clust_cross_entropy: 0.363343, affinity: 0.00421692, balance: 0.191575, coact: 0.0697336, frob: 0.000377304\n",
      "step 17300/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.974983 \n",
      " Validation: accuracy: 0.960938 loss: 0.90129\n",
      " cross_entropy: 0.197797, clust_cross_entropy: 0.325709, affinity: 0.00372803, balance: 0.191242, coact: 0.135025, frob: 0.000377978\n",
      "step 17400/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.95809 \n",
      " Validation: accuracy: 0.945312 loss: 0.951848\n",
      " cross_entropy: 0.226911, clust_cross_entropy: 0.371904, affinity: 0.00283648, balance: 0.21963, coact: 0.0695754, frob: 0.000367207\n",
      "step 17500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.891007 \n",
      " Validation: accuracy: 0.953125 loss: 1.01979\n",
      " cross_entropy: 0.134418, clust_cross_entropy: 0.444277, affinity: 0.00441199, balance: 0.207375, coact: 0.0843914, frob: 0.000376837\n",
      "step 17600/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.811913 \n",
      " Validation: accuracy: 0.976562 loss: 0.648412\n",
      " cross_entropy: 0.128602, clust_cross_entropy: 0.347729, affinity: 0.00722689, balance: 0.138602, coact: 0.160464, frob: 0.000382693\n",
      "step 17700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.709992 \n",
      " Validation: accuracy: 0.976562 loss: 0.697119\n",
      " cross_entropy: 0.187859, clust_cross_entropy: 0.350049, affinity: 0.00325206, balance: 0.140064, coact: 0.10475, frob: 0.000383522\n",
      "step 17800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.809927 \n",
      " Validation: accuracy: 0.984375 loss: 0.760553\n",
      " cross_entropy: 0.146709, clust_cross_entropy: 0.235564, affinity: 0.00499511, balance: 0.17746, coact: 0.0836848, frob: 0.000379464\n",
      "step 17900/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.99594 \n",
      " Validation: accuracy: 0.960938 loss: 0.773176\n",
      " cross_entropy: 0.305392, clust_cross_entropy: 0.566973, affinity: 0.00577435, balance: 0.184728, coact: 0.0893531, frob: 0.000370964\n",
      "step 18000/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.528095 \n",
      " Validation: accuracy: 0.976562 loss: 0.616547\n",
      " cross_entropy: 0.172763, clust_cross_entropy: 0.253464, affinity: 0.00197669, balance: 0.152226, coact: 0.058218, frob: 0.000394652\n",
      "step 18100/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.620842 \n",
      " Validation: accuracy: 0.976562 loss: 0.759427\n",
      " cross_entropy: 0.175151, clust_cross_entropy: 0.369096, affinity: 0.00285981, balance: 0.131824, coact: 0.0567863, frob: 0.000373119\n",
      "step 18200/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.928035 \n",
      " Validation: accuracy: 0.976562 loss: 0.648683\n",
      " cross_entropy: 0.286166, clust_cross_entropy: 0.513647, affinity: 0.00331719, balance: 0.133791, coact: 0.105249, frob: 0.000379066\n",
      "step 18300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.624556 \n",
      " Validation: accuracy: 0.953125 loss: 0.850566\n",
      " cross_entropy: 0.110797, clust_cross_entropy: 0.325258, affinity: 0.0019205, balance: 0.199569, coact: 0.0816073, frob: 0.000378763\n",
      "step 18400/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.592306 \n",
      " Validation: accuracy: 0.96875 loss: 0.632594\n",
      " cross_entropy: 0.173432, clust_cross_entropy: 0.246514, affinity: 0.00509295, balance: 0.0962391, coact: 0.0561109, frob: 0.000377593\n",
      "step 18500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.754605 \n",
      " Validation: accuracy: 0.953125 loss: 0.729793\n",
      " cross_entropy: 0.14112, clust_cross_entropy: 0.227525, affinity: 0.00312301, balance: 0.107713, coact: 0.0620274, frob: 0.000391685\n",
      "step 18600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.773546 \n",
      " Validation: accuracy: 0.945312 loss: 0.745704\n",
      " cross_entropy: 0.213993, clust_cross_entropy: 0.467829, affinity: 0.00350391, balance: 0.125603, coact: 0.034063, frob: 0.000379693\n",
      "step 18700/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.792033 \n",
      " Validation: accuracy: 1 loss: 0.541113\n",
      " cross_entropy: 0.134453, clust_cross_entropy: 0.383477, affinity: 0.0028834, balance: 0.121296, coact: 0.0686081, frob: 0.000381827\n",
      "step 18800/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.691123 \n",
      " Validation: accuracy: 0.976562 loss: 0.849601\n",
      " cross_entropy: 0.177567, clust_cross_entropy: 0.425942, affinity: 0.00392273, balance: 0.170555, coact: 0.0525042, frob: 0.000378126\n",
      "step 18900/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.64663 \n",
      " Validation: accuracy: 0.953125 loss: 0.692492\n",
      " cross_entropy: 0.134447, clust_cross_entropy: 0.268904, affinity: 0.00461476, balance: 0.23392, coact: 0.0677841, frob: 0.000381093\n",
      "step 19000/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.623392 \n",
      " Validation: accuracy: 0.992188 loss: 0.663213\n",
      " cross_entropy: 0.128257, clust_cross_entropy: 0.387647, affinity: 0.00413206, balance: 0.243106, coact: 0.0540857, frob: 0.000393086\n",
      "step 19100/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.651396 \n",
      " Validation: accuracy: 0.976562 loss: 0.731878\n",
      " cross_entropy: 0.130462, clust_cross_entropy: 0.292421, affinity: 0.0040692, balance: 0.133223, coact: 0.0791774, frob: 0.000390364\n",
      "step 19200/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.765464 \n",
      " Validation: accuracy: 0.976562 loss: 0.727543\n",
      " cross_entropy: 0.225926, clust_cross_entropy: 0.452725, affinity: 0.00284154, balance: 0.125539, coact: 0.0410331, frob: 0.000377157\n",
      "step 19300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.662735 \n",
      " Validation: accuracy: 0.96875 loss: 0.586709\n",
      " cross_entropy: 0.167847, clust_cross_entropy: 0.333196, affinity: 0.00218493, balance: 0.136324, coact: 0.0506743, frob: 0.000380428\n",
      "step 19400/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.813399 \n",
      " Validation: accuracy: 0.984375 loss: 0.710945\n",
      " cross_entropy: 0.191881, clust_cross_entropy: 0.288235, affinity: 0.00489876, balance: 0.198693, coact: 0.0621211, frob: 0.00038867\n",
      "step 19500/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.772888 \n",
      " Validation: accuracy: 0.953125 loss: 0.833001\n",
      " cross_entropy: 0.123423, clust_cross_entropy: 0.395773, affinity: 0.00431761, balance: 0.150214, coact: 0.0524172, frob: 0.000384004\n",
      "step 19600/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.764563 \n",
      " Validation: accuracy: 0.976562 loss: 0.734152\n",
      " cross_entropy: 0.144857, clust_cross_entropy: 0.433635, affinity: 0.00543104, balance: 0.136172, coact: 0.0865014, frob: 0.00039179\n",
      "step 19700/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.731576 \n",
      " Validation: accuracy: 0.976562 loss: 0.803317\n",
      " cross_entropy: 0.134145, clust_cross_entropy: 0.358112, affinity: 0.00247631, balance: 0.156873, coact: 0.0749113, frob: 0.000383595\n",
      "step 19800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.744308 \n",
      " Validation: accuracy: 0.992188 loss: 0.550735\n",
      " cross_entropy: 0.169673, clust_cross_entropy: 0.262819, affinity: 0.0030237, balance: 0.190261, coact: 0.0737698, frob: 0.000395543\n",
      "step 19900/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.670973 \n",
      " Validation: accuracy: 0.976562 loss: 0.95269\n",
      " cross_entropy: 0.143606, clust_cross_entropy: 0.19688, affinity: 0.00328178, balance: 0.217635, coact: 0.036637, frob: 0.000385163\n",
      "step 20000/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.657427 \n",
      " Validation: accuracy: 0.976562 loss: 0.591935\n",
      " cross_entropy: 0.195097, clust_cross_entropy: 0.259872, affinity: 0.00284934, balance: 0.160223, coact: 0.0462935, frob: 0.000396326\n",
      "step 20100/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.673584 \n",
      " Validation: accuracy: 0.984375 loss: 0.705575\n",
      " cross_entropy: 0.125741, clust_cross_entropy: 0.318639, affinity: 0.00307484, balance: 0.161073, coact: 0.0542692, frob: 0.000397032\n",
      "step 20200/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.655639 \n",
      " Validation: accuracy: 0.992188 loss: 0.510274\n",
      " cross_entropy: 0.146939, clust_cross_entropy: 0.298146, affinity: 0.00305315, balance: 0.215165, coact: 0.0735984, frob: 0.000394694\n",
      "step 20300/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.461329 \n",
      " Validation: accuracy: 0.976562 loss: 0.639764\n",
      " cross_entropy: 0.111599, clust_cross_entropy: 0.312643, affinity: 0.0032341, balance: 0.165043, coact: 0.068512, frob: 0.000394563\n",
      "step 20400/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.646628 \n",
      " Validation: accuracy: 0.984375 loss: 0.756149\n",
      " cross_entropy: 0.106025, clust_cross_entropy: 0.284633, affinity: 0.00368438, balance: 0.243395, coact: 0.0328888, frob: 0.000390759\n",
      "step 20500/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.663465 \n",
      " Validation: accuracy: 0.96875 loss: 0.71834\n",
      " cross_entropy: 0.271655, clust_cross_entropy: 0.429985, affinity: 0.00272134, balance: 0.14184, coact: 0.0598086, frob: 0.000399342\n",
      "step 20600/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.760422 \n",
      " Validation: accuracy: 0.984375 loss: 0.634649\n",
      " cross_entropy: 0.164755, clust_cross_entropy: 0.303043, affinity: 0.00282386, balance: 0.199761, coact: 0.0438809, frob: 0.000385079\n",
      "step 20700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.705056 \n",
      " Validation: accuracy: 0.960938 loss: 0.570691\n",
      " cross_entropy: 0.143426, clust_cross_entropy: 0.249076, affinity: 0.00241927, balance: 0.164679, coact: 0.0539316, frob: 0.000398741\n",
      "step 20800/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.497841 \n",
      " Validation: accuracy: 0.96875 loss: 0.541491\n",
      " cross_entropy: 0.202199, clust_cross_entropy: 0.245964, affinity: 0.00500529, balance: 0.208919, coact: 0.055952, frob: 0.00039638\n",
      "step 20900/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.531297 \n",
      " Validation: accuracy: 0.960938 loss: 0.616751\n",
      " cross_entropy: 0.105118, clust_cross_entropy: 0.166601, affinity: 0.00113103, balance: 0.17109, coact: 0.0808113, frob: 0.00039269\n",
      "step 21000/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.574165 \n",
      " Validation: accuracy: 0.96875 loss: 0.743076\n",
      " cross_entropy: 0.098652, clust_cross_entropy: 0.203723, affinity: 0.00179277, balance: 0.275119, coact: 0.0768259, frob: 0.000404379\n",
      "step 21100/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.552757 \n",
      " Validation: accuracy: 0.984375 loss: 0.688603\n",
      " cross_entropy: 0.183795, clust_cross_entropy: 0.207871, affinity: 0.00217742, balance: 0.202942, coact: 0.0244855, frob: 0.00039114\n",
      "step 21200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.595724 \n",
      " Validation: accuracy: 0.992188 loss: 0.440559\n",
      " cross_entropy: 0.141868, clust_cross_entropy: 0.335681, affinity: 0.00237046, balance: 0.216102, coact: 0.103882, frob: 0.000402191\n",
      "step 21300/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.458372 \n",
      " Validation: accuracy: 0.953125 loss: 0.694753\n",
      " cross_entropy: 0.162433, clust_cross_entropy: 0.226497, affinity: 0.000596458, balance: 0.154818, coact: 0.0448261, frob: 0.000393376\n",
      "step 21400/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.844762 \n",
      " Validation: accuracy: 0.960938 loss: 0.835906\n",
      " cross_entropy: 0.155593, clust_cross_entropy: 0.364239, affinity: 0.00208027, balance: 0.231969, coact: 0.0473771, frob: 0.000404726\n",
      "step 21500/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.737832 \n",
      " Validation: accuracy: 0.984375 loss: 0.700647\n",
      " cross_entropy: 0.142167, clust_cross_entropy: 0.414204, affinity: 0.00258542, balance: 0.24124, coact: 0.0643191, frob: 0.000402408\n",
      "step 21600/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.727349 \n",
      " Validation: accuracy: 0.992188 loss: 0.65145\n",
      " cross_entropy: 0.165446, clust_cross_entropy: 0.221971, affinity: 0.00160823, balance: 0.279156, coact: 0.0403887, frob: 0.000411199\n",
      "step 21700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.607204 \n",
      " Validation: accuracy: 0.992188 loss: 0.455768\n",
      " cross_entropy: 0.138338, clust_cross_entropy: 0.224281, affinity: 0.00170211, balance: 0.161388, coact: 0.0130927, frob: 0.000407217\n",
      "step 21800/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.526723 \n",
      " Validation: accuracy: 0.992188 loss: 0.81232\n",
      " cross_entropy: 0.144293, clust_cross_entropy: 0.140909, affinity: 0.0013129, balance: 0.114455, coact: 0.0469907, frob: 0.000405735\n",
      "step 21900/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.559444 \n",
      " Validation: accuracy: 0.992188 loss: 0.471124\n",
      " cross_entropy: 0.172454, clust_cross_entropy: 0.240231, affinity: 0.00391094, balance: 0.0904619, coact: 0.0380916, frob: 0.000399108\n",
      "step 22000/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.508282 \n",
      " Validation: accuracy: 0.976562 loss: 0.6248\n",
      " cross_entropy: 0.069605, clust_cross_entropy: 0.210208, affinity: 0.00310465, balance: 0.140521, coact: 0.0527023, frob: 0.000406769\n",
      "step 22100/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.5118 \n",
      " Validation: accuracy: 0.992188 loss: 0.550294\n",
      " cross_entropy: 0.114251, clust_cross_entropy: 0.262521, affinity: 0.00279946, balance: 0.169489, coact: 0.0378188, frob: 0.00041614\n",
      "step 22200/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.727546 \n",
      " Validation: accuracy: 0.984375 loss: 0.708744\n",
      " cross_entropy: 0.110321, clust_cross_entropy: 0.304644, affinity: 0.00152154, balance: 0.117143, coact: 0.0279455, frob: 0.000412742\n",
      "step 22300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.730027 \n",
      " Validation: accuracy: 0.984375 loss: 0.770434\n",
      " cross_entropy: 0.168364, clust_cross_entropy: 0.238661, affinity: 0.00486637, balance: 0.133199, coact: 0.0681317, frob: 0.00040207\n",
      "step 22400/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.819752 \n",
      " Validation: accuracy: 0.992188 loss: 0.635823\n",
      " cross_entropy: 0.111619, clust_cross_entropy: 0.28755, affinity: 0.00361859, balance: 0.184495, coact: 0.0342042, frob: 0.000410765\n",
      "step 22500/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.683715 \n",
      " Validation: accuracy: 1 loss: 0.602649\n",
      " cross_entropy: 0.184191, clust_cross_entropy: 0.293437, affinity: 0.00259892, balance: 0.142021, coact: 0.0480994, frob: 0.000393679\n",
      "step 22600/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.786725 \n",
      " Validation: accuracy: 0.976562 loss: 0.532655\n",
      " cross_entropy: 0.157516, clust_cross_entropy: 0.283293, affinity: 0.00398222, balance: 0.143571, coact: 0.0701496, frob: 0.000392065\n",
      "step 22700/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.562421 \n",
      " Validation: accuracy: 0.992188 loss: 0.574792\n",
      " cross_entropy: 0.167022, clust_cross_entropy: 0.22406, affinity: 0.00161869, balance: 0.227698, coact: 0.0412416, frob: 0.000402635\n",
      "step 22800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.699301 \n",
      " Validation: accuracy: 0.992188 loss: 0.474297\n",
      " cross_entropy: 0.170544, clust_cross_entropy: 0.253257, affinity: 0.000941087, balance: 0.130119, coact: 0.0347501, frob: 0.000405163\n",
      "step 22900/30000 \n",
      " Train: accuracy: 1, loss: 0.54339 \n",
      " Validation: accuracy: 0.984375 loss: 0.477558\n",
      " cross_entropy: 0.0857221, clust_cross_entropy: 0.263796, affinity: 0.00158558, balance: 0.17483, coact: 0.0332365, frob: 0.00041422\n",
      "step 23000/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.685685 \n",
      " Validation: accuracy: 0.984375 loss: 0.674438\n",
      " cross_entropy: 0.161093, clust_cross_entropy: 0.214681, affinity: 0.00137331, balance: 0.237179, coact: 0.0515435, frob: 0.000407165\n",
      "step 23100/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.650932 \n",
      " Validation: accuracy: 0.953125 loss: 0.897268\n",
      " cross_entropy: 0.114274, clust_cross_entropy: 0.149508, affinity: 0.00246886, balance: 0.293315, coact: 0.0402342, frob: 0.000408813\n",
      "step 23200/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.787489 \n",
      " Validation: accuracy: 0.929688 loss: 0.737861\n",
      " cross_entropy: 0.161649, clust_cross_entropy: 0.283933, affinity: 0.0045907, balance: 0.20529, coact: 0.0358899, frob: 0.000412325\n",
      "step 23300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.574673 \n",
      " Validation: accuracy: 0.976562 loss: 0.82389\n",
      " cross_entropy: 0.156446, clust_cross_entropy: 0.255255, affinity: 0.00286628, balance: 0.201926, coact: 0.0688762, frob: 0.000407769\n",
      "step 23400/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.570254 \n",
      " Validation: accuracy: 0.992188 loss: 0.409659\n",
      " cross_entropy: 0.130136, clust_cross_entropy: 0.145851, affinity: 0.00252304, balance: 0.132114, coact: 0.0251434, frob: 0.000411173\n",
      "step 23500/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.737529 \n",
      " Validation: accuracy: 0.984375 loss: 0.643654\n",
      " cross_entropy: 0.146706, clust_cross_entropy: 0.361, affinity: 0.00394198, balance: 0.153873, coact: 0.0391663, frob: 0.000413547\n",
      "step 23600/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.58294 \n",
      " Validation: accuracy: 0.953125 loss: 0.77352\n",
      " cross_entropy: 0.136035, clust_cross_entropy: 0.335353, affinity: 0.00293495, balance: 0.176024, coact: 0.0527368, frob: 0.000408926\n",
      "step 23700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.517235 \n",
      " Validation: accuracy: 0.960938 loss: 0.769733\n",
      " cross_entropy: 0.150278, clust_cross_entropy: 0.242822, affinity: 0.0010405, balance: 0.0978106, coact: 0.00770916, frob: 0.000413236\n",
      "step 23800/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.658788 \n",
      " Validation: accuracy: 0.96875 loss: 0.523147\n",
      " cross_entropy: 0.0935446, clust_cross_entropy: 0.305457, affinity: 0.00186836, balance: 0.164097, coact: 0.00763605, frob: 0.000416996\n",
      "step 23900/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.58974 \n",
      " Validation: accuracy: 0.984375 loss: 0.577721\n",
      " cross_entropy: 0.0960758, clust_cross_entropy: 0.206749, affinity: 0.00151866, balance: 0.101404, coact: 0.0227553, frob: 0.000405621\n",
      "step 24000/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.6065 \n",
      " Validation: accuracy: 0.984375 loss: 0.601017\n",
      " cross_entropy: 0.12746, clust_cross_entropy: 0.339018, affinity: 0.00366221, balance: 0.169958, coact: 0.0582637, frob: 0.00040787\n",
      "step 24100/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.575692 \n",
      " Validation: accuracy: 0.984375 loss: 0.517718\n",
      " cross_entropy: 0.0898012, clust_cross_entropy: 0.206294, affinity: 0.00196122, balance: 0.246375, coact: 0.0668317, frob: 0.000424603\n",
      "step 24200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.443595 \n",
      " Validation: accuracy: 0.96875 loss: 0.611897\n",
      " cross_entropy: 0.133201, clust_cross_entropy: 0.180904, affinity: 0.000860102, balance: 0.146488, coact: 0.0276982, frob: 0.000421059\n",
      "step 24300/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.62941 \n",
      " Validation: accuracy: 0.984375 loss: 0.599162\n",
      " cross_entropy: 0.0994112, clust_cross_entropy: 0.257691, affinity: 0.00267045, balance: 0.116789, coact: 0.0440003, frob: 0.000411876\n",
      "step 24400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.466692 \n",
      " Validation: accuracy: 0.960938 loss: 0.691932\n",
      " cross_entropy: 0.113818, clust_cross_entropy: 0.178765, affinity: 0.00319277, balance: 0.190263, coact: 0.0465098, frob: 0.000411568\n",
      "step 24500/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.568385 \n",
      " Validation: accuracy: 0.976562 loss: 0.605826\n",
      " cross_entropy: 0.119127, clust_cross_entropy: 0.32162, affinity: 0.00310508, balance: 0.222748, coact: 0.0707181, frob: 0.000415321\n",
      "step 24600/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.476915 \n",
      " Validation: accuracy: 0.984375 loss: 0.613817\n",
      " cross_entropy: 0.1291, clust_cross_entropy: 0.142048, affinity: 0.00204421, balance: 0.179037, coact: 0.0301005, frob: 0.000409563\n",
      "step 24700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.649321 \n",
      " Validation: accuracy: 0.953125 loss: 0.655826\n",
      " cross_entropy: 0.124153, clust_cross_entropy: 0.284899, affinity: 0.00278429, balance: 0.141709, coact: 0.055437, frob: 0.00041684\n",
      "step 24800/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.558973 \n",
      " Validation: accuracy: 0.929688 loss: 0.74918\n",
      " cross_entropy: 0.185808, clust_cross_entropy: 0.297584, affinity: 0.00185605, balance: 0.199148, coact: 0.0389011, frob: 0.000417601\n",
      "step 24900/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.592283 \n",
      " Validation: accuracy: 0.984375 loss: 0.564595\n",
      " cross_entropy: 0.129323, clust_cross_entropy: 0.310349, affinity: 0.00308664, balance: 0.0897098, coact: 0.0488154, frob: 0.000428074\n",
      "step 25000/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.823129 \n",
      " Validation: accuracy: 0.992188 loss: 0.507446\n",
      " cross_entropy: 0.197279, clust_cross_entropy: 0.198888, affinity: 0.00130216, balance: 0.228539, coact: 0.0419384, frob: 0.000423057\n",
      "step 25100/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.633581 \n",
      " Validation: accuracy: 0.976562 loss: 0.542777\n",
      " cross_entropy: 0.150478, clust_cross_entropy: 0.227966, affinity: 0.00382126, balance: 0.108306, coact: 0.0544678, frob: 0.000430428\n",
      "step 25200/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.458885 \n",
      " Validation: accuracy: 0.976562 loss: 0.585543\n",
      " cross_entropy: 0.12732, clust_cross_entropy: 0.231058, affinity: 0.00203867, balance: 0.121669, coact: 0.0649373, frob: 0.00041083\n",
      "step 25300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.636439 \n",
      " Validation: accuracy: 1 loss: 0.514121\n",
      " cross_entropy: 0.121254, clust_cross_entropy: 0.341969, affinity: 0.00374693, balance: 0.105562, coact: 0.0645695, frob: 0.000426348\n",
      "step 25400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.501097 \n",
      " Validation: accuracy: 1 loss: 0.464656\n",
      " cross_entropy: 0.0894464, clust_cross_entropy: 0.183213, affinity: 0.0013024, balance: 0.139527, coact: 0.0546224, frob: 0.000429705\n",
      "step 25500/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.488014 \n",
      " Validation: accuracy: 0.992188 loss: 0.467286\n",
      " cross_entropy: 0.125711, clust_cross_entropy: 0.15112, affinity: 0.00258889, balance: 0.222616, coact: 0.0340595, frob: 0.000419438\n",
      "step 25600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.539743 \n",
      " Validation: accuracy: 0.960938 loss: 0.536858\n",
      " cross_entropy: 0.103791, clust_cross_entropy: 0.158867, affinity: 0.00442957, balance: 0.135497, coact: 0.0638835, frob: 0.000426959\n",
      "step 25700/30000 \n",
      " Train: accuracy: 1, loss: 0.466939 \n",
      " Validation: accuracy: 0.984375 loss: 0.505019\n",
      " cross_entropy: 0.135705, clust_cross_entropy: 0.261603, affinity: 0.00181638, balance: 0.188717, coact: 0.0221007, frob: 0.000418215\n",
      "step 25800/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.716878 \n",
      " Validation: accuracy: 0.984375 loss: 0.564007\n",
      " cross_entropy: 0.162176, clust_cross_entropy: 0.200247, affinity: 0.0045637, balance: 0.151691, coact: 0.0778846, frob: 0.000420766\n",
      "step 25900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.439384 \n",
      " Validation: accuracy: 0.976562 loss: 0.57043\n",
      " cross_entropy: 0.124648, clust_cross_entropy: 0.23444, affinity: 0.000725981, balance: 0.139681, coact: 0.0363019, frob: 0.000422566\n",
      "step 26000/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.600048 \n",
      " Validation: accuracy: 0.992188 loss: 0.431812\n",
      " cross_entropy: 0.0796142, clust_cross_entropy: 0.196986, affinity: 0.00194258, balance: 0.134486, coact: 0.0299115, frob: 0.000431104\n",
      "step 26100/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.539995 \n",
      " Validation: accuracy: 0.9375 loss: 0.557439\n",
      " cross_entropy: 0.107984, clust_cross_entropy: 0.191398, affinity: 0.00150963, balance: 0.138679, coact: 0.0567891, frob: 0.000421106\n",
      "step 26200/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.511658 \n",
      " Validation: accuracy: 0.984375 loss: 0.6008\n",
      " cross_entropy: 0.152449, clust_cross_entropy: 0.125659, affinity: 0.00174569, balance: 0.259489, coact: 0.0293469, frob: 0.000423217\n",
      "step 26300/30000 \n",
      " Train: accuracy: 1, loss: 0.409273 \n",
      " Validation: accuracy: 0.953125 loss: 0.647378\n",
      " cross_entropy: 0.095255, clust_cross_entropy: 0.134634, affinity: 0.00139031, balance: 0.141869, coact: 0.0458317, frob: 0.000427237\n",
      "step 26400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.467331 \n",
      " Validation: accuracy: 0.96875 loss: 0.611443\n",
      " cross_entropy: 0.0758974, clust_cross_entropy: 0.135363, affinity: 0.000788841, balance: 0.214824, coact: 0.0296128, frob: 0.000410718\n",
      "step 26500/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.487211 \n",
      " Validation: accuracy: 0.984375 loss: 0.603618\n",
      " cross_entropy: 0.0713321, clust_cross_entropy: 0.153663, affinity: 0.00197401, balance: 0.164084, coact: 0.0264519, frob: 0.000419443\n",
      "step 26600/30000 \n",
      " Train: accuracy: 1, loss: 0.475631 \n",
      " Validation: accuracy: 0.976562 loss: 0.439534\n",
      " cross_entropy: 0.122884, clust_cross_entropy: 0.254811, affinity: 0.00112414, balance: 0.205869, coact: 0.0388961, frob: 0.000434872\n",
      "step 26700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.486403 \n",
      " Validation: accuracy: 0.992188 loss: 0.644985\n",
      " cross_entropy: 0.108357, clust_cross_entropy: 0.155844, affinity: 0.00226237, balance: 0.146698, coact: 0.0285982, frob: 0.000436005\n",
      "step 26800/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.433609 \n",
      " Validation: accuracy: 0.976562 loss: 0.602786\n",
      " cross_entropy: 0.0688467, clust_cross_entropy: 0.100813, affinity: 0.00197359, balance: 0.111914, coact: 0.0547808, frob: 0.000437398\n",
      "step 26900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.611019 \n",
      " Validation: accuracy: 0.96875 loss: 0.666672\n",
      " cross_entropy: 0.0769687, clust_cross_entropy: 0.277654, affinity: 0.00144319, balance: 0.191301, coact: 0.0719722, frob: 0.000430389\n",
      "step 27000/30000 \n",
      " Train: accuracy: 1, loss: 0.571639 \n",
      " Validation: accuracy: 0.984375 loss: 0.452248\n",
      " cross_entropy: 0.0957718, clust_cross_entropy: 0.251694, affinity: 0.0008659, balance: 0.123714, coact: 0.0347342, frob: 0.000441271\n",
      "step 27100/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.380684 \n",
      " Validation: accuracy: 0.976562 loss: 0.50333\n",
      " cross_entropy: 0.113656, clust_cross_entropy: 0.220119, affinity: 0.00177242, balance: 0.193518, coact: 0.0438272, frob: 0.000428622\n",
      "step 27200/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.78303 \n",
      " Validation: accuracy: 0.96875 loss: 0.52877\n",
      " cross_entropy: 0.109253, clust_cross_entropy: 0.325162, affinity: 0.00183619, balance: 0.242212, coact: 0.018504, frob: 0.000424865\n",
      "step 27300/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.495425 \n",
      " Validation: accuracy: 0.976562 loss: 0.610332\n",
      " cross_entropy: 0.0846369, clust_cross_entropy: 0.138676, affinity: 0.00133577, balance: 0.22438, coact: 0.033726, frob: 0.000429885\n",
      "step 27400/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.645102 \n",
      " Validation: accuracy: 0.992188 loss: 0.606252\n",
      " cross_entropy: 0.169336, clust_cross_entropy: 0.231861, affinity: 0.00143342, balance: 0.254139, coact: 0.0198374, frob: 0.000427801\n",
      "step 27500/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.625869 \n",
      " Validation: accuracy: 0.976562 loss: 0.536121\n",
      " cross_entropy: 0.113442, clust_cross_entropy: 0.249893, affinity: 0.00221966, balance: 0.27531, coact: 0.0219015, frob: 0.000420943\n",
      "step 27600/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.534757 \n",
      " Validation: accuracy: 0.992188 loss: 0.410663\n",
      " cross_entropy: 0.138637, clust_cross_entropy: 0.275186, affinity: 0.0020793, balance: 0.15989, coact: 0.0185955, frob: 0.000428864\n",
      "step 27700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.669273 \n",
      " Validation: accuracy: 0.984375 loss: 0.801758\n",
      " cross_entropy: 0.0947574, clust_cross_entropy: 0.235184, affinity: 0.00185698, balance: 0.234424, coact: 0.0316654, frob: 0.000430531\n",
      "step 27800/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.443289 \n",
      " Validation: accuracy: 0.984375 loss: 0.504961\n",
      " cross_entropy: 0.134685, clust_cross_entropy: 0.158782, affinity: 0.00145921, balance: 0.130052, coact: 0.0244232, frob: 0.000430131\n",
      "step 27900/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.71314 \n",
      " Validation: accuracy: 0.953125 loss: 0.85201\n",
      " cross_entropy: 0.149763, clust_cross_entropy: 0.340584, affinity: 0.00233408, balance: 0.163312, coact: 0.0423652, frob: 0.000432956\n",
      "step 28000/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.555257 \n",
      " Validation: accuracy: 0.984375 loss: 0.430795\n",
      " cross_entropy: 0.110436, clust_cross_entropy: 0.199351, affinity: 0.00159268, balance: 0.149576, coact: 0.0443647, frob: 0.000433547\n",
      "step 28100/30000 \n",
      " Train: accuracy: 0.953125, loss: 0.678261 \n",
      " Validation: accuracy: 0.960938 loss: 0.585094\n",
      " cross_entropy: 0.104891, clust_cross_entropy: 0.32407, affinity: 0.00105286, balance: 0.16695, coact: 0.0426534, frob: 0.000438548\n",
      "step 28200/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.587807 \n",
      " Validation: accuracy: 0.96875 loss: 0.745907\n",
      " cross_entropy: 0.156746, clust_cross_entropy: 0.18602, affinity: 0.000922184, balance: 0.239995, coact: 0.0438553, frob: 0.000448583\n",
      "step 28300/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.602252 \n",
      " Validation: accuracy: 0.984375 loss: 0.526188\n",
      " cross_entropy: 0.103479, clust_cross_entropy: 0.265566, affinity: 0.00214205, balance: 0.175805, coact: 0.0439956, frob: 0.00043128\n",
      "step 28400/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.460069 \n",
      " Validation: accuracy: 0.984375 loss: 0.49295\n",
      " cross_entropy: 0.115928, clust_cross_entropy: 0.270406, affinity: 0.00157444, balance: 0.120475, coact: 0.0712785, frob: 0.000441026\n",
      "step 28500/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.382669 \n",
      " Validation: accuracy: 0.96875 loss: 0.641542\n",
      " cross_entropy: 0.0868303, clust_cross_entropy: 0.1605, affinity: 0.00136141, balance: 0.162213, coact: 0.018645, frob: 0.000446288\n",
      "step 28600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.408549 \n",
      " Validation: accuracy: 0.976562 loss: 0.856077\n",
      " cross_entropy: 0.0438605, clust_cross_entropy: 0.176107, affinity: 0.00107908, balance: 0.221239, coact: 0.0132339, frob: 0.000445676\n",
      "step 28700/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.458203 \n",
      " Validation: accuracy: 0.992188 loss: 0.591366\n",
      " cross_entropy: 0.119146, clust_cross_entropy: 0.207932, affinity: 0.00123704, balance: 0.204298, coact: 0.0170741, frob: 0.000441419\n",
      "step 28800/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.441113 \n",
      " Validation: accuracy: 0.96875 loss: 0.523231\n",
      " cross_entropy: 0.0961466, clust_cross_entropy: 0.170873, affinity: 0.00106337, balance: 0.0901471, coact: 0.0299333, frob: 0.000449681\n",
      "step 28900/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.530365 \n",
      " Validation: accuracy: 0.96875 loss: 0.533404\n",
      " cross_entropy: 0.0959058, clust_cross_entropy: 0.181684, affinity: 0.0014759, balance: 0.177965, coact: 0.0272902, frob: 0.000445582\n",
      "step 29000/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.677925 \n",
      " Validation: accuracy: 1 loss: 0.485631\n",
      " cross_entropy: 0.124928, clust_cross_entropy: 0.30211, affinity: 0.00131117, balance: 0.172264, coact: 0.0133104, frob: 0.00044254\n",
      "step 29100/30000 \n",
      " Train: accuracy: 1, loss: 0.520942 \n",
      " Validation: accuracy: 0.992188 loss: 0.373719\n",
      " cross_entropy: 0.0781764, clust_cross_entropy: 0.167756, affinity: 0.00187957, balance: 0.16735, coact: 0.0206165, frob: 0.000433725\n",
      "step 29200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.410222 \n",
      " Validation: accuracy: 0.976562 loss: 0.529976\n",
      " cross_entropy: 0.093478, clust_cross_entropy: 0.1361, affinity: 0.00144049, balance: 0.161204, coact: 0.0379716, frob: 0.000453809\n",
      "step 29300/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.615776 \n",
      " Validation: accuracy: 0.960938 loss: 0.901951\n",
      " cross_entropy: 0.129905, clust_cross_entropy: 0.138652, affinity: 0.00126467, balance: 0.188428, coact: 0.00576487, frob: 0.000439669\n",
      "step 29400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.56922 \n",
      " Validation: accuracy: 0.992188 loss: 0.407658\n",
      " cross_entropy: 0.0887753, clust_cross_entropy: 0.192444, affinity: 0.00121595, balance: 0.188302, coact: 0.0292524, frob: 0.000457135\n",
      "step 29500/30000 \n",
      " Train: accuracy: 1, loss: 0.558195 \n",
      " Validation: accuracy: 1 loss: 0.461087\n",
      " cross_entropy: 0.107219, clust_cross_entropy: 0.306394, affinity: 0.00281205, balance: 0.148056, coact: 0.0459436, frob: 0.000450945\n",
      "step 29600/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.63045 \n",
      " Validation: accuracy: 0.992188 loss: 0.631053\n",
      " cross_entropy: 0.0757487, clust_cross_entropy: 0.19959, affinity: 0.00136542, balance: 0.214341, coact: 0.021061, frob: 0.000445458\n",
      "step 29700/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.434469 \n",
      " Validation: accuracy: 0.984375 loss: 0.524834\n",
      " cross_entropy: 0.140021, clust_cross_entropy: 0.199341, affinity: 0.00207899, balance: 0.114836, coact: 0.0631227, frob: 0.000444026\n",
      "step 29800/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.353785 \n",
      " Validation: accuracy: 0.992188 loss: 0.458664\n",
      " cross_entropy: 0.133704, clust_cross_entropy: 0.15442, affinity: 0.00197873, balance: 0.138938, coact: 0.0321167, frob: 0.000453658\n",
      "step 29900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.495443 \n",
      " Validation: accuracy: 0.992188 loss: 0.384224\n",
      " cross_entropy: 0.0651695, clust_cross_entropy: 0.17557, affinity: 0.000583906, balance: 0.163586, coact: 0.0475191, frob: 0.00046007\n"
     ]
    }
   ],
   "source": [
    "#STEP 1\n",
    "#def next_batch(batch_size, shuffle, images, labels, ep_compl, ep_ind):\n",
    "\n",
    "convy2 = y2\n",
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images_labelled_only, train_labels_labelled_only,_epochs_completed_train,_index_in_epoch_train)\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2], keep_prob:0.3})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, affinity: %g, balance: %g, coact: %g, frob: %g\"%(cc0*entr, cc5*entr2 ,cc1*hist['affinity'][-1],cc2*(1-hist['balance'][-1]),cc3*hist['coactivity'][-1],cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "step 0/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.52273 \n",
      " Validation: accuracy: 0.953125 loss: 0.603315\n",
      " cross_entropy: 0.14733, clust_cross_entropy: 1.22516, affinity: 0.00149108, balance: 0.16553, coact: 0.0279039, frob: 0.000470165\n",
      "step 100/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.21672 \n",
      " Validation: accuracy: 0.9375 loss: 0.772629\n",
      " cross_entropy: 0.200056, clust_cross_entropy: 0.845429, affinity: 0.00224415, balance: 0.12569, coact: 0.024084, frob: 0.000345271\n",
      "step 200/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.31878 \n",
      " Validation: accuracy: 0.96875 loss: 0.685893\n",
      " cross_entropy: 0.334766, clust_cross_entropy: 0.807615, affinity: 0.00280951, balance: 0.208274, coact: 0.0190577, frob: 0.000278624\n",
      "step 300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.921542 \n",
      " Validation: accuracy: 0.960938 loss: 0.870024\n",
      " cross_entropy: 0.225489, clust_cross_entropy: 0.530998, affinity: 0.00299347, balance: 0.0991979, coact: 0.0334937, frob: 0.000260222\n",
      "step 400/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.34311 \n",
      " Validation: accuracy: 0.976562 loss: 0.670682\n",
      " cross_entropy: 0.245656, clust_cross_entropy: 0.86725, affinity: 0.00406041, balance: 0.178243, coact: 0.032272, frob: 0.000257573\n",
      "step 500/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.13488 \n",
      " Validation: accuracy: 0.960938 loss: 0.876788\n",
      " cross_entropy: 0.304993, clust_cross_entropy: 0.518047, affinity: 0.00295046, balance: 0.169462, coact: 0.0202666, frob: 0.000251861\n",
      "step 600/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.05698 \n",
      " Validation: accuracy: 0.984375 loss: 0.798562\n",
      " cross_entropy: 0.331345, clust_cross_entropy: 0.510197, affinity: 0.00328748, balance: 0.153941, coact: 0.0280088, frob: 0.000246098\n",
      "step 700/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.07885 \n",
      " Validation: accuracy: 0.992188 loss: 0.727511\n",
      " cross_entropy: 0.332226, clust_cross_entropy: 0.513596, affinity: 0.00544817, balance: 0.150275, coact: 0.0374539, frob: 0.000246802\n",
      "step 800/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.1908 \n",
      " Validation: accuracy: 0.992188 loss: 0.857226\n",
      " cross_entropy: 0.279998, clust_cross_entropy: 0.71083, affinity: 0.00306185, balance: 0.138542, coact: 0.0408759, frob: 0.000239262\n",
      "step 900/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.20378 \n",
      " Validation: accuracy: 0.976562 loss: 0.806454\n",
      " cross_entropy: 0.298603, clust_cross_entropy: 0.721938, affinity: 0.0047509, balance: 0.167265, coact: 0.0395246, frob: 0.000232443\n",
      "step 1000/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.99941 \n",
      " Validation: accuracy: 0.976562 loss: 0.801313\n",
      " cross_entropy: 0.262718, clust_cross_entropy: 0.614491, affinity: 0.00325973, balance: 0.209863, coact: 0.0417657, frob: 0.0002467\n",
      "step 1100/20000 \n",
      " Train: accuracy: 1, loss: 0.87108 \n",
      " Validation: accuracy: 0.960938 loss: 0.71698\n",
      " cross_entropy: 0.293947, clust_cross_entropy: 0.464459, affinity: 0.00345082, balance: 0.152112, coact: 0.0165144, frob: 0.000239996\n",
      "step 1200/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.25978 \n",
      " Validation: accuracy: 1 loss: 0.862981\n",
      " cross_entropy: 0.29394, clust_cross_entropy: 0.740812, affinity: 0.00622951, balance: 0.114812, coact: 0.0380232, frob: 0.000243273\n",
      "step 1300/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.22332 \n",
      " Validation: accuracy: 0.984375 loss: 0.770345\n",
      " cross_entropy: 0.260593, clust_cross_entropy: 0.636861, affinity: 0.00645797, balance: 0.171221, coact: 0.0507186, frob: 0.000246443\n",
      "step 1400/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.842134 \n",
      " Validation: accuracy: 0.976562 loss: 0.849082\n",
      " cross_entropy: 0.260684, clust_cross_entropy: 0.469959, affinity: 0.00201369, balance: 0.210407, coact: 0.0388705, frob: 0.000250937\n",
      "step 1500/20000 \n",
      " Train: accuracy: 1, loss: 0.86664 \n",
      " Validation: accuracy: 0.976562 loss: 0.847186\n",
      " cross_entropy: 0.290042, clust_cross_entropy: 0.395176, affinity: 0.00417241, balance: 0.114199, coact: 0.0361623, frob: 0.000240376\n",
      "step 1600/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.24818 \n",
      " Validation: accuracy: 0.953125 loss: 0.935413\n",
      " cross_entropy: 0.304358, clust_cross_entropy: 0.711843, affinity: 0.00350033, balance: 0.127633, coact: 0.018876, frob: 0.000248082\n",
      "step 1700/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.999801 \n",
      " Validation: accuracy: 0.984375 loss: 0.804156\n",
      " cross_entropy: 0.311463, clust_cross_entropy: 0.488036, affinity: 0.00323858, balance: 0.151435, coact: 0.0370538, frob: 0.000241776\n",
      "step 1800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.978739 \n",
      " Validation: accuracy: 0.96875 loss: 0.827128\n",
      " cross_entropy: 0.30171, clust_cross_entropy: 0.523929, affinity: 0.00379307, balance: 0.174995, coact: 0.0416782, frob: 0.00024397\n",
      "step 1900/20000 \n",
      " Train: accuracy: 1, loss: 0.996289 \n",
      " Validation: accuracy: 0.984375 loss: 0.883662\n",
      " cross_entropy: 0.21612, clust_cross_entropy: 0.492144, affinity: 0.00367676, balance: 0.182912, coact: 0.0252124, frob: 0.000242218\n",
      "step 2000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.982452 \n",
      " Validation: accuracy: 0.984375 loss: 0.765658\n",
      " cross_entropy: 0.384734, clust_cross_entropy: 0.557564, affinity: 0.00534646, balance: 0.171632, coact: 0.0291792, frob: 0.000244619\n",
      "step 2100/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.00018 \n",
      " Validation: accuracy: 0.976562 loss: 0.973991\n",
      " cross_entropy: 0.313481, clust_cross_entropy: 0.616816, affinity: 0.00423873, balance: 0.148588, coact: 0.00975753, frob: 0.00024338\n",
      "step 2200/20000 \n",
      " Train: accuracy: 1, loss: 1.06577 \n",
      " Validation: accuracy: 0.984375 loss: 0.795165\n",
      " cross_entropy: 0.221453, clust_cross_entropy: 0.639568, affinity: 0.00531294, balance: 0.139366, coact: 0.0265362, frob: 0.000254332\n",
      "step 2300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.956321 \n",
      " Validation: accuracy: 0.992188 loss: 0.837288\n",
      " cross_entropy: 0.285998, clust_cross_entropy: 0.462373, affinity: 0.00494498, balance: 0.132796, coact: 0.0448052, frob: 0.000237945\n",
      "step 2400/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.46518 \n",
      " Validation: accuracy: 1 loss: 0.820968\n",
      " cross_entropy: 0.320354, clust_cross_entropy: 0.969442, affinity: 0.00631596, balance: 0.118141, coact: 0.0421311, frob: 0.000241527\n",
      "step 2500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.95149 \n",
      " Validation: accuracy: 0.960938 loss: 0.807469\n",
      " cross_entropy: 0.328804, clust_cross_entropy: 0.395603, affinity: 0.00284279, balance: 0.167169, coact: 0.0296331, frob: 0.000249392\n",
      "step 2600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.931956 \n",
      " Validation: accuracy: 0.976562 loss: 0.799736\n",
      " cross_entropy: 0.252867, clust_cross_entropy: 0.526363, affinity: 0.00479729, balance: 0.106823, coact: 0.0300329, frob: 0.000243983\n",
      "step 2700/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.07137 \n",
      " Validation: accuracy: 0.96875 loss: 0.97357\n",
      " cross_entropy: 0.282943, clust_cross_entropy: 0.565106, affinity: 0.00608992, balance: 0.152851, coact: 0.0313081, frob: 0.000254528\n",
      "step 2800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.695584 \n",
      " Validation: accuracy: 0.953125 loss: 0.793583\n",
      " cross_entropy: 0.246663, clust_cross_entropy: 0.209057, affinity: 0.00351972, balance: 0.17655, coact: 0.0293144, frob: 0.000243868\n",
      "step 2900/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.20273 \n",
      " Validation: accuracy: 0.984375 loss: 0.929033\n",
      " cross_entropy: 0.327821, clust_cross_entropy: 0.714583, affinity: 0.00374508, balance: 0.139607, coact: 0.0243722, frob: 0.000246832\n",
      "step 3000/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.00785 \n",
      " Validation: accuracy: 0.976562 loss: 0.806889\n",
      " cross_entropy: 0.225781, clust_cross_entropy: 0.38378, affinity: 0.00760146, balance: 0.295083, coact: 0.0291657, frob: 0.00023931\n",
      "step 3100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.997809 \n",
      " Validation: accuracy: 0.992188 loss: 0.891709\n",
      " cross_entropy: 0.323344, clust_cross_entropy: 0.497545, affinity: 0.00545923, balance: 0.222375, coact: 0.0256637, frob: 0.000237975\n",
      "step 3200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.857614 \n",
      " Validation: accuracy: 0.984375 loss: 0.908798\n",
      " cross_entropy: 0.330036, clust_cross_entropy: 0.376643, affinity: 0.00496286, balance: 0.141236, coact: 0.0280663, frob: 0.000250038\n",
      "step 3300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.888921 \n",
      " Validation: accuracy: 0.976562 loss: 0.830324\n",
      " cross_entropy: 0.275252, clust_cross_entropy: 0.41615, affinity: 0.00461853, balance: 0.134597, coact: 0.0190797, frob: 0.00024984\n",
      "step 3400/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.17773 \n",
      " Validation: accuracy: 0.976562 loss: 0.89037\n",
      " cross_entropy: 0.246046, clust_cross_entropy: 0.609713, affinity: 0.00536114, balance: 0.128006, coact: 0.0150966, frob: 0.000251424\n",
      "step 3500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.966491 \n",
      " Validation: accuracy: 0.953125 loss: 0.879536\n",
      " cross_entropy: 0.269101, clust_cross_entropy: 0.46467, affinity: 0.00463285, balance: 0.149657, coact: 0.0147811, frob: 0.000237529\n",
      "step 3600/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.10667 \n",
      " Validation: accuracy: 0.992188 loss: 0.700167\n",
      " cross_entropy: 0.300827, clust_cross_entropy: 0.657842, affinity: 0.00529052, balance: 0.190534, coact: 0.0110032, frob: 0.000245226\n",
      "step 3700/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.03493 \n",
      " Validation: accuracy: 1 loss: 0.689075\n",
      " cross_entropy: 0.335714, clust_cross_entropy: 0.483476, affinity: 0.0036889, balance: 0.138843, coact: 0.0247567, frob: 0.000237118\n",
      "step 3800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.975823 \n",
      " Validation: accuracy: 0.984375 loss: 0.986045\n",
      " cross_entropy: 0.281358, clust_cross_entropy: 0.465026, affinity: 0.00483905, balance: 0.172642, coact: 0.0214876, frob: 0.000248807\n",
      "step 3900/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.06516 \n",
      " Validation: accuracy: 0.976562 loss: 0.791445\n",
      " cross_entropy: 0.307045, clust_cross_entropy: 0.575231, affinity: 0.00587643, balance: 0.165883, coact: 0.0380742, frob: 0.000245256\n",
      "step 4000/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.857245 \n",
      " Validation: accuracy: 0.976562 loss: 0.650768\n",
      " cross_entropy: 0.231533, clust_cross_entropy: 0.449077, affinity: 0.0037307, balance: 0.25576, coact: 0.0316358, frob: 0.000247642\n",
      "step 4100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.856466 \n",
      " Validation: accuracy: 0.984375 loss: 0.86993\n",
      " cross_entropy: 0.280759, clust_cross_entropy: 0.415727, affinity: 0.00399949, balance: 0.161448, coact: 0.0231749, frob: 0.000239837\n",
      "step 4200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.737135 \n",
      " Validation: accuracy: 0.953125 loss: 0.981544\n",
      " cross_entropy: 0.242123, clust_cross_entropy: 0.394538, affinity: 0.00393943, balance: 0.121204, coact: 0.0306753, frob: 0.000242228\n",
      "step 4300/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.03225 \n",
      " Validation: accuracy: 0.984375 loss: 0.873776\n",
      " cross_entropy: 0.388114, clust_cross_entropy: 0.405293, affinity: 0.00253531, balance: 0.203791, coact: 0.0230692, frob: 0.00024273\n",
      "step 4400/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.12285 \n",
      " Validation: accuracy: 0.976562 loss: 0.90338\n",
      " cross_entropy: 0.234081, clust_cross_entropy: 0.703419, affinity: 0.00244302, balance: 0.140449, coact: 0.0264448, frob: 0.000249557\n",
      "step 4500/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.977217 \n",
      " Validation: accuracy: 0.984375 loss: 0.792611\n",
      " cross_entropy: 0.333271, clust_cross_entropy: 0.524046, affinity: 0.00573625, balance: 0.136491, coact: 0.028623, frob: 0.000236191\n",
      "step 4600/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.908646 \n",
      " Validation: accuracy: 0.945312 loss: 0.902128\n",
      " cross_entropy: 0.271644, clust_cross_entropy: 0.494459, affinity: 0.00191966, balance: 0.121255, coact: 0.0225914, frob: 0.000243195\n",
      "step 4700/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.00424 \n",
      " Validation: accuracy: 0.976562 loss: 0.976798\n",
      " cross_entropy: 0.295031, clust_cross_entropy: 0.55119, affinity: 0.00360612, balance: 0.155899, coact: 0.024157, frob: 0.000239738\n",
      "step 4800/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.788418 \n",
      " Validation: accuracy: 0.976562 loss: 0.77979\n",
      " cross_entropy: 0.297501, clust_cross_entropy: 0.305283, affinity: 0.00446835, balance: 0.0688018, coact: 0.0327168, frob: 0.000241313\n",
      "step 4900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.959119 \n",
      " Validation: accuracy: 0.984375 loss: 0.738419\n",
      " cross_entropy: 0.275564, clust_cross_entropy: 0.518076, affinity: 0.00361707, balance: 0.121817, coact: 0.0224667, frob: 0.000237159\n",
      "step 5000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.957266 \n",
      " Validation: accuracy: 0.984375 loss: 0.685855\n",
      " cross_entropy: 0.233415, clust_cross_entropy: 0.424301, affinity: 0.00378167, balance: 0.276883, coact: 0.0302015, frob: 0.000241012\n",
      "step 5100/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.03268 \n",
      " Validation: accuracy: 0.992188 loss: 0.66725\n",
      " cross_entropy: 0.22702, clust_cross_entropy: 0.741106, affinity: 0.00339892, balance: 0.133857, coact: 0.0418924, frob: 0.000251084\n",
      "step 5200/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.12375 \n",
      " Validation: accuracy: 0.984375 loss: 0.607528\n",
      " cross_entropy: 0.25878, clust_cross_entropy: 0.635482, affinity: 0.00504397, balance: 0.184054, coact: 0.0285243, frob: 0.00024368\n",
      "step 5300/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.963737 \n",
      " Validation: accuracy: 0.992188 loss: 0.775652\n",
      " cross_entropy: 0.302024, clust_cross_entropy: 0.515704, affinity: 0.00217316, balance: 0.194717, coact: 0.015112, frob: 0.000238961\n",
      "step 5400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.888945 \n",
      " Validation: accuracy: 0.96875 loss: 0.816029\n",
      " cross_entropy: 0.321037, clust_cross_entropy: 0.343767, affinity: 0.0023721, balance: 0.19516, coact: 0.0169772, frob: 0.000230958\n",
      "step 5500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.854042 \n",
      " Validation: accuracy: 0.992188 loss: 0.743715\n",
      " cross_entropy: 0.311157, clust_cross_entropy: 0.404513, affinity: 0.00564104, balance: 0.103229, coact: 0.0172655, frob: 0.000238059\n",
      "step 5600/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.28486 \n",
      " Validation: accuracy: 0.960938 loss: 1.01251\n",
      " cross_entropy: 0.285775, clust_cross_entropy: 0.775892, affinity: 0.00438947, balance: 0.107059, coact: 0.020979, frob: 0.000241743\n",
      "step 5700/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.834685 \n",
      " Validation: accuracy: 0.976562 loss: 0.851243\n",
      " cross_entropy: 0.359707, clust_cross_entropy: 0.337633, affinity: 0.00584803, balance: 0.214847, coact: 0.0236114, frob: 0.000246076\n",
      "step 5800/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.23008 \n",
      " Validation: accuracy: 0.984375 loss: 0.833217\n",
      " cross_entropy: 0.3022, clust_cross_entropy: 0.681519, affinity: 0.00566162, balance: 0.159323, coact: 0.0269131, frob: 0.000248739\n",
      "step 5900/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.60027 \n",
      " Validation: accuracy: 0.984375 loss: 0.738368\n",
      " cross_entropy: 0.248637, clust_cross_entropy: 1.1903, affinity: 0.00400966, balance: 0.223962, coact: 0.0127532, frob: 0.000245766\n",
      "step 6000/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.18371 \n",
      " Validation: accuracy: 0.992188 loss: 1.11777\n",
      " cross_entropy: 0.255773, clust_cross_entropy: 0.707071, affinity: 0.00262367, balance: 0.125984, coact: 0.0285371, frob: 0.000242619\n",
      "step 6100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.07625 \n",
      " Validation: accuracy: 0.984375 loss: 0.691582\n",
      " cross_entropy: 0.244589, clust_cross_entropy: 0.623265, affinity: 0.00527734, balance: 0.197325, coact: 0.024602, frob: 0.000243287\n",
      "step 6200/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.957687 \n",
      " Validation: accuracy: 0.953125 loss: 0.87595\n",
      " cross_entropy: 0.255205, clust_cross_entropy: 0.541354, affinity: 0.00503753, balance: 0.160702, coact: 0.0290183, frob: 0.000241469\n",
      "step 6300/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.13138 \n",
      " Validation: accuracy: 0.953125 loss: 0.889653\n",
      " cross_entropy: 0.281593, clust_cross_entropy: 0.71752, affinity: 0.0035984, balance: 0.181005, coact: 0.0212659, frob: 0.000244694\n",
      "step 6400/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.821327 \n",
      " Validation: accuracy: 0.984375 loss: 0.634549\n",
      " cross_entropy: 0.289971, clust_cross_entropy: 0.353094, affinity: 0.0025089, balance: 0.137693, coact: 0.0160596, frob: 0.000245837\n",
      "step 6500/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.03193 \n",
      " Validation: accuracy: 0.976562 loss: 0.798574\n",
      " cross_entropy: 0.279457, clust_cross_entropy: 0.540159, affinity: 0.00276707, balance: 0.153392, coact: 0.0434664, frob: 0.00023758\n",
      "step 6600/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.20242 \n",
      " Validation: accuracy: 0.976562 loss: 0.927999\n",
      " cross_entropy: 0.256508, clust_cross_entropy: 0.742963, affinity: 0.00477422, balance: 0.195086, coact: 0.0153883, frob: 0.000240167\n",
      "step 6700/20000 \n",
      " Train: accuracy: 1, loss: 0.946091 \n",
      " Validation: accuracy: 1 loss: 0.787363\n",
      " cross_entropy: 0.256062, clust_cross_entropy: 0.598454, affinity: 0.00475573, balance: 0.24615, coact: 0.0218491, frob: 0.000255706\n",
      "step 6800/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.13337 \n",
      " Validation: accuracy: 0.984375 loss: 0.986437\n",
      " cross_entropy: 0.259221, clust_cross_entropy: 0.559375, affinity: 0.00545422, balance: 0.213645, coact: 0.0301413, frob: 0.000247105\n",
      "step 6900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.909366 \n",
      " Validation: accuracy: 0.984375 loss: 0.884261\n",
      " cross_entropy: 0.301142, clust_cross_entropy: 0.426223, affinity: 0.00353981, balance: 0.169202, coact: 0.0202999, frob: 0.000237262\n",
      "step 7000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.802716 \n",
      " Validation: accuracy: 0.976562 loss: 0.839911\n",
      " cross_entropy: 0.322406, clust_cross_entropy: 0.45896, affinity: 0.00650746, balance: 0.128128, coact: 0.0191684, frob: 0.000241951\n",
      "step 7100/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.19388 \n",
      " Validation: accuracy: 0.992188 loss: 0.701395\n",
      " cross_entropy: 0.255212, clust_cross_entropy: 0.821158, affinity: 0.00302112, balance: 0.12268, coact: 0.0282971, frob: 0.000247394\n",
      "step 7200/20000 \n",
      " Train: accuracy: 1, loss: 0.902132 \n",
      " Validation: accuracy: 0.984375 loss: 0.769522\n",
      " cross_entropy: 0.201746, clust_cross_entropy: 0.494123, affinity: 0.00338965, balance: 0.176146, coact: 0.0230702, frob: 0.000248122\n",
      "step 7300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.762693 \n",
      " Validation: accuracy: 0.976562 loss: 0.763689\n",
      " cross_entropy: 0.254014, clust_cross_entropy: 0.280521, affinity: 0.0035298, balance: 0.189305, coact: 0.0218212, frob: 0.000239583\n",
      "step 7400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.892184 \n",
      " Validation: accuracy: 0.992188 loss: 0.621218\n",
      " cross_entropy: 0.292046, clust_cross_entropy: 0.44899, affinity: 0.00485347, balance: 0.11939, coact: 0.0310904, frob: 0.000237519\n",
      "step 7500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.768084 \n",
      " Validation: accuracy: 0.960938 loss: 0.733607\n",
      " cross_entropy: 0.265866, clust_cross_entropy: 0.266002, affinity: 0.0055284, balance: 0.141326, coact: 0.0204747, frob: 0.000235375\n",
      "step 7600/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.873317 \n",
      " Validation: accuracy: 0.976562 loss: 0.834562\n",
      " cross_entropy: 0.20281, clust_cross_entropy: 0.567222, affinity: 0.00231879, balance: 0.111021, coact: 0.0182705, frob: 0.000241396\n",
      "step 7700/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.16163 \n",
      " Validation: accuracy: 0.984375 loss: 0.760929\n",
      " cross_entropy: 0.244353, clust_cross_entropy: 0.667153, affinity: 0.00211382, balance: 0.180075, coact: 0.0247462, frob: 0.000240085\n",
      "step 7800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.935972 \n",
      " Validation: accuracy: 0.984375 loss: 0.764776\n",
      " cross_entropy: 0.236482, clust_cross_entropy: 0.614764, affinity: 0.00361662, balance: 0.175199, coact: 0.0195665, frob: 0.000243797\n",
      "step 7900/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.0091 \n",
      " Validation: accuracy: 0.976562 loss: 0.925889\n",
      " cross_entropy: 0.20365, clust_cross_entropy: 0.494706, affinity: 0.00304343, balance: 0.171867, coact: 0.0320616, frob: 0.000258763\n",
      "step 8000/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.672667 \n",
      " Validation: accuracy: 0.96875 loss: 0.745304\n",
      " cross_entropy: 0.202118, clust_cross_entropy: 0.315452, affinity: 0.00480923, balance: 0.133624, coact: 0.0156602, frob: 0.000243765\n",
      "step 8100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.15115 \n",
      " Validation: accuracy: 0.960938 loss: 0.812905\n",
      " cross_entropy: 0.27826, clust_cross_entropy: 0.635629, affinity: 0.00346533, balance: 0.260303, coact: 0.0148939, frob: 0.000237141\n",
      "step 8200/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.06411 \n",
      " Validation: accuracy: 0.992188 loss: 0.789822\n",
      " cross_entropy: 0.274016, clust_cross_entropy: 0.632148, affinity: 0.00340731, balance: 0.137487, coact: 0.033738, frob: 0.000248939\n",
      "step 8300/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.27977 \n",
      " Validation: accuracy: 0.984375 loss: 0.674324\n",
      " cross_entropy: 0.240264, clust_cross_entropy: 0.621097, affinity: 0.0036157, balance: 0.215759, coact: 0.0271384, frob: 0.00024835\n",
      "step 8400/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.10914 \n",
      " Validation: accuracy: 0.96875 loss: 0.786521\n",
      " cross_entropy: 0.242092, clust_cross_entropy: 0.666656, affinity: 0.00425344, balance: 0.21169, coact: 0.0213546, frob: 0.000241397\n",
      "step 8500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.884708 \n",
      " Validation: accuracy: 0.96875 loss: 0.816322\n",
      " cross_entropy: 0.255241, clust_cross_entropy: 0.427037, affinity: 0.00212504, balance: 0.13133, coact: 0.0328215, frob: 0.000234561\n",
      "step 8600/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.12013 \n",
      " Validation: accuracy: 0.976562 loss: 0.836382\n",
      " cross_entropy: 0.230932, clust_cross_entropy: 0.609161, affinity: 0.00393908, balance: 0.175328, coact: 0.0230356, frob: 0.000245371\n",
      "step 8700/20000 \n",
      " Train: accuracy: 0.953125, loss: 1.11651 \n",
      " Validation: accuracy: 0.976562 loss: 0.924783\n",
      " cross_entropy: 0.272794, clust_cross_entropy: 0.71276, affinity: 0.0032115, balance: 0.143304, coact: 0.0162085, frob: 0.000244838\n",
      "step 8800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.724296 \n",
      " Validation: accuracy: 0.984375 loss: 0.805027\n",
      " cross_entropy: 0.210376, clust_cross_entropy: 0.232673, affinity: 0.00230902, balance: 0.278559, coact: 0.0261863, frob: 0.000247965\n",
      "step 8900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.863449 \n",
      " Validation: accuracy: 0.984375 loss: 0.921559\n",
      " cross_entropy: 0.275608, clust_cross_entropy: 0.429713, affinity: 0.00395032, balance: 0.162101, coact: 0.0215014, frob: 0.000245005\n",
      "step 9000/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.850139 \n",
      " Validation: accuracy: 0.976562 loss: 0.72674\n",
      " cross_entropy: 0.277491, clust_cross_entropy: 0.430297, affinity: 0.00255853, balance: 0.140734, coact: 0.0333154, frob: 0.000245649\n",
      "step 9100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.02011 \n",
      " Validation: accuracy: 1 loss: 0.696072\n",
      " cross_entropy: 0.305841, clust_cross_entropy: 0.466443, affinity: 0.00475913, balance: 0.185111, coact: 0.0225064, frob: 0.000240797\n",
      "step 9200/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.695116 \n",
      " Validation: accuracy: 0.992188 loss: 0.650127\n",
      " cross_entropy: 0.227105, clust_cross_entropy: 0.310387, affinity: 0.00162034, balance: 0.164836, coact: 0.0233919, frob: 0.000233069\n",
      "step 9300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.610689 \n",
      " Validation: accuracy: 0.96875 loss: 0.827857\n",
      " cross_entropy: 0.258731, clust_cross_entropy: 0.157927, affinity: 0.00329047, balance: 0.168531, coact: 0.0181322, frob: 0.000243237\n",
      "step 9400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.96403 \n",
      " Validation: accuracy: 0.992188 loss: 0.67904\n",
      " cross_entropy: 0.218869, clust_cross_entropy: 0.643954, affinity: 0.00300433, balance: 0.183713, coact: 0.0176301, frob: 0.000245776\n",
      "step 9500/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.10798 \n",
      " Validation: accuracy: 1 loss: 0.69614\n",
      " cross_entropy: 0.31232, clust_cross_entropy: 0.538073, affinity: 0.00259766, balance: 0.118902, coact: 0.00911699, frob: 0.000241489\n",
      "step 9600/20000 \n",
      " Train: accuracy: 1, loss: 0.87112 \n",
      " Validation: accuracy: 0.992188 loss: 0.630968\n",
      " cross_entropy: 0.259466, clust_cross_entropy: 0.456935, affinity: 0.00477754, balance: 0.113594, coact: 0.0252196, frob: 0.000239769\n",
      "step 9700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.878075 \n",
      " Validation: accuracy: 0.96875 loss: 0.724171\n",
      " cross_entropy: 0.280347, clust_cross_entropy: 0.393987, affinity: 0.00237882, balance: 0.163265, coact: 0.0296228, frob: 0.000239295\n",
      "step 9800/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.07808 \n",
      " Validation: accuracy: 0.960938 loss: 0.825196\n",
      " cross_entropy: 0.246833, clust_cross_entropy: 0.724551, affinity: 0.00336237, balance: 0.151742, coact: 0.0279285, frob: 0.00024262\n",
      "step 9900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.868401 \n",
      " Validation: accuracy: 0.984375 loss: 0.771068\n",
      " cross_entropy: 0.244778, clust_cross_entropy: 0.491975, affinity: 0.00311241, balance: 0.148054, coact: 0.0134235, frob: 0.000242766\n",
      "step 10000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.824799 \n",
      " Validation: accuracy: 0.96875 loss: 0.866632\n",
      " cross_entropy: 0.247878, clust_cross_entropy: 0.381142, affinity: 0.002065, balance: 0.202071, coact: 0.0266224, frob: 0.000227833\n",
      "step 10100/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.703113 \n",
      " Validation: accuracy: 1 loss: 0.789263\n",
      " cross_entropy: 0.238377, clust_cross_entropy: 0.267006, affinity: 0.00299437, balance: 0.174821, coact: 0.0112602, frob: 0.000247344\n",
      "step 10200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.948877 \n",
      " Validation: accuracy: 0.992188 loss: 0.718764\n",
      " cross_entropy: 0.242899, clust_cross_entropy: 0.577985, affinity: 0.00304168, balance: 0.156885, coact: 0.0194169, frob: 0.000238609\n",
      "step 10300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.8151 \n",
      " Validation: accuracy: 0.960938 loss: 0.852395\n",
      " cross_entropy: 0.213639, clust_cross_entropy: 0.434582, affinity: 0.00342739, balance: 0.137096, coact: 0.0360015, frob: 0.000250226\n",
      "step 10400/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.18433 \n",
      " Validation: accuracy: 0.984375 loss: 0.762317\n",
      " cross_entropy: 0.281489, clust_cross_entropy: 0.641067, affinity: 0.00407591, balance: 0.0589694, coact: 0.0226251, frob: 0.000236832\n",
      "step 10500/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.01276 \n",
      " Validation: accuracy: 0.976562 loss: 0.74884\n",
      " cross_entropy: 0.327875, clust_cross_entropy: 0.556279, affinity: 0.00342424, balance: 0.177104, coact: 0.0184048, frob: 0.000245745\n",
      "step 10600/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.17287 \n",
      " Validation: accuracy: 0.976562 loss: 0.752729\n",
      " cross_entropy: 0.302264, clust_cross_entropy: 0.700655, affinity: 0.00367932, balance: 0.228438, coact: 0.0141415, frob: 0.000235695\n",
      "step 10700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.728056 \n",
      " Validation: accuracy: 1 loss: 0.86075\n",
      " cross_entropy: 0.25259, clust_cross_entropy: 0.307691, affinity: 0.00379183, balance: 0.127827, coact: 0.0412361, frob: 0.000239442\n",
      "step 10800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.69031 \n",
      " Validation: accuracy: 0.976562 loss: 0.872159\n",
      " cross_entropy: 0.264974, clust_cross_entropy: 0.260046, affinity: 0.00351594, balance: 0.118065, coact: 0.0210973, frob: 0.000247908\n",
      "step 10900/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.04747 \n",
      " Validation: accuracy: 0.976562 loss: 0.731984\n",
      " cross_entropy: 0.232162, clust_cross_entropy: 0.623065, affinity: 0.00257113, balance: 0.168459, coact: 0.00881514, frob: 0.000248087\n",
      "step 11000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.861362 \n",
      " Validation: accuracy: 0.984375 loss: 0.757953\n",
      " cross_entropy: 0.259658, clust_cross_entropy: 0.456898, affinity: 0.00159458, balance: 0.138866, coact: 0.0200732, frob: 0.000244698\n",
      "step 11100/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.918659 \n",
      " Validation: accuracy: 0.96875 loss: 0.788764\n",
      " cross_entropy: 0.248276, clust_cross_entropy: 0.464036, affinity: 0.00351468, balance: 0.115911, coact: 0.0184986, frob: 0.000244435\n",
      "step 11200/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.1815 \n",
      " Validation: accuracy: 0.96875 loss: 0.753101\n",
      " cross_entropy: 0.263606, clust_cross_entropy: 0.604483, affinity: 0.00133482, balance: 0.232072, coact: 0.0214312, frob: 0.000249883\n",
      "step 11300/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.11782 \n",
      " Validation: accuracy: 1 loss: 0.797943\n",
      " cross_entropy: 0.289506, clust_cross_entropy: 0.538517, affinity: 0.00394074, balance: 0.199406, coact: 0.0313076, frob: 0.000246697\n",
      "step 11400/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.34308 \n",
      " Validation: accuracy: 0.984375 loss: 0.934022\n",
      " cross_entropy: 0.314835, clust_cross_entropy: 0.862982, affinity: 0.00371466, balance: 0.186113, coact: 0.0175907, frob: 0.000243722\n",
      "step 11500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.954704 \n",
      " Validation: accuracy: 0.984375 loss: 0.770515\n",
      " cross_entropy: 0.258428, clust_cross_entropy: 0.557724, affinity: 0.00467579, balance: 0.0840856, coact: 0.0387906, frob: 0.000243561\n",
      "step 11600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.924369 \n",
      " Validation: accuracy: 0.976562 loss: 0.639586\n",
      " cross_entropy: 0.32627, clust_cross_entropy: 0.496841, affinity: 0.00488064, balance: 0.0725064, coact: 0.00548062, frob: 0.000245166\n",
      "step 11700/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.24729 \n",
      " Validation: accuracy: 0.992188 loss: 0.763174\n",
      " cross_entropy: 0.290534, clust_cross_entropy: 0.643465, affinity: 0.00255585, balance: 0.241926, coact: 0.0232275, frob: 0.000235497\n",
      "step 11800/20000 \n",
      " Train: accuracy: 1, loss: 0.838642 \n",
      " Validation: accuracy: 0.992188 loss: 0.738646\n",
      " cross_entropy: 0.228774, clust_cross_entropy: 0.46692, affinity: 0.00534738, balance: 0.15486, coact: 0.0308215, frob: 0.000247671\n",
      "step 11900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.955408 \n",
      " Validation: accuracy: 0.992188 loss: 0.808082\n",
      " cross_entropy: 0.202459, clust_cross_entropy: 0.507458, affinity: 0.00473398, balance: 0.160278, coact: 0.0246038, frob: 0.000249983\n",
      "step 12000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.988431 \n",
      " Validation: accuracy: 0.992188 loss: 0.708904\n",
      " cross_entropy: 0.208489, clust_cross_entropy: 0.522183, affinity: 0.00501361, balance: 0.204101, coact: 0.0280173, frob: 0.000238764\n",
      "step 12100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.02501 \n",
      " Validation: accuracy: 0.992188 loss: 0.68381\n",
      " cross_entropy: 0.259138, clust_cross_entropy: 0.65545, affinity: 0.00373403, balance: 0.18563, coact: 0.0176691, frob: 0.000245258\n",
      "step 12200/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.25067 \n",
      " Validation: accuracy: 0.992188 loss: 0.721724\n",
      " cross_entropy: 0.266349, clust_cross_entropy: 0.620198, affinity: 0.00266537, balance: 0.231078, coact: 0.0281136, frob: 0.000244058\n",
      "step 12300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.720697 \n",
      " Validation: accuracy: 0.96875 loss: 0.839968\n",
      " cross_entropy: 0.229003, clust_cross_entropy: 0.228113, affinity: 0.0018392, balance: 0.207598, coact: 0.0164458, frob: 0.000257404\n",
      "step 12400/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.9044 \n",
      " Validation: accuracy: 0.976562 loss: 0.993566\n",
      " cross_entropy: 0.288115, clust_cross_entropy: 0.543537, affinity: 0.00221118, balance: 0.0865673, coact: 0.0235972, frob: 0.000241876\n",
      "step 12500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.667791 \n",
      " Validation: accuracy: 0.992188 loss: 0.700172\n",
      " cross_entropy: 0.238341, clust_cross_entropy: 0.280198, affinity: 0.00332345, balance: 0.0999326, coact: 0.0126646, frob: 0.000247775\n",
      "step 12600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.94944 \n",
      " Validation: accuracy: 0.96875 loss: 0.882763\n",
      " cross_entropy: 0.225023, clust_cross_entropy: 0.502051, affinity: 0.00245491, balance: 0.126583, coact: 0.00925568, frob: 0.000242411\n",
      "step 12700/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.977684 \n",
      " Validation: accuracy: 0.992188 loss: 0.740969\n",
      " cross_entropy: 0.292208, clust_cross_entropy: 0.461887, affinity: 0.00441028, balance: 0.185892, coact: 0.0316816, frob: 0.000249793\n",
      "step 12800/20000 \n",
      " Train: accuracy: 1, loss: 1.05573 \n",
      " Validation: accuracy: 0.976562 loss: 0.677101\n",
      " cross_entropy: 0.190191, clust_cross_entropy: 0.68032, affinity: 0.00341066, balance: 0.139221, coact: 0.0237147, frob: 0.000247953\n",
      "step 12900/20000 \n",
      " Train: accuracy: 1, loss: 0.806207 \n",
      " Validation: accuracy: 0.96875 loss: 0.986181\n",
      " cross_entropy: 0.233689, clust_cross_entropy: 0.371268, affinity: 0.00250376, balance: 0.176535, coact: 0.022063, frob: 0.000241549\n",
      "step 13000/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.945199 \n",
      " Validation: accuracy: 0.945312 loss: 0.890679\n",
      " cross_entropy: 0.303548, clust_cross_entropy: 0.66045, affinity: 0.0026467, balance: 0.121984, coact: 0.0218128, frob: 0.00023628\n",
      "step 13100/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.652097 \n",
      " Validation: accuracy: 0.976562 loss: 0.909439\n",
      " cross_entropy: 0.235138, clust_cross_entropy: 0.214993, affinity: 0.002225, balance: 0.140599, coact: 0.0163511, frob: 0.000244884\n",
      "step 13200/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.12943 \n",
      " Validation: accuracy: 0.96875 loss: 0.792037\n",
      " cross_entropy: 0.234688, clust_cross_entropy: 0.55529, affinity: 0.000936732, balance: 0.258332, coact: 0.0177871, frob: 0.000246493\n",
      "step 13300/20000 \n",
      " Train: accuracy: 1, loss: 0.86601 \n",
      " Validation: accuracy: 0.984375 loss: 0.671089\n",
      " cross_entropy: 0.190486, clust_cross_entropy: 0.437669, affinity: 0.00333473, balance: 0.149451, coact: 0.00967014, frob: 0.00024777\n",
      "step 13400/20000 \n",
      " Train: accuracy: 1, loss: 0.817091 \n",
      " Validation: accuracy: 0.992188 loss: 0.678911\n",
      " cross_entropy: 0.237038, clust_cross_entropy: 0.466068, affinity: 0.00284848, balance: 0.150999, coact: 0.0168766, frob: 0.000242431\n",
      "step 13500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.728269 \n",
      " Validation: accuracy: 0.992188 loss: 0.753081\n",
      " cross_entropy: 0.225444, clust_cross_entropy: 0.368135, affinity: 0.00262947, balance: 0.130127, coact: 0.0258934, frob: 0.000247721\n",
      "step 13600/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.855091 \n",
      " Validation: accuracy: 0.984375 loss: 0.728641\n",
      " cross_entropy: 0.308975, clust_cross_entropy: 0.511273, affinity: 0.00287106, balance: 0.121992, coact: 0.0162408, frob: 0.000247796\n",
      "step 13700/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.781788 \n",
      " Validation: accuracy: 0.992188 loss: 0.724398\n",
      " cross_entropy: 0.223225, clust_cross_entropy: 0.447041, affinity: 0.00322213, balance: 0.102086, coact: 0.0166384, frob: 0.000242106\n",
      "step 13800/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.01083 \n",
      " Validation: accuracy: 1 loss: 0.684357\n",
      " cross_entropy: 0.190275, clust_cross_entropy: 0.606601, affinity: 0.00254825, balance: 0.120672, coact: 0.0200287, frob: 0.000253657\n",
      "step 13900/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.959072 \n",
      " Validation: accuracy: 0.96875 loss: 0.753248\n",
      " cross_entropy: 0.314142, clust_cross_entropy: 0.566836, affinity: 0.0038948, balance: 0.0834254, coact: 0.0149297, frob: 0.000241778\n",
      "step 14000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.956514 \n",
      " Validation: accuracy: 0.984375 loss: 0.710011\n",
      " cross_entropy: 0.262574, clust_cross_entropy: 0.523685, affinity: 0.00134838, balance: 0.153574, coact: 0.00865842, frob: 0.000246553\n",
      "step 14100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.16231 \n",
      " Validation: accuracy: 0.96875 loss: 0.836418\n",
      " cross_entropy: 0.277826, clust_cross_entropy: 0.594867, affinity: 0.0041861, balance: 0.230381, coact: 0.0294635, frob: 0.000242051\n",
      "step 14200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.879471 \n",
      " Validation: accuracy: 0.992188 loss: 0.724801\n",
      " cross_entropy: 0.348523, clust_cross_entropy: 0.398534, affinity: 0.00395772, balance: 0.108695, coact: 0.0125998, frob: 0.000244235\n",
      "step 14300/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.18984 \n",
      " Validation: accuracy: 0.984375 loss: 0.894025\n",
      " cross_entropy: 0.23523, clust_cross_entropy: 0.820319, affinity: 0.00396503, balance: 0.11289, coact: 0.0255906, frob: 0.000256085\n",
      "step 14400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.666879 \n",
      " Validation: accuracy: 0.984375 loss: 0.769598\n",
      " cross_entropy: 0.290985, clust_cross_entropy: 0.336668, affinity: 0.00410276, balance: 0.149677, coact: 0.0279821, frob: 0.000247067\n",
      "step 14500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.907845 \n",
      " Validation: accuracy: 1 loss: 0.602911\n",
      " cross_entropy: 0.24927, clust_cross_entropy: 0.319638, affinity: 0.00271179, balance: 0.159671, coact: 0.0111364, frob: 0.000249307\n",
      "step 14600/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.09702 \n",
      " Validation: accuracy: 0.984375 loss: 0.728506\n",
      " cross_entropy: 0.270571, clust_cross_entropy: 0.639617, affinity: 0.0057626, balance: 0.117416, coact: 0.0204179, frob: 0.000238155\n",
      "step 14700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.803816 \n",
      " Validation: accuracy: 1 loss: 0.724757\n",
      " cross_entropy: 0.298689, clust_cross_entropy: 0.254478, affinity: 0.00252755, balance: 0.172252, coact: 0.0151453, frob: 0.00024603\n",
      "step 14800/20000 \n",
      " Train: accuracy: 1, loss: 0.85721 \n",
      " Validation: accuracy: 1 loss: 0.637792\n",
      " cross_entropy: 0.197029, clust_cross_entropy: 0.468234, affinity: 0.00257645, balance: 0.120242, coact: 0.0216308, frob: 0.000245953\n",
      "step 14900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.902709 \n",
      " Validation: accuracy: 0.96875 loss: 0.753982\n",
      " cross_entropy: 0.233906, clust_cross_entropy: 0.346969, affinity: 0.0030914, balance: 0.20225, coact: 0.034314, frob: 0.000252958\n",
      "step 15000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.796198 \n",
      " Validation: accuracy: 0.984375 loss: 0.83362\n",
      " cross_entropy: 0.283906, clust_cross_entropy: 0.358446, affinity: 0.00264543, balance: 0.175867, coact: 0.019944, frob: 0.000248388\n",
      "step 15100/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.04633 \n",
      " Validation: accuracy: 0.984375 loss: 0.769211\n",
      " cross_entropy: 0.305964, clust_cross_entropy: 0.568215, affinity: 0.00321627, balance: 0.172431, coact: 0.0249803, frob: 0.000252818\n",
      "step 15200/20000 \n",
      " Train: accuracy: 0.953125, loss: 1.05016 \n",
      " Validation: accuracy: 0.992188 loss: 0.853465\n",
      " cross_entropy: 0.258151, clust_cross_entropy: 0.706763, affinity: 0.00334157, balance: 0.0838261, coact: 0.0208924, frob: 0.0002524\n",
      "step 15300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.909826 \n",
      " Validation: accuracy: 0.984375 loss: 0.797674\n",
      " cross_entropy: 0.255262, clust_cross_entropy: 0.516876, affinity: 0.00252681, balance: 0.15883, coact: 0.0225803, frob: 0.000255576\n",
      "step 15400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.986622 \n",
      " Validation: accuracy: 0.984375 loss: 0.645458\n",
      " cross_entropy: 0.186878, clust_cross_entropy: 0.488899, affinity: 0.0017108, balance: 0.161406, coact: 0.0148579, frob: 0.000252108\n",
      "step 15500/20000 \n",
      " Train: accuracy: 0.953125, loss: 1.1193 \n",
      " Validation: accuracy: 0.976562 loss: 0.787269\n",
      " cross_entropy: 0.285174, clust_cross_entropy: 0.685409, affinity: 0.00477227, balance: 0.126106, coact: 0.0195546, frob: 0.000250179\n",
      "step 15600/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.09308 \n",
      " Validation: accuracy: 0.984375 loss: 0.816712\n",
      " cross_entropy: 0.282491, clust_cross_entropy: 0.614246, affinity: 0.00321547, balance: 0.209594, coact: 0.00909207, frob: 0.000252536\n",
      "step 15700/20000 \n",
      " Train: accuracy: 0.953125, loss: 1.30028 \n",
      " Validation: accuracy: 0.992188 loss: 0.720668\n",
      " cross_entropy: 0.312644, clust_cross_entropy: 0.839333, affinity: 0.00347578, balance: 0.214976, coact: 0.0266975, frob: 0.000259095\n",
      "step 15800/20000 \n",
      " Train: accuracy: 0.96875, loss: 1.0087 \n",
      " Validation: accuracy: 0.976562 loss: 0.801213\n",
      " cross_entropy: 0.275728, clust_cross_entropy: 0.459184, affinity: 0.00378737, balance: 0.196606, coact: 0.0147041, frob: 0.000244506\n",
      "step 15900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.826537 \n",
      " Validation: accuracy: 0.992188 loss: 0.810283\n",
      " cross_entropy: 0.223105, clust_cross_entropy: 0.414866, affinity: 0.00167587, balance: 0.146351, coact: 0.0111037, frob: 0.000254501\n",
      "step 16000/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.749453 \n",
      " Validation: accuracy: 1 loss: 0.646427\n",
      " cross_entropy: 0.245552, clust_cross_entropy: 0.351934, affinity: 0.00238632, balance: 0.134779, coact: 0.0186486, frob: 0.000239753\n",
      "step 16100/20000 \n",
      " Train: accuracy: 0.976562, loss: 1.06741 \n",
      " Validation: accuracy: 0.992188 loss: 0.770374\n",
      " cross_entropy: 0.184435, clust_cross_entropy: 0.664144, affinity: 0.00197945, balance: 0.183651, coact: 0.016774, frob: 0.00025417\n",
      "step 16200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.921139 \n",
      " Validation: accuracy: 0.96875 loss: 0.792425\n",
      " cross_entropy: 0.243957, clust_cross_entropy: 0.558174, affinity: 0.00205343, balance: 0.122683, coact: 0.0338287, frob: 0.00025235\n",
      "step 16300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.818484 \n",
      " Validation: accuracy: 0.984375 loss: 0.816144\n",
      " cross_entropy: 0.224914, clust_cross_entropy: 0.486237, affinity: 0.00177883, balance: 0.128891, coact: 0.0188579, frob: 0.000246466\n",
      "step 16400/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.800807 \n",
      " Validation: accuracy: 0.984375 loss: 0.826707\n",
      " cross_entropy: 0.314332, clust_cross_entropy: 0.302065, affinity: 0.00211803, balance: 0.149341, coact: 0.0140506, frob: 0.000244728\n",
      "step 16500/20000 \n",
      " Train: accuracy: 1, loss: 0.871771 \n",
      " Validation: accuracy: 0.976562 loss: 0.862515\n",
      " cross_entropy: 0.218745, clust_cross_entropy: 0.408443, affinity: 0.0033028, balance: 0.200878, coact: 0.0224921, frob: 0.000249961\n",
      "step 16600/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.1963 \n",
      " Validation: accuracy: 0.992188 loss: 0.660461\n",
      " cross_entropy: 0.251041, clust_cross_entropy: 0.68603, affinity: 0.00198316, balance: 0.124886, coact: 0.0128069, frob: 0.000248756\n",
      "step 16700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.81507 \n",
      " Validation: accuracy: 0.96875 loss: 0.764364\n",
      " cross_entropy: 0.230642, clust_cross_entropy: 0.465269, affinity: 0.00443603, balance: 0.138924, coact: 0.0147941, frob: 0.000259232\n",
      "step 16800/20000 \n",
      " Train: accuracy: 1, loss: 0.815719 \n",
      " Validation: accuracy: 0.984375 loss: 0.70913\n",
      " cross_entropy: 0.242593, clust_cross_entropy: 0.316956, affinity: 0.00507534, balance: 0.125155, coact: 0.0280168, frob: 0.000243806\n",
      "step 16900/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.08637 \n",
      " Validation: accuracy: 0.984375 loss: 0.672969\n",
      " cross_entropy: 0.268433, clust_cross_entropy: 0.596069, affinity: 0.0027922, balance: 0.167201, coact: 0.028451, frob: 0.000240899\n",
      "step 17000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.884247 \n",
      " Validation: accuracy: 0.960938 loss: 0.843969\n",
      " cross_entropy: 0.253177, clust_cross_entropy: 0.493099, affinity: 0.00304098, balance: 0.227701, coact: 0.0145033, frob: 0.000252581\n",
      "step 17100/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.04398 \n",
      " Validation: accuracy: 0.992188 loss: 0.635366\n",
      " cross_entropy: 0.237684, clust_cross_entropy: 0.575526, affinity: 0.00299516, balance: 0.197594, coact: 0.011282, frob: 0.000253924\n",
      "step 17200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.77742 \n",
      " Validation: accuracy: 0.976562 loss: 0.850751\n",
      " cross_entropy: 0.219317, clust_cross_entropy: 0.380688, affinity: 0.0020995, balance: 0.112481, coact: 0.0184512, frob: 0.000256938\n",
      "step 17300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.840761 \n",
      " Validation: accuracy: 0.992188 loss: 0.764997\n",
      " cross_entropy: 0.244611, clust_cross_entropy: 0.479775, affinity: 0.00313511, balance: 0.244049, coact: 0.0236178, frob: 0.000249568\n",
      "step 17400/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.06589 \n",
      " Validation: accuracy: 0.96875 loss: 0.859232\n",
      " cross_entropy: 0.209281, clust_cross_entropy: 0.656923, affinity: 0.00288155, balance: 0.104307, coact: 0.011006, frob: 0.000249389\n",
      "step 17500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.759114 \n",
      " Validation: accuracy: 0.953125 loss: 0.801035\n",
      " cross_entropy: 0.253645, clust_cross_entropy: 0.364104, affinity: 0.00172372, balance: 0.158929, coact: 0.01776, frob: 0.00024587\n",
      "step 17600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.771115 \n",
      " Validation: accuracy: 0.96875 loss: 0.813171\n",
      " cross_entropy: 0.218818, clust_cross_entropy: 0.454712, affinity: 0.00262432, balance: 0.179561, coact: 0.0106563, frob: 0.00024621\n",
      "step 17700/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.835561 \n",
      " Validation: accuracy: 0.984375 loss: 0.79007\n",
      " cross_entropy: 0.216545, clust_cross_entropy: 0.290753, affinity: 0.0029268, balance: 0.279166, coact: 0.00687195, frob: 0.00024603\n",
      "step 17800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.922889 \n",
      " Validation: accuracy: 0.976562 loss: 0.716223\n",
      " cross_entropy: 0.243422, clust_cross_entropy: 0.496472, affinity: 0.00221802, balance: 0.140679, coact: 0.0172655, frob: 0.000248449\n",
      "step 17900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.979608 \n",
      " Validation: accuracy: 1 loss: 0.719069\n",
      " cross_entropy: 0.226793, clust_cross_entropy: 0.556385, affinity: 0.00328606, balance: 0.221831, coact: 0.0273075, frob: 0.000258009\n",
      "step 18000/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.13771 \n",
      " Validation: accuracy: 1 loss: 0.848983\n",
      " cross_entropy: 0.247178, clust_cross_entropy: 0.589843, affinity: 0.00222234, balance: 0.164329, coact: 0.0164216, frob: 0.00025589\n",
      "step 18100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.878959 \n",
      " Validation: accuracy: 0.992188 loss: 0.776326\n",
      " cross_entropy: 0.265301, clust_cross_entropy: 0.509441, affinity: 0.0037275, balance: 0.126752, coact: 0.0108699, frob: 0.000250459\n",
      "step 18200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.714757 \n",
      " Validation: accuracy: 1 loss: 0.49636\n",
      " cross_entropy: 0.208328, clust_cross_entropy: 0.395958, affinity: 0.0024802, balance: 0.0919834, coact: 0.0200739, frob: 0.000259295\n",
      "step 18300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.994912 \n",
      " Validation: accuracy: 0.96875 loss: 0.688305\n",
      " cross_entropy: 0.232095, clust_cross_entropy: 0.644314, affinity: 0.00187898, balance: 0.164406, coact: 0.0144865, frob: 0.000251362\n",
      "step 18400/20000 \n",
      " Train: accuracy: 0.992188, loss: 1.09461 \n",
      " Validation: accuracy: 0.992188 loss: 0.618184\n",
      " cross_entropy: 0.293197, clust_cross_entropy: 0.560515, affinity: 0.00454545, balance: 0.203644, coact: 0.0184189, frob: 0.000242798\n",
      "step 18500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.846554 \n",
      " Validation: accuracy: 1 loss: 0.730595\n",
      " cross_entropy: 0.286301, clust_cross_entropy: 0.45694, affinity: 0.00360839, balance: 0.11863, coact: 0.0184921, frob: 0.000249694\n",
      "step 18600/20000 \n",
      " Train: accuracy: 1, loss: 0.927037 \n",
      " Validation: accuracy: 0.976562 loss: 0.63181\n",
      " cross_entropy: 0.212779, clust_cross_entropy: 0.467628, affinity: 0.00222317, balance: 0.156254, coact: 0.0172235, frob: 0.000249982\n",
      "step 18700/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.984286 \n",
      " Validation: accuracy: 0.945312 loss: 0.75765\n",
      " cross_entropy: 0.236683, clust_cross_entropy: 0.580771, affinity: 0.00149987, balance: 0.212508, coact: 0.00743459, frob: 0.000255279\n",
      "step 18800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.512395 \n",
      " Validation: accuracy: 0.992188 loss: 0.628951\n",
      " cross_entropy: 0.210674, clust_cross_entropy: 0.134145, affinity: 0.00408427, balance: 0.135405, coact: 0.0127331, frob: 0.000260682\n",
      "step 18900/20000 \n",
      " Train: accuracy: 0.984375, loss: 1.01189 \n",
      " Validation: accuracy: 0.984375 loss: 0.793375\n",
      " cross_entropy: 0.296393, clust_cross_entropy: 0.592651, affinity: 0.00285618, balance: 0.184864, coact: 0.023128, frob: 0.000248766\n",
      "step 19000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.79134 \n",
      " Validation: accuracy: 0.96875 loss: 0.86326\n",
      " cross_entropy: 0.230638, clust_cross_entropy: 0.312871, affinity: 0.00215197, balance: 0.168766, coact: 0.0181216, frob: 0.000241788\n",
      "step 19100/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.664824 \n",
      " Validation: accuracy: 1 loss: 0.754861\n",
      " cross_entropy: 0.188552, clust_cross_entropy: 0.48731, affinity: 0.00290674, balance: 0.137392, coact: 0.016123, frob: 0.000250348\n",
      "step 19200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.999246 \n",
      " Validation: accuracy: 0.992188 loss: 0.65772\n",
      " cross_entropy: 0.246183, clust_cross_entropy: 0.418741, affinity: 0.00182015, balance: 0.247479, coact: 0.00695662, frob: 0.000248761\n",
      "step 19300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.859914 \n",
      " Validation: accuracy: 1 loss: 0.670967\n",
      " cross_entropy: 0.229966, clust_cross_entropy: 0.421726, affinity: 0.00286653, balance: 0.140885, coact: 0.0191719, frob: 0.000257021\n",
      "step 19400/20000 \n",
      " Train: accuracy: 0.960938, loss: 1.20956 \n",
      " Validation: accuracy: 0.992188 loss: 0.694226\n",
      " cross_entropy: 0.2898, clust_cross_entropy: 0.770233, affinity: 0.00210369, balance: 0.145794, coact: 0.00958121, frob: 0.000243496\n",
      "step 19500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.846737 \n",
      " Validation: accuracy: 0.992188 loss: 0.829949\n",
      " cross_entropy: 0.315147, clust_cross_entropy: 0.356416, affinity: 0.00354856, balance: 0.128793, coact: 0.011172, frob: 0.000236272\n",
      "step 19600/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.861239 \n",
      " Validation: accuracy: 0.976562 loss: 0.884857\n",
      " cross_entropy: 0.246685, clust_cross_entropy: 0.473233, affinity: 0.00347643, balance: 0.127022, coact: 0.0120812, frob: 0.000255844\n",
      "step 19700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.804701 \n",
      " Validation: accuracy: 0.984375 loss: 0.832322\n",
      " cross_entropy: 0.267435, clust_cross_entropy: 0.269501, affinity: 0.00373032, balance: 0.200853, coact: 0.0125232, frob: 0.000248703\n",
      "step 19800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.978197 \n",
      " Validation: accuracy: 0.992188 loss: 0.826772\n",
      " cross_entropy: 0.259554, clust_cross_entropy: 0.530057, affinity: 0.0021322, balance: 0.0999275, coact: 0.0148892, frob: 0.000258841\n",
      "step 19900/20000 \n",
      " Train: accuracy: 1, loss: 1.03881 \n",
      " Validation: accuracy: 0.992188 loss: 0.757314\n",
      " cross_entropy: 0.250455, clust_cross_entropy: 0.535149, affinity: 0.00266439, balance: 0.184694, coact: 0.00934117, frob: 0.000248012\n"
     ]
    }
   ],
   "source": [
    "#STEP 2\n",
    "\n",
    "convy2 = y2\n",
    "totalSteps = 20000\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images, train_labels_clipped,_epochs_completed_train,_index_in_epoch_train)\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2], keep_prob:0.3})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, affinity: %g, balance: %g, coact: %g, frob: %g\"%(cc0*entr, cc5*entr2 ,cc1*hist['affinity'][-1],cc2*(1-hist['balance'][-1]),cc3*hist['coactivity'][-1],cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2], keep_prob:0.3}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: accuracy: 1, loss: 0.204403\n",
      "Test: accuracy: 0.984375, loss: 0.364431\n",
      "Test: accuracy: 0.984375, loss: 0.499556\n",
      "Test: accuracy: 0.984375, loss: 0.386514\n",
      "Test: accuracy: 0.992188, loss: 0.32038\n",
      "Test: accuracy: 0.992188, loss: 0.218507\n",
      "Test: accuracy: 0.984375, loss: 0.249786\n",
      "Test: accuracy: 1, loss: 0.19006\n",
      "Test: accuracy: 1, loss: 0.316847\n",
      "Test: accuracy: 0.992188, loss: 0.400686\n",
      "Test: accuracy: 0.984375, loss: 0.291195\n",
      "Test: accuracy: 1, loss: 0.34554\n",
      "Test: accuracy: 0.992188, loss: 0.326866\n",
      "Test: accuracy: 0.984375, loss: 0.429394\n",
      "Test: accuracy: 0.992188, loss: 0.284437\n",
      "Test: accuracy: 0.992188, loss: 0.412961\n",
      "Test: accuracy: 1, loss: 0.168777\n",
      "Test: accuracy: 1, loss: 0.212099\n",
      "Test: accuracy: 0.992188, loss: 0.190638\n",
      "Test: accuracy: 0.96875, loss: 0.293299\n",
      "Test: accuracy: 1, loss: 0.350169\n",
      "Test: accuracy: 0.992188, loss: 0.403076\n",
      "Test: accuracy: 0.976562, loss: 0.310627\n",
      "Test: accuracy: 0.992188, loss: 0.313449\n",
      "Test: accuracy: 0.984375, loss: 0.314437\n",
      "Test: accuracy: 0.992188, loss: 0.366838\n",
      "Test: accuracy: 0.976562, loss: 0.235682\n",
      "Test: accuracy: 1, loss: 0.188122\n",
      "Test: accuracy: 1, loss: 0.317768\n",
      "Test: accuracy: 1, loss: 0.258354\n",
      "Test: accuracy: 0.992188, loss: 0.221936\n",
      "Test: accuracy: 0.992188, loss: 0.323751\n",
      "Test: accuracy: 1, loss: 0.346684\n",
      "Test: accuracy: 1, loss: 0.250258\n",
      "Test: accuracy: 0.976562, loss: 0.380722\n",
      "Test: accuracy: 0.984375, loss: 0.383964\n",
      "Test: accuracy: 0.992188, loss: 0.347925\n",
      "Test: accuracy: 0.992188, loss: 0.366813\n",
      "Test: accuracy: 0.992188, loss: 0.387603\n",
      "Test: accuracy: 0.984375, loss: 0.250793\n",
      "Test: accuracy: 0.984375, loss: 0.245674\n",
      "Test: accuracy: 0.984375, loss: 0.294226\n",
      "Test: accuracy: 0.992188, loss: 0.289502\n",
      "Test: accuracy: 0.992188, loss: 0.332146\n",
      "Test: accuracy: 1, loss: 0.244382\n",
      "Test: accuracy: 1, loss: 0.328772\n",
      "Test: accuracy: 1, loss: 0.307814\n",
      "Test: accuracy: 0.992188, loss: 0.344549\n",
      "Test: accuracy: 0.984375, loss: 0.30485\n",
      "Test: accuracy: 0.976562, loss: 0.328289\n",
      "Test: accuracy: 0.976562, loss: 0.372477\n",
      "Test: accuracy: 1, loss: 0.360224\n",
      "Test: accuracy: 0.984375, loss: 0.227935\n",
      "Test: accuracy: 1, loss: 0.381913\n",
      "Test: accuracy: 0.984375, loss: 0.463677\n",
      "Test: accuracy: 1, loss: 0.190689\n",
      "Test: accuracy: 0.984375, loss: 0.455174\n",
      "Test: accuracy: 0.992188, loss: 0.393438\n",
      "Test: accuracy: 1, loss: 0.278911\n",
      "Test: accuracy: 0.992188, loss: 0.425105\n",
      "Test: accuracy: 1, loss: 0.508604\n",
      "Test: accuracy: 0.992188, loss: 0.313539\n",
      "Test: accuracy: 1, loss: 0.194669\n",
      "Test: accuracy: 0.984375, loss: 0.260432\n",
      "Test: accuracy: 0.984375, loss: 0.399365\n",
      "Test: accuracy: 0.984375, loss: 0.308004\n",
      "Test: accuracy: 0.976562, loss: 0.262444\n",
      "Test: accuracy: 0.992188, loss: 0.26782\n",
      "Test: accuracy: 1, loss: 0.326199\n",
      "Test: accuracy: 0.984375, loss: 0.349616\n",
      "Test: accuracy: 0.992188, loss: 0.250548\n",
      "Test: accuracy: 0.992188, loss: 0.377747\n",
      "Test: accuracy: 0.992188, loss: 0.181672\n",
      "Test: accuracy: 1, loss: 0.267609\n",
      "Test: accuracy: 0.984375, loss: 0.394569\n",
      "Test: accuracy: 0.976562, loss: 0.284943\n",
      "Test: accuracy: 1, loss: 0.313709\n",
      "Test: accuracy: 0.984375, loss: 0.275339\n",
      "Test: accuracy: 1, loss: 0.255842\n",
      "Test: accuracy: 0.992188, loss: 0.310334\n",
      "Test: accuracy: 1, loss: 0.293272\n",
      "Test: accuracy: 1, loss: 0.329293\n",
      "Test: accuracy: 1, loss: 0.242214\n",
      "Test: accuracy: 0.976562, loss: 0.346959\n",
      "Test: accuracy: 1, loss: 0.325041\n",
      "Test: accuracy: 0.992188, loss: 0.215357\n",
      "Test: accuracy: 0.984375, loss: 0.312213\n",
      "Test: accuracy: 0.984375, loss: 0.303245\n",
      "Test: accuracy: 1, loss: 0.222914\n",
      "Test: accuracy: 0.984375, loss: 0.351602\n",
      "Test: accuracy: 0.992188, loss: 0.286216\n",
      "Test: accuracy: 0.976562, loss: 0.317881\n",
      "Test: accuracy: 0.976562, loss: 0.603073\n",
      "Test: accuracy: 1, loss: 0.241455\n",
      "Test: accuracy: 0.992188, loss: 0.312057\n",
      "Test: accuracy: 0.992188, loss: 0.316964\n",
      "Test: accuracy: 0.992188, loss: 0.235973\n",
      "Test: accuracy: 0.992188, loss: 0.340899\n",
      "Test: accuracy: 0.984375, loss: 0.216883\n",
      "Test: accuracy: 0.992188, loss: 0.401503\n",
      "0.990859\n"
     ]
    }
   ],
   "source": [
    "tAcc = []\n",
    "testSize = 1000\n",
    "for i in range(100):\n",
    "    testbatch = next_batch(batchSize,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "\n",
    "    test_loss,test_acc = sess.run([loss,accuracy],{x: testbatch[0], y_: testbatch[1], y2_: testbatch[2], keep_prob:1.0})\n",
    "    tAcc.append(test_acc)\n",
    "    print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))\n",
    "print np.average(tAcc)\n",
    "testAcc = np.average(tAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd168748cd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAANSCAYAAAD23iayAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkoppZRSmdj/AcOggVKQVQkWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0e3fa1b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy and loss\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(211)\n",
    "plt.plot(hist['train_acc'],'-b',label='train_acc')\n",
    "plt.plot(hist['val_acc'],'-r',label='val_acc')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['val_loss'],'-r',label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0f0229fd0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAGfCAYAAAAHwBxKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0f01bf050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "#plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['affinity'],'-r',label='affinity')\n",
    "plt.plot(np.subtract(1,hist['balance']),'-y',label='balance')\n",
    "plt.plot(hist['coactivity'],'-g',label='coactivity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digitTrace = np.zeros((classCount*clustCount,784))\n",
    "digitTraceCount = np.zeros((classCount*clustCount))\n",
    "digitCount = np.zeros(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "for i in range(4000):\n",
    "    testbatch = next_batch(1,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "    lbl = testbatch[2].ravel()\n",
    "    digitCount[np.argmax(lbl)]+=1\n",
    "    smMat, acc = sess.run([softmaxMat,accuracy],feed_dict={x: testbatch[0], y_: testbatch[1], y2_:testbatch[2], keep_prob:1.0})\n",
    "    ypred = softmaxMat.eval({x: testbatch[0], y_: testbatch[1], y2_:testbatch[2], keep_prob:1.0})\n",
    "    ypred.reshape(20)\n",
    "    digitTrace[np.argmax(ypred),:] += testbatch[0].ravel()\n",
    "    digitTraceCount[np.argmax(ypred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 174.  256.  184.  179.  191.  181.  192.  219.  208.  191.  188.  239.\n",
      "  241.  212.  183.  168.  192.  230.  164.  208.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.]\n",
      "[ 180.  264.  178.  182.  192.  182.  191.  214.  205.  189.  194.  235.\n",
      "  239.  216.  182.  171.  185.  225.  170.  206.]\n"
     ]
    }
   ],
   "source": [
    "print(digitCount)\n",
    "print(digitTraceCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAC4CAYAAAAR8SaJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0e3d5e0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stepCount = len(hist['train_acc'])*100\n",
    "with open('./trainlog.txt','ab') as f:\n",
    "    f.write('lr: %g, batchsize: %i, steps: %i, thresh: %g, c1: %g, c2: %g, c3: %g, c4: %g, test_acc: %g, test_loss: %g\\n'%\n",
    "            (lr,batchSize,stepCount,tresh.eval(), cc1, cc2, cc3, cc4, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "Clustering Accuracy: 0.9675\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "(10000, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "testbatch = next_batch(10000,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "lbls = testbatch[2].reshape(10000,20)\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1],y2_:testbatch[2], keep_prob:1.0}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((testbatch[0].shape[0],clustCount*classCount))\n",
    "print(np.argmax(ypred,1).shape)\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(testbatch[2][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(lbls,1).astype('int32'))\n",
    "clustAcc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(clustAcc))\n",
    "print(ylookup)\n",
    "print(testbatch[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy: 0.9772\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "testbatch = next_batch(10000,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "lbls = testbatch[2].reshape(10000,20)\n",
    "selection = np.argmax(lbls,1)<10\n",
    "testFeed = {x: testbatch[0][selection], y_: testbatch[1][selection],y2_:testbatch[2][selection], keep_prob:1.0}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred[:,0]\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum((testbatch[2][selection])[ypred==i],0)).astype('int32') for i in range(clustCount)] #*classCount\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(lbls[selection],1).astype('int32'))\n",
    "clustAccOfficial = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(clustAccOfficial))\n",
    "print(ylookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notify(\"Superclass: %g \\nSubclass total: %g \\nSubclass unflipped only: %g\"%(testAcc,clustAcc,clustAccOfficial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it to k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7d9304e2606c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtb0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#<5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkm0_ypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tb' is not defined"
     ]
    }
   ],
   "source": [
    "tb0 = [tb[0][np.argmax(tb[1],1)<5],tb[1][np.argmax(tb[1],1)<5]]\n",
    "tb1 = [tb[0][np.argmax(tb[1],1)>4],tb[1][np.argmax(tb[1],1)>4]]\n",
    "#<5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km0_ypred = kmeans.fit_transform(tb0[0])\n",
    "km0_ypred = np.argmax(km0_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb0[1][km0_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km0_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb0[1],1).astype('int32'))\n",
    "km0_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "#>4\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km1_ypred = kmeans.fit_transform(tb1[0])\n",
    "km1_ypred = np.argmax(km1_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb1[1][km1_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km1_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb1[1],1).astype('int32'))\n",
    "km1_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "print('ACOL Accuracy: %g'%(accuracy))\n",
    "print('KMeans Accuracy: %g'%((km0_accuracy+km1_accuracy)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualise kmeans\n",
    "digitTrace = np.concatenate([[np.sum(tb0[0][km0_ypred==i,:],axis=0) for i in range(clustCount)],\n",
    "                       [np.sum(tb1[0][km1_ypred==i,:],axis=0) for i in range(clustCount)]])\n",
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = next_batch(2,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ims = t[0].reshape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(ims[0])\n",
    "print t[1][0]\n",
    "print t[2][0]\n",
    "plt.figure()\n",
    "plt.imshow(ims[1])\n",
    "print t[1][1]\n",
    "print t[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = [slice(None)] * 3\n",
    "indexer[1] = slice(None, None, -1)\n",
    "t[2][tuple(indexer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
