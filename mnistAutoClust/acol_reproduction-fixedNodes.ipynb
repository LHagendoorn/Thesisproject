{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACOL replication tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from notifiers import notify\n",
    "#imports and settings:\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from jupyterthemes import jtplot\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import threshold\n",
    "#jtplot.style()\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustCount = 5\n",
    "classCount = 2\n",
    "net = 0\n",
    "trainsteps = 50000\n",
    "#trainsteps = 30000\n",
    "perc = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper funcs\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def matrix_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    return tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "\n",
    "def avg_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_sum(totalSoft,2)\n",
    "\n",
    "def max_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_max(totalSoft,2)\n",
    "\n",
    "def initACOL(in_size,clust,clss):\n",
    "    acolLayers = []\n",
    "    for i in range(clss):\n",
    "        acolLayers.append([\n",
    "            weight_variable([in_size, clustCount]),\n",
    "            bias_variable([clustCount])\n",
    "        ])\n",
    "    return acolLayers\n",
    "        \n",
    "def connectACOL(inLayer,acol):\n",
    "    clust = []\n",
    "    for l in range(0,len(acol)):\n",
    "        clust.append(tf.matmul(inLayer, acol[l][0]) + acol[l][1])\n",
    "    return clust\n",
    "        \n",
    "def acol(input,clust_count, class_count):\n",
    "    acolLayers = []\n",
    "    for i in range(class_count):\n",
    "        if isinstance(input, tuple):\n",
    "                input = input[0]\n",
    "\n",
    "        #I don't know what this bit does, but I don't think it'll hurt anything\n",
    "        #Or maybe it does, who knows\n",
    "        input_shape = input.get_shape()\n",
    "        if input_shape.ndims == 4:\n",
    "            dim = 1\n",
    "            for d in input_shape[1:].as_list():\n",
    "                dim *= d\n",
    "        #    feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n",
    "        else:\n",
    "            feed_in, dim = (input, int(input_shape[-1]))\n",
    "\n",
    "        init_weights = tf.truncated_normal_initializer(0.0, stddev=0.1)#(0.0, stddev=0.01)\n",
    "        init_biases = tf.constant_initializer(1.0)#(0.1)\n",
    "\n",
    "        weights = weight_variable([dim, clust_count])\n",
    "        biases = bias_variable([clust_count])\n",
    "\n",
    "        acoll = tf.nn.xw_plus_b(input,weights,biases)\n",
    "        acolLayers.append(acol)\n",
    "    return acolLayers    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders (weights&biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    acol = initACOL(1024,clustCount,classCount)\n",
    "\n",
    "    #final fc layer\n",
    "    W_fc2 = weight_variable([1024, classCount])\n",
    "    b_fc2 = bias_variable([classCount])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    dropout=0.3\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    l_pool1 = max_pool_2x2(l_conv1)\n",
    "\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_pool1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_pool2, [-1, 7*7*64])\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(dropout))\n",
    "\n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([3,3,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([3,3,32,32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "\n",
    "    #conv_layer3\n",
    "    W_conv3 = weight_variable([3,3,32,64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "\n",
    "    #conv_layer4\n",
    "    W_conv4 = weight_variable([3,3,64,64])\n",
    "    b_conv4 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    #acol = initACOL(2048,clustCount,classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_conv1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    l_drop1 = tf.nn.dropout(l_pool2, tf.constant(0.25))\n",
    "\n",
    "    #conv 3\n",
    "    l_conv3 = tf.nn.relu(conv2d(l_drop1, W_conv3) + b_conv3)\n",
    "    #conv 4\n",
    "    l_conv4 = tf.nn.relu(conv2d(l_conv3, W_conv4) + b_conv4)\n",
    "    l_pool4 = max_pool_2x2(l_conv4)\n",
    "\n",
    "    l_drop2 = tf.nn.dropout(l_pool4, tf.constant(0.25))\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_drop2, [-1, 7*7*64])\n",
    "\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(0.5))\n",
    "    \n",
    "    #l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    l_acol = acol(l_fc1_drop,clustCount, classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper loss funcs\n",
    "def zBar(x):\n",
    "    xshape = x.shape.as_list()\n",
    "    s=[-1,xshape[1]*xshape[2]]\n",
    "    return tf.maximum(tf.reshape(x,s),0)\n",
    "    \n",
    "def bigU(zb):\n",
    "    return tf.matmul(tf.transpose(zb),zb)\n",
    "\n",
    "def selectNonDiag(x):\n",
    "    selection = np.ones(x.shape.as_list()[0],dtype='float32') - np.eye(x.shape.as_list()[0],dtype='float32')\n",
    "    return tf.reduce_sum(tf.multiply(x,selection))\n",
    "\n",
    "def bigV(x):\n",
    "    smallNu=tf.reshape(tf.reduce_sum(x,axis=0),[1,-1])\n",
    "    return tf.multiply(tf.transpose(smallNu),smallNu)\n",
    "\n",
    "def specialNormalise(x):\n",
    "    top = selectNonDiag(x)\n",
    "    bottom = tf.multiply(tf.to_float(x.shape[1]-1),tf.reduce_sum(tf.multiply(x,np.eye(x.shape[1],dtype='float32'))))\n",
    "    return tf.divide(top,bottom)\n",
    "\n",
    "def frobNorm(x):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "\n",
    "tresh = tf.constant(0.03)\n",
    "cc0=1.0\n",
    "cc1=1.0\n",
    "cc2=1.0\n",
    "cc3=0.0003\n",
    "cc4=0.000001\n",
    "cc5=1.0\n",
    "c0 = tf.constant(cc0)\n",
    "c1 = tf.constant(cc1)\n",
    "c2 = tf.constant(cc2)\n",
    "c3val = tf.constant(cc3)\n",
    "c3 = lambda affinity: tf.cond(tf.less(affinity,tresh),lambda: c3val,lambda: tf.constant(0.0))\n",
    "c4 =tf.constant(cc4)\n",
    "c5 = tf.constant(cc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate losses\n",
    "#affinity\n",
    "bZ = zBar(stackedClusts)#softmaxMat)\n",
    "bU = bigU(bZ)\n",
    "coact = selectNonDiag(bU)\n",
    "affinity = specialNormalise(bU)\n",
    "\n",
    "#balance\n",
    "bV=bigV(bZ)\n",
    "balance = specialNormalise(bV)\n",
    "\n",
    "#cluster cross entropy (added if secondary label is set for that input, hard to do with batches?)\n",
    "clust_cross_entropy = tf.reduce_mean(-tf.reduce_sum(y2_ * tf.log(tf.clip_by_value(softmaxMat,1e-10,1.0)), reduction_indices=[1,2]))\n",
    "\n",
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))\n",
    "\n",
    "frob = frobNorm(stackedClusts)#softmaxMat)\n",
    "\n",
    "loss = c0*cross_entropy + c5*clust_cross_entropy + c1*affinity + c2*tf.subtract(tf.constant(1.0),balance) + c3(affinity)*coact + c4*frob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y = {0:[0,1], 1:[1,0]}\n",
    "y = {0:[1,0,0,0,0],\n",
    "     1:[1,0,0,0,0],\n",
    "     2:[0,1,0,0,0],\n",
    "     3:[0,1,0,0,0],\n",
    "     4:[0,0,1,0,0],\n",
    "     5:[0,0,1,0,0],\n",
    "     6:[0,0,0,1,0],\n",
    "     7:[0,0,0,1,0],\n",
    "     8:[0,0,0,0,1],\n",
    "     9:[0,0,0,0,1]}\n",
    "\n",
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][1,0] = 1\n",
    "y2[6][1,1] = 1\n",
    "y2[7][1,2] = 1\n",
    "y2[8][1,3] = 1\n",
    "y2[9][1,4] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "totalSteps = trainsteps\n",
    "stepCount=0\n",
    "batchSize = 128\n",
    "hist = {\n",
    "    'train_acc':[],\n",
    "    'val_acc':[],\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'affinity':[],\n",
    "    'balance':[],\n",
    "    'coactivity':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "step 0/50000 \n",
      " Train: accuracy: 0.507812, loss: 20.3852 \n",
      " Validation: accuracy: 0.53125 loss: 19.0112\n",
      " cross_entropy: 4.61811, clust_cross_entropy: 15.6266, affinity: 0.302045, balance: 0.275938, coact: 61.5733, frob: 0.000416031\n",
      "step 100/50000 \n",
      " Train: accuracy: 0.492188, loss: 15.1888 \n",
      " Validation: accuracy: 0.585938 loss: 15.9642\n",
      " cross_entropy: 2.49402, clust_cross_entropy: 12.9221, affinity: 0.278256, balance: 0.0287163, coact: 28.5, frob: 0.000296874\n",
      "step 200/50000 \n",
      " Train: accuracy: 0.46875, loss: 10.8558 \n",
      " Validation: accuracy: 0.523438 loss: 11.9184\n",
      " cross_entropy: 1.93255, clust_cross_entropy: 8.51456, affinity: 0.2819, balance: 0.0347903, coact: 13.2807, frob: 0.000239322\n",
      "step 300/50000 \n",
      " Train: accuracy: 0.484375, loss: 8.4551 \n",
      " Validation: accuracy: 0.5625 loss: 9.27991\n",
      " cross_entropy: 1.61012, clust_cross_entropy: 5.65447, affinity: 0.232758, balance: 0.0255228, coact: 10.6941, frob: 0.000219539\n",
      "step 400/50000 \n",
      " Train: accuracy: 0.664062, loss: 6.10864 \n",
      " Validation: accuracy: 0.679688 loss: 5.08333\n",
      " cross_entropy: 1.37396, clust_cross_entropy: 5.03038, affinity: 0.230616, balance: 0.0213981, coact: 6.32644, frob: 0.000187604\n",
      "step 500/50000 \n",
      " Train: accuracy: 0.59375, loss: 4.7558 \n",
      " Validation: accuracy: 0.671875 loss: 3.77487\n",
      " cross_entropy: 1.45569, clust_cross_entropy: 3.15361, affinity: 0.216624, balance: 0.0133523, coact: 4.39444, frob: 0.000172068\n",
      "step 600/50000 \n",
      " Train: accuracy: 0.703125, loss: 3.40722 \n",
      " Validation: accuracy: 0.765625 loss: 3.50928\n",
      " cross_entropy: 1.13388, clust_cross_entropy: 2.46836, affinity: 0.172849, balance: 0.0359374, coact: 3.88426, frob: 0.000162725\n",
      "step 700/50000 \n",
      " Train: accuracy: 0.734375, loss: 3.25372 \n",
      " Validation: accuracy: 0.804688 loss: 2.59966\n",
      " cross_entropy: 1.13355, clust_cross_entropy: 2.4848, affinity: 0.177201, balance: 0.0135139, coact: 2.69639, frob: 0.000152098\n",
      "step 800/50000 \n",
      " Train: accuracy: 0.804688, loss: 2.46602 \n",
      " Validation: accuracy: 0.765625 loss: 2.78328\n",
      " cross_entropy: 0.705575, clust_cross_entropy: 1.73935, affinity: 0.145655, balance: 0.0282767, coact: 2.21508, frob: 0.000155051\n",
      "step 900/50000 \n",
      " Train: accuracy: 0.820312, loss: 2.1466 \n",
      " Validation: accuracy: 0.765625 loss: 2.35933\n",
      " cross_entropy: 0.533982, clust_cross_entropy: 1.32914, affinity: 0.138334, balance: 0.0460728, coact: 2.41099, frob: 0.000143865\n",
      "step 1000/50000 \n",
      " Train: accuracy: 0.789062, loss: 1.96856 \n",
      " Validation: accuracy: 0.820312 loss: 1.81098\n",
      " cross_entropy: 0.68533, clust_cross_entropy: 1.1028, affinity: 0.137048, balance: 0.0262766, coact: 1.62544, frob: 0.000139868\n",
      "step 1100/50000 \n",
      " Train: accuracy: 0.859375, loss: 1.87489 \n",
      " Validation: accuracy: 0.828125 loss: 1.90352\n",
      " cross_entropy: 0.576702, clust_cross_entropy: 0.996452, affinity: 0.146341, balance: 0.0694148, coact: 2.10526, frob: 0.000139937\n",
      "step 1200/50000 \n",
      " Train: accuracy: 0.796875, loss: 2.05676 \n",
      " Validation: accuracy: 0.851562 loss: 1.36724\n",
      " cross_entropy: 0.548718, clust_cross_entropy: 1.1548, affinity: 0.14112, balance: 0.0541457, coact: 2.02806, frob: 0.000138873\n",
      "step 1300/50000 \n",
      " Train: accuracy: 0.828125, loss: 1.67541 \n",
      " Validation: accuracy: 0.859375 loss: 1.8487\n",
      " cross_entropy: 0.480406, clust_cross_entropy: 1.20422, affinity: 0.119816, balance: 0.0343561, coact: 1.40616, frob: 0.000138422\n",
      "step 1400/50000 \n",
      " Train: accuracy: 0.890625, loss: 1.42821 \n",
      " Validation: accuracy: 0.898438 loss: 1.59313\n",
      " cross_entropy: 0.560081, clust_cross_entropy: 0.891743, affinity: 0.129956, balance: 0.0413966, coact: 2.09923, frob: 0.000137878\n",
      "step 1500/50000 \n",
      " Train: accuracy: 0.859375, loss: 1.38352 \n",
      " Validation: accuracy: 0.796875 loss: 1.92715\n",
      " cross_entropy: 0.382332, clust_cross_entropy: 0.831124, affinity: 0.104074, balance: 0.0203549, coact: 1.57717, frob: 0.000131953\n",
      "step 1600/50000 \n",
      " Train: accuracy: 0.882812, loss: 1.37816 \n",
      " Validation: accuracy: 0.875 loss: 1.21796\n",
      " cross_entropy: 0.365921, clust_cross_entropy: 0.710889, affinity: 0.109963, balance: 0.080961, coact: 1.79421, frob: 0.000138403\n",
      "step 1700/50000 \n",
      " Train: accuracy: 0.882812, loss: 1.13831 \n",
      " Validation: accuracy: 0.859375 loss: 1.2932\n",
      " cross_entropy: 0.509517, clust_cross_entropy: 0.540502, affinity: 0.100087, balance: 0.0104669, coact: 1.43842, frob: 0.000132916\n",
      "step 1800/50000 \n",
      " Train: accuracy: 0.890625, loss: 1.36753 \n",
      " Validation: accuracy: 0.898438 loss: 1.0123\n",
      " cross_entropy: 0.350307, clust_cross_entropy: 0.792424, affinity: 0.100419, balance: 0.0429578, coact: 1.34358, frob: 0.000131499\n",
      "step 1900/50000 \n",
      " Train: accuracy: 0.914062, loss: 1.04046 \n",
      " Validation: accuracy: 0.875 loss: 1.22119\n",
      " cross_entropy: 0.323828, clust_cross_entropy: 0.576184, affinity: 0.110305, balance: 0.0525975, coact: 1.38453, frob: 0.000137286\n",
      "step 2000/50000 \n",
      " Train: accuracy: 0.867188, loss: 1.18286 \n",
      " Validation: accuracy: 0.945312 loss: 0.990912\n",
      " cross_entropy: 0.373791, clust_cross_entropy: 0.511839, affinity: 0.0920162, balance: 0.0438036, coact: 1.35106, frob: 0.000133773\n",
      "step 2100/50000 \n",
      " Train: accuracy: 0.875, loss: 1.40797 \n",
      " Validation: accuracy: 0.9375 loss: 0.783203\n",
      " cross_entropy: 0.410703, clust_cross_entropy: 0.621577, affinity: 0.103778, balance: 0.0736827, coact: 1.36724, frob: 0.000132614\n",
      "step 2200/50000 \n",
      " Train: accuracy: 0.882812, loss: 0.998447 \n",
      " Validation: accuracy: 0.914062 loss: 0.921726\n",
      " cross_entropy: 0.32923, clust_cross_entropy: 0.423513, affinity: 0.092253, balance: 0.0552602, coact: 1.30557, frob: 0.000140336\n",
      "step 2300/50000 \n",
      " Train: accuracy: 0.929688, loss: 1.02451 \n",
      " Validation: accuracy: 0.882812 loss: 1.0526\n",
      " cross_entropy: 0.433888, clust_cross_entropy: 0.561707, affinity: 0.0814578, balance: 0.0585548, coact: 1.57944, frob: 0.000138771\n",
      "step 2400/50000 \n",
      " Train: accuracy: 0.914062, loss: 0.909229 \n",
      " Validation: accuracy: 0.914062 loss: 1.05292\n",
      " cross_entropy: 0.318361, clust_cross_entropy: 0.580117, affinity: 0.0941665, balance: 0.0240383, coact: 1.37076, frob: 0.000136753\n",
      "step 2500/50000 \n",
      " Train: accuracy: 0.859375, loss: 1.05024 \n",
      " Validation: accuracy: 0.921875 loss: 0.845505\n",
      " cross_entropy: 0.353873, clust_cross_entropy: 0.456032, affinity: 0.0817043, balance: 0.0271004, coact: 1.57341, frob: 0.00013715\n",
      "step 2600/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.803863 \n",
      " Validation: accuracy: 0.9375 loss: 1.00116\n",
      " cross_entropy: 0.250691, clust_cross_entropy: 0.34433, affinity: 0.0718676, balance: 0.0478163, coact: 1.19903, frob: 0.000137278\n",
      "step 2700/50000 \n",
      " Train: accuracy: 0.890625, loss: 1.1382 \n",
      " Validation: accuracy: 0.960938 loss: 0.917393\n",
      " cross_entropy: 0.289365, clust_cross_entropy: 0.525742, affinity: 0.0856363, balance: 0.0420888, coact: 1.25746, frob: 0.00014444\n",
      "step 2800/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.896144 \n",
      " Validation: accuracy: 0.914062 loss: 0.881\n",
      " cross_entropy: 0.390404, clust_cross_entropy: 0.545812, affinity: 0.083078, balance: 0.0245837, coact: 1.21334, frob: 0.000136832\n",
      "step 2900/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.855476 \n",
      " Validation: accuracy: 0.867188 loss: 1.08535\n",
      " cross_entropy: 0.289069, clust_cross_entropy: 0.63995, affinity: 0.0750397, balance: 0.0569564, coact: 1.4085, frob: 0.000150092\n",
      "step 3000/50000 \n",
      " Train: accuracy: 0.90625, loss: 0.919988 \n",
      " Validation: accuracy: 0.914062 loss: 0.912004\n",
      " cross_entropy: 0.296449, clust_cross_entropy: 0.291595, affinity: 0.0883339, balance: 0.0368972, coact: 1.60948, frob: 0.000143865\n",
      "step 3100/50000 \n",
      " Train: accuracy: 0.914062, loss: 1.09503 \n",
      " Validation: accuracy: 0.914062 loss: 1.14601\n",
      " cross_entropy: 0.260395, clust_cross_entropy: 0.741666, affinity: 0.0668243, balance: 0.0413775, coact: 1.39896, frob: 0.000141544\n",
      "step 3200/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.847018 \n",
      " Validation: accuracy: 0.945312 loss: 0.685904\n",
      " cross_entropy: 0.349651, clust_cross_entropy: 0.471557, affinity: 0.0769283, balance: 0.0297559, coact: 1.2154, frob: 0.000143996\n",
      "step 3300/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.757438 \n",
      " Validation: accuracy: 0.898438 loss: 1.05665\n",
      " cross_entropy: 0.241811, clust_cross_entropy: 0.548778, affinity: 0.072777, balance: 0.0523963, coact: 1.21075, frob: 0.000146395\n",
      "step 3400/50000 \n",
      " Train: accuracy: 0.890625, loss: 0.880749 \n",
      " Validation: accuracy: 0.914062 loss: 0.839413\n",
      " cross_entropy: 0.352391, clust_cross_entropy: 0.451577, affinity: 0.0814229, balance: 0.0316421, coact: 1.49168, frob: 0.000139245\n",
      "step 3500/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.82994 \n",
      " Validation: accuracy: 0.9375 loss: 0.928926\n",
      " cross_entropy: 0.202826, clust_cross_entropy: 0.478623, affinity: 0.0691737, balance: 0.0431031, coact: 1.45742, frob: 0.000150163\n",
      "step 3600/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.806626 \n",
      " Validation: accuracy: 0.929688 loss: 0.82973\n",
      " cross_entropy: 0.315697, clust_cross_entropy: 0.316182, affinity: 0.0671708, balance: 0.0469636, coact: 1.34803, frob: 0.000145329\n",
      "step 3700/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.838979 \n",
      " Validation: accuracy: 0.929688 loss: 0.563802\n",
      " cross_entropy: 0.319645, clust_cross_entropy: 0.477442, affinity: 0.0738882, balance: 0.135299, coact: 1.32283, frob: 0.000150409\n",
      "step 3800/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.690618 \n",
      " Validation: accuracy: 0.890625 loss: 1.09293\n",
      " cross_entropy: 0.244391, clust_cross_entropy: 0.374898, affinity: 0.0799066, balance: 0.0620069, coact: 1.46449, frob: 0.000147138\n",
      "step 3900/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.678611 \n",
      " Validation: accuracy: 0.953125 loss: 0.782885\n",
      " cross_entropy: 0.180845, clust_cross_entropy: 0.333388, affinity: 0.0652414, balance: 0.0682513, coact: 1.27922, frob: 0.000149967\n",
      "step 4000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.704054 \n",
      " Validation: accuracy: 0.890625 loss: 1.09336\n",
      " cross_entropy: 0.170273, clust_cross_entropy: 0.435533, affinity: 0.0684952, balance: 0.0256914, coact: 1.25573, frob: 0.000146994\n",
      "step 4100/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.584236 \n",
      " Validation: accuracy: 0.9375 loss: 0.757357\n",
      " cross_entropy: 0.244728, clust_cross_entropy: 0.334099, affinity: 0.0659399, balance: 0.0588002, coact: 1.20859, frob: 0.00015493\n",
      "step 4200/50000 \n",
      " Train: accuracy: 0.90625, loss: 0.825819 \n",
      " Validation: accuracy: 0.90625 loss: 0.81872\n",
      " cross_entropy: 0.279957, clust_cross_entropy: 0.342386, affinity: 0.0707506, balance: 0.062582, coact: 1.36892, frob: 0.000153133\n",
      "step 4300/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.665475 \n",
      " Validation: accuracy: 0.9375 loss: 0.657147\n",
      " cross_entropy: 0.168372, clust_cross_entropy: 0.314835, affinity: 0.0720513, balance: 0.0397421, coact: 1.35051, frob: 0.000152151\n",
      "step 4400/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.680476 \n",
      " Validation: accuracy: 0.929688 loss: 0.698803\n",
      " cross_entropy: 0.105193, clust_cross_entropy: 0.413323, affinity: 0.0714458, balance: 0.0282533, coact: 1.25163, frob: 0.000150399\n",
      "step 4500/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.811741 \n",
      " Validation: accuracy: 0.9375 loss: 0.673065\n",
      " cross_entropy: 0.225484, clust_cross_entropy: 0.45334, affinity: 0.0651588, balance: 0.0427703, coact: 1.21409, frob: 0.000151825\n",
      "step 4600/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.600053 \n",
      " Validation: accuracy: 0.960938 loss: 0.472519\n",
      " cross_entropy: 0.218909, clust_cross_entropy: 0.338285, affinity: 0.0628263, balance: 0.0500108, coact: 1.42585, frob: 0.000150236\n",
      "step 4700/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.804794 \n",
      " Validation: accuracy: 0.953125 loss: 0.661794\n",
      " cross_entropy: 0.244125, clust_cross_entropy: 0.305282, affinity: 0.079119, balance: 0.0312616, coact: 1.31195, frob: 0.00014947\n",
      "step 4800/50000 \n",
      " Train: accuracy: 0.921875, loss: 0.835962 \n",
      " Validation: accuracy: 0.984375 loss: 0.397881\n",
      " cross_entropy: 0.31978, clust_cross_entropy: 0.330952, affinity: 0.0651607, balance: 0.0314339, coact: 1.3055, frob: 0.00015373\n",
      "step 4900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.55781 \n",
      " Validation: accuracy: 0.921875 loss: 0.74022\n",
      " cross_entropy: 0.2413, clust_cross_entropy: 0.25563, affinity: 0.0708334, balance: 0.0603667, coact: 1.40223, frob: 0.000157845\n",
      "step 5000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.7737 \n",
      " Validation: accuracy: 0.914062 loss: 0.783121\n",
      " cross_entropy: 0.22851, clust_cross_entropy: 0.369074, affinity: 0.0561208, balance: 0.0695116, coact: 0.963852, frob: 0.000153586\n",
      "step 5100/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.75836 \n",
      " Validation: accuracy: 0.960938 loss: 0.600602\n",
      " cross_entropy: 0.195224, clust_cross_entropy: 0.390953, affinity: 0.0568557, balance: 0.0355019, coact: 1.30254, frob: 0.000154312\n",
      "step 5200/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.562374 \n",
      " Validation: accuracy: 0.9375 loss: 0.72444\n",
      " cross_entropy: 0.17167, clust_cross_entropy: 0.27695, affinity: 0.0675933, balance: 0.0401387, coact: 1.61879, frob: 0.000154778\n",
      "step 5300/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.696072 \n",
      " Validation: accuracy: 0.953125 loss: 0.555816\n",
      " cross_entropy: 0.272884, clust_cross_entropy: 0.426491, affinity: 0.0602976, balance: 0.0754247, coact: 1.22675, frob: 0.000162176\n",
      "step 5400/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.602664 \n",
      " Validation: accuracy: 0.945312 loss: 0.633736\n",
      " cross_entropy: 0.149005, clust_cross_entropy: 0.248156, affinity: 0.0478153, balance: 0.0989226, coact: 1.43266, frob: 0.000158406\n",
      "step 5500/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.69073 \n",
      " Validation: accuracy: 0.953125 loss: 0.574924\n",
      " cross_entropy: 0.263453, clust_cross_entropy: 0.297301, affinity: 0.0482936, balance: 0.0708685, coact: 1.2048, frob: 0.000161\n",
      "step 5600/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.526933 \n",
      " Validation: accuracy: 0.984375 loss: 0.574636\n",
      " cross_entropy: 0.150318, clust_cross_entropy: 0.230204, affinity: 0.0583744, balance: 0.0255141, coact: 1.1805, frob: 0.000157281\n",
      "step 5700/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.655852 \n",
      " Validation: accuracy: 0.960938 loss: 0.491645\n",
      " cross_entropy: 0.247595, clust_cross_entropy: 0.3227, affinity: 0.0496964, balance: 0.065114, coact: 1.21044, frob: 0.00016164\n",
      "step 5800/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.500209 \n",
      " Validation: accuracy: 0.929688 loss: 0.622122\n",
      " cross_entropy: 0.18852, clust_cross_entropy: 0.311225, affinity: 0.0601149, balance: 0.0709767, coact: 1.30649, frob: 0.000168737\n",
      "step 5900/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.526759 \n",
      " Validation: accuracy: 0.953125 loss: 0.655997\n",
      " cross_entropy: 0.197565, clust_cross_entropy: 0.468128, affinity: 0.0490366, balance: 0.0518069, coact: 1.13288, frob: 0.000160469\n",
      "step 6000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.463736 \n",
      " Validation: accuracy: 0.976562 loss: 0.363777\n",
      " cross_entropy: 0.0944353, clust_cross_entropy: 0.230382, affinity: 0.0610225, balance: 0.0470357, coact: 1.24463, frob: 0.000163898\n",
      "step 6100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.4404 \n",
      " Validation: accuracy: 0.96875 loss: 0.478032\n",
      " cross_entropy: 0.124458, clust_cross_entropy: 0.16799, affinity: 0.0526058, balance: 0.0618815, coact: 1.22555, frob: 0.000165215\n",
      "step 6200/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.360973 \n",
      " Validation: accuracy: 0.9375 loss: 0.709677\n",
      " cross_entropy: 0.155996, clust_cross_entropy: 0.222115, affinity: 0.0577201, balance: 0.0175235, coact: 1.1088, frob: 0.000165245\n",
      "step 6300/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.601309 \n",
      " Validation: accuracy: 0.953125 loss: 0.634009\n",
      " cross_entropy: 0.296102, clust_cross_entropy: 0.247652, affinity: 0.0511545, balance: 0.064267, coact: 1.33753, frob: 0.000167136\n",
      "step 6400/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.573741 \n",
      " Validation: accuracy: 0.945312 loss: 0.675915\n",
      " cross_entropy: 0.20916, clust_cross_entropy: 0.346478, affinity: 0.0479609, balance: 0.0720609, coact: 1.27325, frob: 0.000166597\n",
      "step 6500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.38213 \n",
      " Validation: accuracy: 0.945312 loss: 0.530093\n",
      " cross_entropy: 0.127475, clust_cross_entropy: 0.136426, affinity: 0.0428161, balance: 0.0693911, coact: 1.24984, frob: 0.000169434\n",
      "step 6600/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.583206 \n",
      " Validation: accuracy: 0.9375 loss: 0.482784\n",
      " cross_entropy: 0.184496, clust_cross_entropy: 0.307627, affinity: 0.0515111, balance: 0.0719352, coact: 1.18835, frob: 0.000158475\n",
      "step 6700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.354006 \n",
      " Validation: accuracy: 0.960938 loss: 0.53294\n",
      " cross_entropy: 0.0676575, clust_cross_entropy: 0.205651, affinity: 0.0499341, balance: 0.0624679, coact: 1.23703, frob: 0.000167784\n",
      "step 6800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.429964 \n",
      " Validation: accuracy: 0.9375 loss: 0.532545\n",
      " cross_entropy: 0.127038, clust_cross_entropy: 0.225061, affinity: 0.0410098, balance: 0.0413911, coact: 1.29505, frob: 0.000168965\n",
      "step 6900/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.500104 \n",
      " Validation: accuracy: 0.96875 loss: 0.569054\n",
      " cross_entropy: 0.13422, clust_cross_entropy: 0.17939, affinity: 0.0480035, balance: 0.114425, coact: 0.984824, frob: 0.000168423\n",
      "step 7000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.441575 \n",
      " Validation: accuracy: 0.976562 loss: 0.407313\n",
      " cross_entropy: 0.144917, clust_cross_entropy: 0.356608, affinity: 0.048953, balance: 0.071198, coact: 1.14055, frob: 0.000159338\n",
      "step 7100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.564049 \n",
      " Validation: accuracy: 0.984375 loss: 0.411294\n",
      " cross_entropy: 0.125554, clust_cross_entropy: 0.274422, affinity: 0.0420727, balance: 0.0301527, coact: 1.1658, frob: 0.000167432\n",
      "step 7200/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.464051 \n",
      " Validation: accuracy: 0.960938 loss: 0.385021\n",
      " cross_entropy: 0.15634, clust_cross_entropy: 0.306328, affinity: 0.0550786, balance: 0.0883446, coact: 1.26008, frob: 0.00017156\n",
      "step 7300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.431413 \n",
      " Validation: accuracy: 0.976562 loss: 0.380251\n",
      " cross_entropy: 0.102895, clust_cross_entropy: 0.149175, affinity: 0.0518529, balance: 0.0215774, coact: 1.14888, frob: 0.000171591\n",
      "step 7400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.343561 \n",
      " Validation: accuracy: 0.96875 loss: 0.342977\n",
      " cross_entropy: 0.101794, clust_cross_entropy: 0.175676, affinity: 0.038562, balance: 0.0478196, coact: 1.0708, frob: 0.000167515\n",
      "step 7500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.4377 \n",
      " Validation: accuracy: 0.96875 loss: 0.38028\n",
      " cross_entropy: 0.0857429, clust_cross_entropy: 0.194103, affinity: 0.0528511, balance: 0.125615, coact: 1.27904, frob: 0.000169557\n",
      "step 7600/50000 \n",
      " Train: accuracy: 0.914062, loss: 0.725198 \n",
      " Validation: accuracy: 0.976562 loss: 0.336107\n",
      " cross_entropy: 0.188862, clust_cross_entropy: 0.43805, affinity: 0.0406235, balance: 0.0363148, coact: 1.08583, frob: 0.000173892\n",
      "step 7700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.391759 \n",
      " Validation: accuracy: 0.953125 loss: 0.403041\n",
      " cross_entropy: 0.165243, clust_cross_entropy: 0.327306, affinity: 0.0516106, balance: 0.0195255, coact: 1.09471, frob: 0.000168311\n",
      "step 7800/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.35269 \n",
      " Validation: accuracy: 0.9375 loss: 0.69984\n",
      " cross_entropy: 0.100809, clust_cross_entropy: 0.206933, affinity: 0.0467316, balance: 0.0795234, coact: 1.10679, frob: 0.000167871\n",
      "step 7900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.489932 \n",
      " Validation: accuracy: 0.929688 loss: 0.703866\n",
      " cross_entropy: 0.142372, clust_cross_entropy: 0.291876, affinity: 0.0494327, balance: 0.0283136, coact: 1.21999, frob: 0.000175955\n",
      "step 8000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.574869 \n",
      " Validation: accuracy: 0.960938 loss: 0.458549\n",
      " cross_entropy: 0.17649, clust_cross_entropy: 0.258922, affinity: 0.0550512, balance: 0.0328193, coact: 1.07194, frob: 0.000171416\n",
      "step 8100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.427255 \n",
      " Validation: accuracy: 0.984375 loss: 0.556385\n",
      " cross_entropy: 0.106895, clust_cross_entropy: 0.160527, affinity: 0.0432709, balance: 0.0456238, coact: 1.26114, frob: 0.000178949\n",
      "step 8200/50000 \n",
      " Train: accuracy: 0.9375, loss: 0.571821 \n",
      " Validation: accuracy: 0.976562 loss: 0.367946\n",
      " cross_entropy: 0.0979851, clust_cross_entropy: 0.166853, affinity: 0.0443673, balance: 0.0645822, coact: 0.995067, frob: 0.000173276\n",
      "step 8300/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.477753 \n",
      " Validation: accuracy: 0.9375 loss: 0.582597\n",
      " cross_entropy: 0.125192, clust_cross_entropy: 0.20558, affinity: 0.0407541, balance: 0.0637406, coact: 0.89358, frob: 0.000175407\n",
      "step 8400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.380807 \n",
      " Validation: accuracy: 0.953125 loss: 0.722056\n",
      " cross_entropy: 0.117304, clust_cross_entropy: 0.205571, affinity: 0.0417447, balance: 0.140757, coact: 1.02438, frob: 0.000179242\n",
      "step 8500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.511498 \n",
      " Validation: accuracy: 0.945312 loss: 0.676622\n",
      " cross_entropy: 0.169792, clust_cross_entropy: 0.277327, affinity: 0.00805525, balance: 0.0894451, coact: 0.0819974, frob: 0.000216184\n",
      "step 8600/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.707245 \n",
      " Validation: accuracy: 0.945312 loss: 0.626573\n",
      " cross_entropy: 0.151909, clust_cross_entropy: 0.228929, affinity: 0.00380742, balance: 0.167245, coact: 0.0625472, frob: 0.000218769\n",
      "step 8700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.575748 \n",
      " Validation: accuracy: 0.960938 loss: 0.780773\n",
      " cross_entropy: 0.168029, clust_cross_entropy: 0.373839, affinity: 0.00241508, balance: 0.180994, coact: 0.0550889, frob: 0.000213654\n",
      "step 8800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.529202 \n",
      " Validation: accuracy: 0.914062 loss: 0.830296\n",
      " cross_entropy: 0.222203, clust_cross_entropy: 0.26938, affinity: 0.00410748, balance: 0.141229, coact: 0.0828929, frob: 0.00021575\n",
      "step 8900/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.708846 \n",
      " Validation: accuracy: 0.976562 loss: 0.543917\n",
      " cross_entropy: 0.207152, clust_cross_entropy: 0.323856, affinity: 0.00185183, balance: 0.144515, coact: 0.0684618, frob: 0.000216603\n",
      "step 9000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.463907 \n",
      " Validation: accuracy: 0.960938 loss: 0.414922\n",
      " cross_entropy: 0.159934, clust_cross_entropy: 0.294285, affinity: 0.00445891, balance: 0.127377, coact: 0.0644397, frob: 0.000223522\n",
      "step 9100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.555918 \n",
      " Validation: accuracy: 0.976562 loss: 0.477367\n",
      " cross_entropy: 0.165741, clust_cross_entropy: 0.229822, affinity: 0.00471279, balance: 0.110766, coact: 0.0229583, frob: 0.000224376\n",
      "step 9200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.499361 \n",
      " Validation: accuracy: 0.945312 loss: 0.60559\n",
      " cross_entropy: 0.108365, clust_cross_entropy: 0.206872, affinity: 0.0057424, balance: 0.0784901, coact: 0.0267607, frob: 0.0002186\n",
      "step 9300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.617542 \n",
      " Validation: accuracy: 1 loss: 0.216888\n",
      " cross_entropy: 0.19509, clust_cross_entropy: 0.309684, affinity: 0.006387, balance: 0.196577, coact: 0.0269294, frob: 0.000227974\n",
      "step 9400/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.550697 \n",
      " Validation: accuracy: 0.976562 loss: 0.356464\n",
      " cross_entropy: 0.171566, clust_cross_entropy: 0.220106, affinity: 0.00521229, balance: 0.0813651, coact: 0.0263783, frob: 0.000226846\n",
      "step 9500/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.621919 \n",
      " Validation: accuracy: 0.96875 loss: 0.482991\n",
      " cross_entropy: 0.114365, clust_cross_entropy: 0.284934, affinity: 0.00406392, balance: 0.0805244, coact: 0.0274863, frob: 0.000223358\n",
      "step 9600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.542854 \n",
      " Validation: accuracy: 0.9375 loss: 0.55333\n",
      " cross_entropy: 0.132601, clust_cross_entropy: 0.133259, affinity: 0.00417101, balance: 0.0933594, coact: 0.0224719, frob: 0.000222913\n",
      "step 9700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.429716 \n",
      " Validation: accuracy: 0.960938 loss: 0.60453\n",
      " cross_entropy: 0.168761, clust_cross_entropy: 0.316342, affinity: 0.00379993, balance: 0.055611, coact: 0.0431307, frob: 0.000230961\n",
      "step 9800/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.61507 \n",
      " Validation: accuracy: 0.96875 loss: 0.391683\n",
      " cross_entropy: 0.184589, clust_cross_entropy: 0.254761, affinity: 0.00326111, balance: 0.169245, coact: 0.0628949, frob: 0.000231758\n",
      "step 9900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.545149 \n",
      " Validation: accuracy: 0.96875 loss: 0.424625\n",
      " cross_entropy: 0.156444, clust_cross_entropy: 0.229293, affinity: 0.0051244, balance: 0.141246, coact: 0.0463508, frob: 0.000228477\n",
      "step 10000/50000 \n",
      " Train: accuracy: 0.929688, loss: 0.443166 \n",
      " Validation: accuracy: 0.976562 loss: 0.377675\n",
      " cross_entropy: 0.189697, clust_cross_entropy: 0.158291, affinity: 0.00417333, balance: 0.0272115, coact: 0.0433803, frob: 0.000223932\n",
      "step 10100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.503325 \n",
      " Validation: accuracy: 0.960938 loss: 0.527778\n",
      " cross_entropy: 0.157868, clust_cross_entropy: 0.378454, affinity: 0.00296365, balance: 0.0600664, coact: 0.0433496, frob: 0.000225308\n",
      "step 10200/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.51165 \n",
      " Validation: accuracy: 0.960938 loss: 0.459443\n",
      " cross_entropy: 0.172529, clust_cross_entropy: 0.283564, affinity: 0.00691295, balance: 0.0930441, coact: 0.0307026, frob: 0.000224167\n",
      "step 10300/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.396466 \n",
      " Validation: accuracy: 0.960938 loss: 0.482223\n",
      " cross_entropy: 0.0725895, clust_cross_entropy: 0.145165, affinity: 0.00564462, balance: 0.138573, coact: 0.0486512, frob: 0.000221791\n",
      "step 10400/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.534861 \n",
      " Validation: accuracy: 0.914062 loss: 0.722355\n",
      " cross_entropy: 0.10551, clust_cross_entropy: 0.17426, affinity: 0.0039846, balance: 0.072061, coact: 0.0578555, frob: 0.000234545\n",
      "step 10500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.344742 \n",
      " Validation: accuracy: 0.945312 loss: 0.668866\n",
      " cross_entropy: 0.107363, clust_cross_entropy: 0.14944, affinity: 0.00493049, balance: 0.0887368, coact: 0.0225801, frob: 0.000223794\n",
      "step 10600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.696956 \n",
      " Validation: accuracy: 0.984375 loss: 0.528485\n",
      " cross_entropy: 0.154024, clust_cross_entropy: 0.305667, affinity: 0.00524528, balance: 0.059383, coact: 0.0609096, frob: 0.000230299\n",
      "step 10700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.4466 \n",
      " Validation: accuracy: 0.953125 loss: 0.411741\n",
      " cross_entropy: 0.164018, clust_cross_entropy: 0.123325, affinity: 0.00537774, balance: 0.0932887, coact: 0.0138307, frob: 0.000223552\n",
      "step 10800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.31946 \n",
      " Validation: accuracy: 0.960938 loss: 0.498657\n",
      " cross_entropy: 0.0884484, clust_cross_entropy: 0.172335, affinity: 0.00405509, balance: 0.104309, coact: 0.0319457, frob: 0.00023288\n",
      "step 10900/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.493591 \n",
      " Validation: accuracy: 0.96875 loss: 0.504097\n",
      " cross_entropy: 0.200393, clust_cross_entropy: 0.212033, affinity: 0.00303154, balance: 0.0798497, coact: 0.0459078, frob: 0.000224029\n",
      "step 11000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.300808 \n",
      " Validation: accuracy: 0.960938 loss: 0.455476\n",
      " cross_entropy: 0.0779897, clust_cross_entropy: 0.120744, affinity: 0.00581478, balance: 0.0173094, coact: 0.0626403, frob: 0.000229917\n",
      "step 11100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.523645 \n",
      " Validation: accuracy: 0.960938 loss: 0.409346\n",
      " cross_entropy: 0.144471, clust_cross_entropy: 0.336233, affinity: 0.003845, balance: 0.0925015, coact: 0.0396633, frob: 0.0002339\n",
      "step 11200/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.439503 \n",
      " Validation: accuracy: 0.960938 loss: 0.56647\n",
      " cross_entropy: 0.162612, clust_cross_entropy: 0.192584, affinity: 0.00263864, balance: 0.00961596, coact: 0.0561276, frob: 0.000229724\n",
      "step 11300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.542552 \n",
      " Validation: accuracy: 0.96875 loss: 0.411871\n",
      " cross_entropy: 0.115656, clust_cross_entropy: 0.29919, affinity: 0.0035182, balance: 0.111336, coact: 0.0125597, frob: 0.000235119\n",
      "step 11400/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.365216 \n",
      " Validation: accuracy: 0.984375 loss: 0.558676\n",
      " cross_entropy: 0.0816855, clust_cross_entropy: 0.132993, affinity: 0.00276989, balance: 0.0603987, coact: 0.0208208, frob: 0.000236756\n",
      "step 11500/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.391264 \n",
      " Validation: accuracy: 0.96875 loss: 0.406737\n",
      " cross_entropy: 0.0798052, clust_cross_entropy: 0.165522, affinity: 0.000858267, balance: 0.0429951, coact: 0.0800135, frob: 0.000234566\n",
      "step 11600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.350418 \n",
      " Validation: accuracy: 0.96875 loss: 0.472213\n",
      " cross_entropy: 0.154974, clust_cross_entropy: 0.139707, affinity: 0.00561047, balance: 0.0150871, coact: 0.0243876, frob: 0.00023836\n",
      "step 11700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.493761 \n",
      " Validation: accuracy: 0.976562 loss: 0.350584\n",
      " cross_entropy: 0.13575, clust_cross_entropy: 0.2671, affinity: 0.00636169, balance: 0.0822794, coact: 0.0279716, frob: 0.000224679\n",
      "step 11800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.323947 \n",
      " Validation: accuracy: 0.96875 loss: 0.466\n",
      " cross_entropy: 0.0949249, clust_cross_entropy: 0.0759389, affinity: 0.00555064, balance: 0.0838512, coact: 0.016415, frob: 0.000227059\n",
      "step 11900/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.502971 \n",
      " Validation: accuracy: 0.976562 loss: 0.441849\n",
      " cross_entropy: 0.144989, clust_cross_entropy: 0.138826, affinity: 0.00315638, balance: 0.12402, coact: 0.0448654, frob: 0.000221607\n",
      "step 12000/50000 \n",
      " Train: accuracy: 1, loss: 0.226381 \n",
      " Validation: accuracy: 0.960938 loss: 0.440287\n",
      " cross_entropy: 0.0829564, clust_cross_entropy: 0.163227, affinity: 0.00236568, balance: 0.115462, coact: 0.0163682, frob: 0.000239611\n",
      "step 12100/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.639861 \n",
      " Validation: accuracy: 0.96875 loss: 0.437956\n",
      " cross_entropy: 0.107793, clust_cross_entropy: 0.260496, affinity: 0.0032782, balance: 0.115007, coact: 0.0302624, frob: 0.000229404\n",
      "step 12200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.453044 \n",
      " Validation: accuracy: 0.992188 loss: 0.338955\n",
      " cross_entropy: 0.0994334, clust_cross_entropy: 0.18607, affinity: 0.00515352, balance: 0.197053, coact: 0.0165898, frob: 0.00024077\n",
      "step 12300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.394557 \n",
      " Validation: accuracy: 0.96875 loss: 0.328285\n",
      " cross_entropy: 0.110105, clust_cross_entropy: 0.124996, affinity: 0.0039277, balance: 0.104306, coact: 0.0424723, frob: 0.000235785\n",
      "step 12400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.297638 \n",
      " Validation: accuracy: 0.921875 loss: 0.812779\n",
      " cross_entropy: 0.106649, clust_cross_entropy: 0.190679, affinity: 0.00336708, balance: 0.0856748, coact: 0.0266383, frob: 0.000238778\n",
      "step 12500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.561014 \n",
      " Validation: accuracy: 0.960938 loss: 0.368591\n",
      " cross_entropy: 0.146602, clust_cross_entropy: 0.225122, affinity: 0.00086066, balance: 0.126841, coact: 0.0454403, frob: 0.000234754\n",
      "step 12600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.557239 \n",
      " Validation: accuracy: 0.953125 loss: 0.416692\n",
      " cross_entropy: 0.102706, clust_cross_entropy: 0.241178, affinity: 0.00261939, balance: 0.111094, coact: 0.0362975, frob: 0.000229898\n",
      "step 12700/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.462582 \n",
      " Validation: accuracy: 0.960938 loss: 0.283179\n",
      " cross_entropy: 0.15639, clust_cross_entropy: 0.221657, affinity: 0.00275677, balance: 0.13219, coact: 0.0187714, frob: 0.000229777\n",
      "step 12800/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.39708 \n",
      " Validation: accuracy: 0.96875 loss: 0.466093\n",
      " cross_entropy: 0.0816593, clust_cross_entropy: 0.194134, affinity: 0.00311608, balance: 0.075501, coact: 0.0324779, frob: 0.00024145\n",
      "step 12900/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.539324 \n",
      " Validation: accuracy: 0.953125 loss: 0.497264\n",
      " cross_entropy: 0.120994, clust_cross_entropy: 0.191011, affinity: 0.00283781, balance: 0.145872, coact: 0.0148978, frob: 0.000231087\n",
      "step 13000/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.571032 \n",
      " Validation: accuracy: 0.976562 loss: 0.460212\n",
      " cross_entropy: 0.155653, clust_cross_entropy: 0.323722, affinity: 0.00153614, balance: 0.109186, coact: 0.0555483, frob: 0.000240786\n",
      "step 13100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.455541 \n",
      " Validation: accuracy: 0.976562 loss: 0.404206\n",
      " cross_entropy: 0.100908, clust_cross_entropy: 0.174123, affinity: 0.00202084, balance: 0.0870605, coact: 0.0116445, frob: 0.00024039\n",
      "step 13200/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.501678 \n",
      " Validation: accuracy: 0.96875 loss: 0.277892\n",
      " cross_entropy: 0.138972, clust_cross_entropy: 0.191835, affinity: 0.00145444, balance: 0.0807293, coact: 0.024613, frob: 0.00023384\n",
      "step 13300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.372946 \n",
      " Validation: accuracy: 0.992188 loss: 0.373152\n",
      " cross_entropy: 0.107891, clust_cross_entropy: 0.195581, affinity: 0.00213915, balance: 0.113902, coact: 0.0189282, frob: 0.000239233\n",
      "step 13400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.433041 \n",
      " Validation: accuracy: 0.96875 loss: 0.582335\n",
      " cross_entropy: 0.110242, clust_cross_entropy: 0.158314, affinity: 0.00318771, balance: 0.0888091, coact: 0.0441121, frob: 0.000242422\n",
      "step 13500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.355252 \n",
      " Validation: accuracy: 0.976562 loss: 0.308778\n",
      " cross_entropy: 0.102893, clust_cross_entropy: 0.243989, affinity: 0.00195698, balance: 0.0562831, coact: 0.0377392, frob: 0.000247671\n",
      "step 13600/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.370007 \n",
      " Validation: accuracy: 0.992188 loss: 0.389076\n",
      " cross_entropy: 0.152595, clust_cross_entropy: 0.13509, affinity: 0.00336983, balance: 0.0951409, coact: 0.0181704, frob: 0.000242759\n",
      "step 13700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.368747 \n",
      " Validation: accuracy: 0.992188 loss: 0.287061\n",
      " cross_entropy: 0.0990443, clust_cross_entropy: 0.167427, affinity: 0.0027254, balance: 0.0682813, coact: 0.0231453, frob: 0.000246258\n",
      "step 13800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.326181 \n",
      " Validation: accuracy: 0.976562 loss: 0.3873\n",
      " cross_entropy: 0.0655584, clust_cross_entropy: 0.111523, affinity: 0.00361439, balance: 0.0440912, coact: 0.0312476, frob: 0.000252559\n",
      "step 13900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.337208 \n",
      " Validation: accuracy: 0.984375 loss: 0.389307\n",
      " cross_entropy: 0.0377816, clust_cross_entropy: 0.170716, affinity: 0.00539474, balance: 0.112534, coact: 0.00870688, frob: 0.000250224\n",
      "step 14000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.404531 \n",
      " Validation: accuracy: 0.992188 loss: 0.18851\n",
      " cross_entropy: 0.127078, clust_cross_entropy: 0.158299, affinity: 0.00477729, balance: 0.0591413, coact: 0.0208749, frob: 0.000238537\n",
      "step 14100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.491356 \n",
      " Validation: accuracy: 0.9375 loss: 0.432462\n",
      " cross_entropy: 0.110276, clust_cross_entropy: 0.312386, affinity: 0.00189309, balance: 0.0724269, coact: 0.0173656, frob: 0.000240792\n",
      "step 14200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.490294 \n",
      " Validation: accuracy: 0.96875 loss: 0.606441\n",
      " cross_entropy: 0.157981, clust_cross_entropy: 0.215973, affinity: 0.00216336, balance: 0.112939, coact: 0.0273206, frob: 0.00024056\n",
      "step 14300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.369916 \n",
      " Validation: accuracy: 0.976562 loss: 0.390853\n",
      " cross_entropy: 0.0735818, clust_cross_entropy: 0.178523, affinity: 0.00259278, balance: 0.129761, coact: 0.0212788, frob: 0.000254278\n",
      "step 14400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.316687 \n",
      " Validation: accuracy: 1 loss: 0.369804\n",
      " cross_entropy: 0.0804898, clust_cross_entropy: 0.0883465, affinity: 0.00412824, balance: 0.0946311, coact: 0.0534705, frob: 0.000242854\n",
      "step 14500/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.393212 \n",
      " Validation: accuracy: 0.976562 loss: 0.365995\n",
      " cross_entropy: 0.100961, clust_cross_entropy: 0.184846, affinity: 0.00189885, balance: 0.0716525, coact: 0.0197591, frob: 0.000242668\n",
      "step 14600/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.638189 \n",
      " Validation: accuracy: 0.992188 loss: 0.332482\n",
      " cross_entropy: 0.210465, clust_cross_entropy: 0.190177, affinity: 0.00155247, balance: 0.163841, coact: 0.0176902, frob: 0.000255868\n",
      "step 14700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.409546 \n",
      " Validation: accuracy: 0.953125 loss: 0.450427\n",
      " cross_entropy: 0.106097, clust_cross_entropy: 0.141089, affinity: 0.00189928, balance: 0.127753, coact: 0.0136488, frob: 0.000245165\n",
      "step 14800/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.289097 \n",
      " Validation: accuracy: 0.984375 loss: 0.275329\n",
      " cross_entropy: 0.0794376, clust_cross_entropy: 0.0728601, affinity: 0.00348425, balance: 0.108583, coact: 0.0134456, frob: 0.000248309\n",
      "step 14900/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.572902 \n",
      " Validation: accuracy: 0.976562 loss: 0.351901\n",
      " cross_entropy: 0.123109, clust_cross_entropy: 0.291548, affinity: 0.00150701, balance: 0.163817, coact: 0.0373272, frob: 0.000245446\n",
      "step 15000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.265665 \n",
      " Validation: accuracy: 0.984375 loss: 0.307423\n",
      " cross_entropy: 0.123648, clust_cross_entropy: 0.195789, affinity: 0.00129714, balance: 0.0644311, coact: 0.0199961, frob: 0.000245497\n",
      "step 15100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.256813 \n",
      " Validation: accuracy: 0.96875 loss: 0.373912\n",
      " cross_entropy: 0.0615903, clust_cross_entropy: 0.126127, affinity: 0.00274326, balance: 0.0447615, coact: 0.0194851, frob: 0.000250743\n",
      "step 15200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.579162 \n",
      " Validation: accuracy: 0.960938 loss: 0.470316\n",
      " cross_entropy: 0.168156, clust_cross_entropy: 0.231199, affinity: 0.00262169, balance: 0.164259, coact: 0.0163597, frob: 0.000258389\n",
      "step 15300/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.468782 \n",
      " Validation: accuracy: 0.953125 loss: 0.5343\n",
      " cross_entropy: 0.11186, clust_cross_entropy: 0.159523, affinity: 0.00183027, balance: 0.0829162, coact: 0.0192312, frob: 0.000255365\n",
      "step 15400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.296834 \n",
      " Validation: accuracy: 0.929688 loss: 0.478519\n",
      " cross_entropy: 0.0672875, clust_cross_entropy: 0.134951, affinity: 0.0026367, balance: 0.0458333, coact: 0.0189193, frob: 0.000251525\n",
      "step 15500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.272576 \n",
      " Validation: accuracy: 0.976562 loss: 0.373623\n",
      " cross_entropy: 0.0660429, clust_cross_entropy: 0.0673115, affinity: 0.00104747, balance: 0.0981205, coact: 0.025457, frob: 0.000251249\n",
      "step 15600/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.448669 \n",
      " Validation: accuracy: 0.953125 loss: 0.688171\n",
      " cross_entropy: 0.0601254, clust_cross_entropy: 0.116906, affinity: 0.00206617, balance: 0.0871881, coact: 0.0771352, frob: 0.000257574\n",
      "step 15700/50000 \n",
      " Train: accuracy: 1, loss: 0.228376 \n",
      " Validation: accuracy: 0.992188 loss: 0.279193\n",
      " cross_entropy: 0.070822, clust_cross_entropy: 0.0962645, affinity: 0.00235978, balance: 0.0652181, coact: 0.0141865, frob: 0.000250706\n",
      "step 15800/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.429823 \n",
      " Validation: accuracy: 0.945312 loss: 0.481192\n",
      " cross_entropy: 0.182173, clust_cross_entropy: 0.227354, affinity: 0.00111971, balance: 0.139341, coact: 0.0152449, frob: 0.000258926\n",
      "step 15900/50000 \n",
      " Train: accuracy: 1, loss: 0.107371 \n",
      " Validation: accuracy: 0.96875 loss: 0.373562\n",
      " cross_entropy: 0.0795531, clust_cross_entropy: 0.0821433, affinity: 0.00136074, balance: 0.0407563, coact: 0.0162001, frob: 0.000256779\n",
      "step 16000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.288646 \n",
      " Validation: accuracy: 0.992188 loss: 0.244659\n",
      " cross_entropy: 0.092377, clust_cross_entropy: 0.136382, affinity: 0.00110545, balance: 0.0144224, coact: 0.0210712, frob: 0.00025302\n",
      "step 16100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.351919 \n",
      " Validation: accuracy: 0.96875 loss: 0.388493\n",
      " cross_entropy: 0.118902, clust_cross_entropy: 0.116119, affinity: 0.00118899, balance: 0.102215, coact: 0.00851968, frob: 0.000256643\n",
      "step 16200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.4157 \n",
      " Validation: accuracy: 0.992188 loss: 0.272968\n",
      " cross_entropy: 0.140098, clust_cross_entropy: 0.17416, affinity: 0.00149799, balance: 0.0782174, coact: 0.00311214, frob: 0.000257411\n",
      "step 16300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.266908 \n",
      " Validation: accuracy: 0.976562 loss: 0.35983\n",
      " cross_entropy: 0.0569778, clust_cross_entropy: 0.148054, affinity: 0.00155233, balance: 0.0563242, coact: 0.0108612, frob: 0.000251485\n",
      "step 16400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.421659 \n",
      " Validation: accuracy: 0.945312 loss: 0.460614\n",
      " cross_entropy: 0.122327, clust_cross_entropy: 0.185633, affinity: 0.00267522, balance: 0.0732984, coact: 0.0291629, frob: 0.000257978\n",
      "step 16500/50000 \n",
      " Train: accuracy: 1, loss: 0.284431 \n",
      " Validation: accuracy: 0.976562 loss: 0.397893\n",
      " cross_entropy: 0.0486497, clust_cross_entropy: 0.100909, affinity: 0.000631819, balance: 0.112797, coact: 0.00975577, frob: 0.00026703\n",
      "step 16600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.225793 \n",
      " Validation: accuracy: 0.984375 loss: 0.227026\n",
      " cross_entropy: 0.0311787, clust_cross_entropy: 0.0389866, affinity: 0.00460759, balance: 0.0899981, coact: 0.0134044, frob: 0.00025924\n",
      "step 16700/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.532739 \n",
      " Validation: accuracy: 1 loss: 0.308618\n",
      " cross_entropy: 0.153516, clust_cross_entropy: 0.215441, affinity: 0.00291192, balance: 0.175737, coact: 0.0164884, frob: 0.000255593\n",
      "step 16800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.218427 \n",
      " Validation: accuracy: 0.992188 loss: 0.329953\n",
      " cross_entropy: 0.0859966, clust_cross_entropy: 0.122771, affinity: 0.00149735, balance: 0.0234115, coact: 0.019185, frob: 0.000264365\n",
      "step 16900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.274262 \n",
      " Validation: accuracy: 0.976562 loss: 0.266009\n",
      " cross_entropy: 0.0784236, clust_cross_entropy: 0.146339, affinity: 0.00203236, balance: 0.0803439, coact: 0.012892, frob: 0.000260956\n",
      "step 17000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.25529 \n",
      " Validation: accuracy: 0.992188 loss: 0.265451\n",
      " cross_entropy: 0.0439286, clust_cross_entropy: 0.0966405, affinity: 0.00269858, balance: 0.0654532, coact: 0.0113757, frob: 0.000251464\n",
      "step 17100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.267916 \n",
      " Validation: accuracy: 0.96875 loss: 0.385365\n",
      " cross_entropy: 0.0660756, clust_cross_entropy: 0.0533913, affinity: 0.00196835, balance: 0.141865, coact: 0.0296845, frob: 0.000263975\n",
      "step 17200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.292774 \n",
      " Validation: accuracy: 0.953125 loss: 0.436763\n",
      " cross_entropy: 0.0446211, clust_cross_entropy: 0.115852, affinity: 0.000660694, balance: 0.0854758, coact: 0.0127398, frob: 0.00025623\n",
      "step 17300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.307163 \n",
      " Validation: accuracy: 0.992188 loss: 0.220691\n",
      " cross_entropy: 0.0841418, clust_cross_entropy: 0.0783853, affinity: 0.00156383, balance: 0.181369, coact: 0.0122448, frob: 0.000267132\n",
      "step 17400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.376842 \n",
      " Validation: accuracy: 0.984375 loss: 0.303962\n",
      " cross_entropy: 0.0575966, clust_cross_entropy: 0.0901758, affinity: 0.00139782, balance: 0.0391482, coact: 0.0240108, frob: 0.000266508\n",
      "step 17500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.317827 \n",
      " Validation: accuracy: 0.960938 loss: 0.459586\n",
      " cross_entropy: 0.0765744, clust_cross_entropy: 0.108469, affinity: 0.00274793, balance: 0.0747939, coact: 0.0180283, frob: 0.000249017\n",
      "step 17600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.329165 \n",
      " Validation: accuracy: 0.96875 loss: 0.368099\n",
      " cross_entropy: 0.125126, clust_cross_entropy: 0.116178, affinity: 0.000420108, balance: 0.0357013, coact: 0.0228474, frob: 0.00026081\n",
      "step 17700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.389044 \n",
      " Validation: accuracy: 0.992188 loss: 0.208126\n",
      " cross_entropy: 0.0644453, clust_cross_entropy: 0.0846133, affinity: 0.00169461, balance: 0.141451, coact: 0.0286535, frob: 0.000252972\n",
      "step 17800/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.32478 \n",
      " Validation: accuracy: 0.960938 loss: 0.455375\n",
      " cross_entropy: 0.162242, clust_cross_entropy: 0.137547, affinity: 0.0010212, balance: 0.0224177, coact: 0.0111162, frob: 0.000257536\n",
      "step 17900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.225631 \n",
      " Validation: accuracy: 1 loss: 0.197753\n",
      " cross_entropy: 0.0706874, clust_cross_entropy: 0.116124, affinity: 0.00325402, balance: 0.130058, coact: 0.019613, frob: 0.000268667\n",
      "step 18000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.365908 \n",
      " Validation: accuracy: 0.984375 loss: 0.327682\n",
      " cross_entropy: 0.065419, clust_cross_entropy: 0.127109, affinity: 0.00137044, balance: 0.170258, coact: 0.0490678, frob: 0.000253358\n",
      "step 18100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.373396 \n",
      " Validation: accuracy: 0.976562 loss: 0.335433\n",
      " cross_entropy: 0.0763098, clust_cross_entropy: 0.146116, affinity: 0.00270976, balance: 0.0703183, coact: 0.0246677, frob: 0.000255064\n",
      "step 18200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.319496 \n",
      " Validation: accuracy: 0.96875 loss: 0.274182\n",
      " cross_entropy: 0.0695357, clust_cross_entropy: 0.141307, affinity: 0.00250568, balance: 0.147297, coact: 0.0257654, frob: 0.000264326\n",
      "step 18300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.400964 \n",
      " Validation: accuracy: 0.984375 loss: 0.400827\n",
      " cross_entropy: 0.161516, clust_cross_entropy: 0.173463, affinity: 0.00174027, balance: 0.0884795, coact: 0.0217086, frob: 0.000261722\n",
      "step 18400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.150354 \n",
      " Validation: accuracy: 0.96875 loss: 0.301317\n",
      " cross_entropy: 0.0550216, clust_cross_entropy: 0.0341296, affinity: 0.00146446, balance: 0.0757064, coact: 0.0157556, frob: 0.000251352\n",
      "step 18500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.330852 \n",
      " Validation: accuracy: 0.984375 loss: 0.201891\n",
      " cross_entropy: 0.0316437, clust_cross_entropy: 0.112664, affinity: 0.00173231, balance: 0.13412, coact: 0.022334, frob: 0.000274708\n",
      "step 18600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.376602 \n",
      " Validation: accuracy: 0.984375 loss: 0.268125\n",
      " cross_entropy: 0.110737, clust_cross_entropy: 0.213509, affinity: 0.00253851, balance: 0.080232, coact: 0.0251192, frob: 0.000252768\n",
      "step 18700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.213818 \n",
      " Validation: accuracy: 1 loss: 0.226009\n",
      " cross_entropy: 0.0756304, clust_cross_entropy: 0.0950713, affinity: 0.0017871, balance: 0.0523154, coact: 0.0220575, frob: 0.000264687\n",
      "step 18800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.267182 \n",
      " Validation: accuracy: 0.992188 loss: 0.379723\n",
      " cross_entropy: 0.085889, clust_cross_entropy: 0.128288, affinity: 0.000556613, balance: 0.0668161, coact: 0.00117999, frob: 0.000263405\n",
      "step 18900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.209266 \n",
      " Validation: accuracy: 0.984375 loss: 0.395434\n",
      " cross_entropy: 0.0460727, clust_cross_entropy: 0.0425113, affinity: 0.00079964, balance: 0.0698704, coact: 0.0244847, frob: 0.000256567\n",
      "step 19000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.249841 \n",
      " Validation: accuracy: 0.984375 loss: 0.458176\n",
      " cross_entropy: 0.0475703, clust_cross_entropy: 0.146978, affinity: 0.00352639, balance: 0.0758085, coact: 0.0124212, frob: 0.000258676\n",
      "step 19100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.213264 \n",
      " Validation: accuracy: 0.984375 loss: 0.274556\n",
      " cross_entropy: 0.0722653, clust_cross_entropy: 0.153858, affinity: 0.00183314, balance: 0.0334359, coact: 0.00914435, frob: 0.000270349\n",
      "step 19200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.334983 \n",
      " Validation: accuracy: 0.992188 loss: 0.210394\n",
      " cross_entropy: 0.120838, clust_cross_entropy: 0.123549, affinity: 0.0011134, balance: 0.0791615, coact: 0.00560159, frob: 0.000267675\n",
      "step 19300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.319868 \n",
      " Validation: accuracy: 1 loss: 0.305608\n",
      " cross_entropy: 0.0978883, clust_cross_entropy: 0.124076, affinity: 0.00240265, balance: 0.0874424, coact: 0.00945271, frob: 0.000257817\n",
      "step 19400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.273508 \n",
      " Validation: accuracy: 0.992188 loss: 0.290101\n",
      " cross_entropy: 0.0858108, clust_cross_entropy: 0.131409, affinity: 0.000864421, balance: 0.0767192, coact: 0.0091779, frob: 0.000267754\n",
      "step 19500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.25169 \n",
      " Validation: accuracy: 0.984375 loss: 0.313483\n",
      " cross_entropy: 0.14284, clust_cross_entropy: 0.201763, affinity: 0.00138724, balance: 0.0595757, coact: 0.00601059, frob: 0.000268464\n",
      "step 19600/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.255717 \n",
      " Validation: accuracy: 0.96875 loss: 0.357749\n",
      " cross_entropy: 0.0869349, clust_cross_entropy: 0.0962163, affinity: 0.00133915, balance: 0.132357, coact: 0.0169244, frob: 0.000260097\n",
      "step 19700/50000 \n",
      " Train: accuracy: 1, loss: 0.194459 \n",
      " Validation: accuracy: 0.992188 loss: 0.213889\n",
      " cross_entropy: 0.0765242, clust_cross_entropy: 0.0970767, affinity: 0.000939664, balance: 0.078929, coact: 0.013442, frob: 0.000259562\n",
      "step 19800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.289011 \n",
      " Validation: accuracy: 0.976562 loss: 0.321729\n",
      " cross_entropy: 0.0726788, clust_cross_entropy: 0.0725442, affinity: 0.00209439, balance: 0.0955993, coact: 0.000839515, frob: 0.000264172\n",
      "step 19900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.299742 \n",
      " Validation: accuracy: 0.976562 loss: 0.223942\n",
      " cross_entropy: 0.0987005, clust_cross_entropy: 0.0565903, affinity: 0.000547367, balance: 0.143556, coact: 0.0170203, frob: 0.000265628\n",
      "step 20000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.315298 \n",
      " Validation: accuracy: 0.976562 loss: 0.206219\n",
      " cross_entropy: 0.0926849, clust_cross_entropy: 0.184445, affinity: 0.000726063, balance: 0.0792698, coact: 0.0342288, frob: 0.000265121\n",
      "step 20100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.20541 \n",
      " Validation: accuracy: 0.992188 loss: 0.269797\n",
      " cross_entropy: 0.0596516, clust_cross_entropy: 0.151495, affinity: 0.000773962, balance: 0.0163442, coact: 0.00526669, frob: 0.000255322\n",
      "step 20200/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.467609 \n",
      " Validation: accuracy: 0.984375 loss: 0.197317\n",
      " cross_entropy: 0.114481, clust_cross_entropy: 0.117917, affinity: 0.00108945, balance: 0.0760492, coact: 0.0170622, frob: 0.000276117\n",
      "step 20300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.434624 \n",
      " Validation: accuracy: 0.976562 loss: 0.267899\n",
      " cross_entropy: 0.101761, clust_cross_entropy: 0.121569, affinity: 0.00111778, balance: 0.125361, coact: 0.019751, frob: 0.000273005\n",
      "step 20400/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.354584 \n",
      " Validation: accuracy: 0.976562 loss: 0.348674\n",
      " cross_entropy: 0.0551733, clust_cross_entropy: 0.0923202, affinity: 0.00137195, balance: 0.12032, coact: 0.00808125, frob: 0.000262923\n",
      "step 20500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.277338 \n",
      " Validation: accuracy: 1 loss: 0.194254\n",
      " cross_entropy: 0.11115, clust_cross_entropy: 0.0789514, affinity: 0.000887132, balance: 0.17932, coact: 0.015489, frob: 0.000270122\n",
      "step 20600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.384844 \n",
      " Validation: accuracy: 0.976562 loss: 0.296231\n",
      " cross_entropy: 0.074879, clust_cross_entropy: 0.135168, affinity: 0.000317238, balance: 0.0806701, coact: 0.0549381, frob: 0.000265378\n",
      "step 20700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.289177 \n",
      " Validation: accuracy: 0.984375 loss: 0.17289\n",
      " cross_entropy: 0.0729516, clust_cross_entropy: 0.170219, affinity: 0.00304925, balance: 0.0669382, coact: 0.000525602, frob: 0.000267781\n",
      "step 20800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.282011 \n",
      " Validation: accuracy: 0.960938 loss: 0.454712\n",
      " cross_entropy: 0.0596289, clust_cross_entropy: 0.100634, affinity: 0.00073303, balance: 0.104208, coact: 0.000175085, frob: 0.000264954\n",
      "step 20900/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.33305 \n",
      " Validation: accuracy: 0.984375 loss: 0.261812\n",
      " cross_entropy: 0.0996722, clust_cross_entropy: 0.195459, affinity: 0.00329929, balance: 0.0485761, coact: 0.0224913, frob: 0.000280091\n",
      "step 21000/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.234551 \n",
      " Validation: accuracy: 1 loss: 0.176409\n",
      " cross_entropy: 0.121765, clust_cross_entropy: 0.144477, affinity: 0.0017476, balance: 0.0365349, coact: 0.0115374, frob: 0.000267848\n",
      "step 21100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.382016 \n",
      " Validation: accuracy: 0.976562 loss: 0.197439\n",
      " cross_entropy: 0.0394665, clust_cross_entropy: 0.126093, affinity: 0.00115706, balance: 0.141465, coact: 0.00888362, frob: 0.000278762\n",
      "step 21200/50000 \n",
      " Train: accuracy: 1, loss: 0.176567 \n",
      " Validation: accuracy: 0.984375 loss: 0.238818\n",
      " cross_entropy: 0.0860473, clust_cross_entropy: 0.116452, affinity: 0.00305849, balance: 0.0365989, coact: 0.00221642, frob: 0.000274414\n",
      "step 21300/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.405853 \n",
      " Validation: accuracy: 0.976562 loss: 0.354672\n",
      " cross_entropy: 0.0688899, clust_cross_entropy: 0.141895, affinity: 0.00212603, balance: 0.0545216, coact: 0.0348829, frob: 0.000277221\n",
      "step 21400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.284515 \n",
      " Validation: accuracy: 0.984375 loss: 0.18889\n",
      " cross_entropy: 0.0711634, clust_cross_entropy: 0.10549, affinity: 0.000552106, balance: 0.0640948, coact: 0.0149142, frob: 0.000270368\n",
      "step 21500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.26959 \n",
      " Validation: accuracy: 0.984375 loss: 0.284446\n",
      " cross_entropy: 0.0702744, clust_cross_entropy: 0.0948597, affinity: 0.00128473, balance: 0.103513, coact: 0.00591038, frob: 0.000272914\n",
      "step 21600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.184277 \n",
      " Validation: accuracy: 0.960938 loss: 0.309675\n",
      " cross_entropy: 0.0491261, clust_cross_entropy: 0.0692847, affinity: 0.00323564, balance: 0.061774, coact: 0.0343838, frob: 0.000270658\n",
      "step 21700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.165649 \n",
      " Validation: accuracy: 0.992188 loss: 0.216238\n",
      " cross_entropy: 0.0623035, clust_cross_entropy: 0.0755385, affinity: 0.000702698, balance: 0.0443245, coact: 0.0156377, frob: 0.000265858\n",
      "step 21800/50000 \n",
      " Train: accuracy: 1, loss: 0.198895 \n",
      " Validation: accuracy: 0.992188 loss: 0.255808\n",
      " cross_entropy: 0.0423941, clust_cross_entropy: 0.0680446, affinity: 0.0022423, balance: 0.0993308, coact: 0.0156763, frob: 0.000266699\n",
      "step 21900/50000 \n",
      " Train: accuracy: 1, loss: 0.204604 \n",
      " Validation: accuracy: 0.984375 loss: 0.266806\n",
      " cross_entropy: 0.0292489, clust_cross_entropy: 0.0445299, affinity: 0.00127109, balance: 0.110843, coact: 0.0192644, frob: 0.000274223\n",
      "step 22000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.377803 \n",
      " Validation: accuracy: 0.992188 loss: 0.20424\n",
      " cross_entropy: 0.108465, clust_cross_entropy: 0.152108, affinity: 0.00189158, balance: 0.0314078, coact: 0.00557492, frob: 0.00027063\n",
      "step 22100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.398471 \n",
      " Validation: accuracy: 0.984375 loss: 0.173803\n",
      " cross_entropy: 0.0717132, clust_cross_entropy: 0.0943551, affinity: 0.000831332, balance: 0.109915, coact: 0.0356048, frob: 0.000272218\n",
      "step 22200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.297106 \n",
      " Validation: accuracy: 0.976562 loss: 0.343292\n",
      " cross_entropy: 0.0516386, clust_cross_entropy: 0.108407, affinity: 0.000734988, balance: 0.121393, coact: 0.00485067, frob: 0.000271061\n",
      "step 22300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.233224 \n",
      " Validation: accuracy: 0.984375 loss: 0.364921\n",
      " cross_entropy: 0.0667925, clust_cross_entropy: 0.108681, affinity: 0.00210564, balance: 0.14454, coact: 0.0137033, frob: 0.000276249\n",
      "step 22400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.305697 \n",
      " Validation: accuracy: 0.945312 loss: 0.392781\n",
      " cross_entropy: 0.0637715, clust_cross_entropy: 0.121481, affinity: 0.00179356, balance: 0.0462027, coact: 0.0116536, frob: 0.000270247\n",
      "step 22500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.300145 \n",
      " Validation: accuracy: 0.96875 loss: 0.386977\n",
      " cross_entropy: 0.0544307, clust_cross_entropy: 0.112104, affinity: 0.00100445, balance: 0.0990785, coact: 0.00355543, frob: 0.000280832\n",
      "step 22600/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.29402 \n",
      " Validation: accuracy: 0.976562 loss: 0.403223\n",
      " cross_entropy: 0.10196, clust_cross_entropy: 0.155624, affinity: 9.28174e-05, balance: 0.126649, coact: 0.00159558, frob: 0.000272528\n",
      "step 22700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.191204 \n",
      " Validation: accuracy: 0.992188 loss: 0.255812\n",
      " cross_entropy: 0.0493878, clust_cross_entropy: 0.0460966, affinity: 0, balance: 0.0842105, coact: 0.00869493, frob: 0.000283566\n",
      "step 22800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.431984 \n",
      " Validation: accuracy: 0.976562 loss: 0.359245\n",
      " cross_entropy: 0.105687, clust_cross_entropy: 0.14872, affinity: 0.000662164, balance: 0.0744899, coact: 0.0207008, frob: 0.000276241\n",
      "step 22900/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.308658 \n",
      " Validation: accuracy: 1 loss: 0.163331\n",
      " cross_entropy: 0.116228, clust_cross_entropy: 0.07573, affinity: 0.000312631, balance: 0.0251776, coact: 0.00908298, frob: 0.000272507\n",
      "step 23000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.407101 \n",
      " Validation: accuracy: 0.96875 loss: 0.320732\n",
      " cross_entropy: 0.0650535, clust_cross_entropy: 0.133075, affinity: 0.00342315, balance: 0.162678, coact: 0.00783532, frob: 0.000280201\n",
      "step 23100/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.428616 \n",
      " Validation: accuracy: 0.984375 loss: 0.404617\n",
      " cross_entropy: 0.12716, clust_cross_entropy: 0.117961, affinity: 0.00107128, balance: 0.149507, coact: 0.0211603, frob: 0.000278136\n",
      "step 23200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.291953 \n",
      " Validation: accuracy: 0.96875 loss: 0.374838\n",
      " cross_entropy: 0.0787989, clust_cross_entropy: 0.0380262, affinity: 0.000892157, balance: 0.114601, coact: 0.00581131, frob: 0.000274606\n",
      "step 23300/50000 \n",
      " Train: accuracy: 0.953125, loss: 0.321728 \n",
      " Validation: accuracy: 0.953125 loss: 0.470901\n",
      " cross_entropy: 0.106066, clust_cross_entropy: 0.117414, affinity: 0.00190442, balance: 0.0600396, coact: 0.0111429, frob: 0.000282308\n",
      "step 23400/50000 \n",
      " Train: accuracy: 1, loss: 0.234022 \n",
      " Validation: accuracy: 0.992188 loss: 0.342727\n",
      " cross_entropy: 0.0541356, clust_cross_entropy: 0.0981484, affinity: 0.00241853, balance: 0.122131, coact: 0.0108877, frob: 0.000280706\n",
      "step 23500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.30798 \n",
      " Validation: accuracy: 1 loss: 0.193515\n",
      " cross_entropy: 0.0722503, clust_cross_entropy: 0.111131, affinity: 0.000805714, balance: 0.139558, coact: 0.0155261, frob: 0.000285721\n",
      "step 23600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.133767 \n",
      " Validation: accuracy: 0.976562 loss: 0.320634\n",
      " cross_entropy: 0.0363421, clust_cross_entropy: 0.0551012, affinity: 0.000247774, balance: 0.0741292, coact: 0.0225585, frob: 0.000276204\n",
      "step 23700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.313373 \n",
      " Validation: accuracy: 0.960938 loss: 0.256559\n",
      " cross_entropy: 0.0449296, clust_cross_entropy: 0.131574, affinity: 0.000886711, balance: 0.130747, coact: 0.0108858, frob: 0.000280524\n",
      "step 23800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.103411 \n",
      " Validation: accuracy: 0.976562 loss: 0.375475\n",
      " cross_entropy: 0.0618737, clust_cross_entropy: 0.08233, affinity: 0.00197575, balance: 0.0397633, coact: 0.0182241, frob: 0.000270996\n",
      "step 23900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.285962 \n",
      " Validation: accuracy: 0.984375 loss: 0.178581\n",
      " cross_entropy: 0.0584857, clust_cross_entropy: 0.126943, affinity: 0.00139568, balance: 0.137082, coact: 0.00645845, frob: 0.000290851\n",
      "step 24000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.494523 \n",
      " Validation: accuracy: 0.976562 loss: 0.309255\n",
      " cross_entropy: 0.0833673, clust_cross_entropy: 0.239388, affinity: 0.000770318, balance: 0.0496334, coact: 0.00246175, frob: 0.000267716\n",
      "step 24100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.189362 \n",
      " Validation: accuracy: 0.960938 loss: 0.378662\n",
      " cross_entropy: 0.0749009, clust_cross_entropy: 0.10171, affinity: 0.000589434, balance: 0.0629946, coact: 0.00662697, frob: 0.000287143\n",
      "step 24200/50000 \n",
      " Train: accuracy: 1, loss: 0.208268 \n",
      " Validation: accuracy: 1 loss: 0.290425\n",
      " cross_entropy: 0.0423445, clust_cross_entropy: 0.0702819, affinity: 0.000973459, balance: 0.100117, coact: 0.00362905, frob: 0.000278736\n",
      "step 24300/50000 \n",
      " Train: accuracy: 1, loss: 0.128077 \n",
      " Validation: accuracy: 0.96875 loss: 0.37358\n",
      " cross_entropy: 0.0504299, clust_cross_entropy: 0.0560835, affinity: 0.00143297, balance: 0.0713342, coact: 0.0248548, frob: 0.000273115\n",
      "step 24400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.375105 \n",
      " Validation: accuracy: 0.992188 loss: 0.173652\n",
      " cross_entropy: 0.0673302, clust_cross_entropy: 0.133154, affinity: 0.00137535, balance: 0.153209, coact: 0.0118302, frob: 0.00027034\n",
      "step 24500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.438245 \n",
      " Validation: accuracy: 0.960938 loss: 0.430456\n",
      " cross_entropy: 0.103007, clust_cross_entropy: 0.189797, affinity: 2.63381e-05, balance: 0.15101, coact: 0.00870513, frob: 0.00027891\n",
      "step 24600/50000 \n",
      " Train: accuracy: 1, loss: 0.244919 \n",
      " Validation: accuracy: 0.984375 loss: 0.241536\n",
      " cross_entropy: 0.0330072, clust_cross_entropy: 0.0581566, affinity: 0.00057799, balance: 0.216432, coact: 0.0108022, frob: 0.000270814\n",
      "step 24700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.262997 \n",
      " Validation: accuracy: 0.976562 loss: 0.396932\n",
      " cross_entropy: 0.0634279, clust_cross_entropy: 0.0801058, affinity: 0.00146503, balance: 0.163413, coact: 0.0201741, frob: 0.000280843\n",
      "step 24800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.24027 \n",
      " Validation: accuracy: 0.984375 loss: 0.306525\n",
      " cross_entropy: 0.0818174, clust_cross_entropy: 0.184656, affinity: 0.00157545, balance: 0.0940225, coact: 0.0169926, frob: 0.000278649\n",
      "step 24900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.193172 \n",
      " Validation: accuracy: 0.96875 loss: 0.40517\n",
      " cross_entropy: 0.0570991, clust_cross_entropy: 0.0654037, affinity: 0.00141798, balance: 0.0470612, coact: 0.00656417, frob: 0.000285767\n",
      "step 25000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.315215 \n",
      " Validation: accuracy: 0.976562 loss: 0.214179\n",
      " cross_entropy: 0.0670619, clust_cross_entropy: 0.218714, affinity: 0.00166705, balance: 0.0766452, coact: 0.0240743, frob: 0.000280136\n",
      "step 25100/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.237246 \n",
      " Validation: accuracy: 0.976562 loss: 0.356589\n",
      " cross_entropy: 0.0484421, clust_cross_entropy: 0.0589617, affinity: 0.00080676, balance: 0.0293034, coact: 0.0294526, frob: 0.00026734\n",
      "step 25200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.20704 \n",
      " Validation: accuracy: 0.984375 loss: 0.270203\n",
      " cross_entropy: 0.0325475, clust_cross_entropy: 0.0534058, affinity: 0.0018858, balance: 0.124608, coact: 0.0196952, frob: 0.000280012\n",
      "step 25300/50000 \n",
      " Train: accuracy: 1, loss: 0.203091 \n",
      " Validation: accuracy: 0.984375 loss: 0.298273\n",
      " cross_entropy: 0.0518307, clust_cross_entropy: 0.0745629, affinity: 0.00247003, balance: 0.091512, coact: 0.0115512, frob: 0.000282633\n",
      "step 25400/50000 \n",
      " Train: accuracy: 1, loss: 0.072391 \n",
      " Validation: accuracy: 0.984375 loss: 0.285292\n",
      " cross_entropy: 0.0278786, clust_cross_entropy: 0.0287421, affinity: 0.000320054, balance: 0.0356597, coact: 0.00682652, frob: 0.000275281\n",
      "step 25500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.161797 \n",
      " Validation: accuracy: 0.992188 loss: 0.23997\n",
      " cross_entropy: 0.0708435, clust_cross_entropy: 0.0721564, affinity: 0.00101902, balance: 0.0526139, coact: 0.00123706, frob: 0.000276442\n",
      "step 25600/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.539614 \n",
      " Validation: accuracy: 0.992188 loss: 0.192272\n",
      " cross_entropy: 0.110894, clust_cross_entropy: 0.131526, affinity: 0.000731079, balance: 0.114545, coact: 0.00815765, frob: 0.00028902\n",
      "step 25700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.277536 \n",
      " Validation: accuracy: 0.984375 loss: 0.179354\n",
      " cross_entropy: 0.0581054, clust_cross_entropy: 0.0983139, affinity: 0.000201509, balance: 0.073618, coact: 0.0082203, frob: 0.000283727\n",
      "step 25800/50000 \n",
      " Train: accuracy: 1, loss: 0.209082 \n",
      " Validation: accuracy: 0.984375 loss: 0.168228\n",
      " cross_entropy: 0.0638975, clust_cross_entropy: 0.0766885, affinity: 0.0015366, balance: 0.0587261, coact: 0.0146537, frob: 0.000284887\n",
      "step 25900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.156549 \n",
      " Validation: accuracy: 0.992188 loss: 0.151653\n",
      " cross_entropy: 0.0334216, clust_cross_entropy: 0.0537261, affinity: 0.00144711, balance: 0.0631835, coact: 0.00379211, frob: 0.000284716\n",
      "step 26000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.238135 \n",
      " Validation: accuracy: 0.984375 loss: 0.209671\n",
      " cross_entropy: 0.0636771, clust_cross_entropy: 0.0607648, affinity: 0.000318234, balance: 0.129376, coact: 0.012933, frob: 0.00028703\n",
      "step 26100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.381333 \n",
      " Validation: accuracy: 0.992188 loss: 0.22957\n",
      " cross_entropy: 0.0497992, clust_cross_entropy: 0.126916, affinity: 0.00147956, balance: 0.117663, coact: 0.0094541, frob: 0.00029007\n",
      "step 26200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.472452 \n",
      " Validation: accuracy: 0.976562 loss: 0.529774\n",
      " cross_entropy: 0.104831, clust_cross_entropy: 0.0847685, affinity: 0.00201811, balance: 0.0815809, coact: 0.00887868, frob: 0.000288662\n",
      "step 26300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.308208 \n",
      " Validation: accuracy: 0.976562 loss: 0.322886\n",
      " cross_entropy: 0.0629333, clust_cross_entropy: 0.0979525, affinity: 0.000455086, balance: 0.103633, coact: 0.010036, frob: 0.000286549\n",
      "step 26400/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.42012 \n",
      " Validation: accuracy: 1 loss: 0.121711\n",
      " cross_entropy: 0.0716647, clust_cross_entropy: 0.103656, affinity: 0.000909358, balance: 0.124277, coact: 0.0231528, frob: 0.000285332\n",
      "step 26500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.168327 \n",
      " Validation: accuracy: 0.984375 loss: 0.278205\n",
      " cross_entropy: 0.0960303, clust_cross_entropy: 0.115484, affinity: 0.000417761, balance: 0.0500083, coact: 0.0143966, frob: 0.000283117\n",
      "step 26600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.15474 \n",
      " Validation: accuracy: 0.992188 loss: 0.242678\n",
      " cross_entropy: 0.0357891, clust_cross_entropy: 0.10565, affinity: 0.000875138, balance: 0.0592741, coact: 0.0253422, frob: 0.000281978\n",
      "step 26700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.23181 \n",
      " Validation: accuracy: 0.976562 loss: 0.281734\n",
      " cross_entropy: 0.0404108, clust_cross_entropy: 0.0670378, affinity: 0.00106326, balance: 0.0843037, coact: 0.00472472, frob: 0.000278182\n",
      "step 26800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.230781 \n",
      " Validation: accuracy: 0.96875 loss: 0.389285\n",
      " cross_entropy: 0.0471262, clust_cross_entropy: 0.0480118, affinity: 0.00182037, balance: 0.0799448, coact: 0.00644061, frob: 0.00028702\n",
      "step 26900/50000 \n",
      " Train: accuracy: 1, loss: 0.180201 \n",
      " Validation: accuracy: 1 loss: 0.22701\n",
      " cross_entropy: 0.0433085, clust_cross_entropy: 0.0777485, affinity: 0.00060964, balance: 0.0634194, coact: 0.00438953, frob: 0.000276716\n",
      "step 27000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.241066 \n",
      " Validation: accuracy: 0.960938 loss: 0.340738\n",
      " cross_entropy: 0.0418489, clust_cross_entropy: 0.107026, affinity: 0.000730619, balance: 0.128774, coact: 0.0147208, frob: 0.000286973\n",
      "step 27100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.270831 \n",
      " Validation: accuracy: 0.976562 loss: 0.277644\n",
      " cross_entropy: 0.0421406, clust_cross_entropy: 0.0751631, affinity: 0.00234872, balance: 0.0564419, coact: 0.0222559, frob: 0.000280492\n",
      "step 27200/50000 \n",
      " Train: accuracy: 1, loss: 0.212941 \n",
      " Validation: accuracy: 0.984375 loss: 0.184675\n",
      " cross_entropy: 0.0521468, clust_cross_entropy: 0.0802016, affinity: 0.000254621, balance: 0.0797051, coact: 0.00668286, frob: 0.000292436\n",
      "step 27300/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.446103 \n",
      " Validation: accuracy: 0.992188 loss: 0.153452\n",
      " cross_entropy: 0.0969106, clust_cross_entropy: 0.0949214, affinity: 0.00100178, balance: 0.215606, coact: 0.00927732, frob: 0.000286553\n",
      "step 27400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.220574 \n",
      " Validation: accuracy: 1 loss: 0.202774\n",
      " cross_entropy: 0.0463267, clust_cross_entropy: 0.0213332, affinity: 0.000963227, balance: 0.0365701, coact: 0.011168, frob: 0.000292202\n",
      "step 27500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.301532 \n",
      " Validation: accuracy: 0.984375 loss: 0.203378\n",
      " cross_entropy: 0.069175, clust_cross_entropy: 0.176061, affinity: 0.00148459, balance: 0.0682358, coact: 0.00733684, frob: 0.000298284\n",
      "step 27600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.262005 \n",
      " Validation: accuracy: 0.984375 loss: 0.202361\n",
      " cross_entropy: 0.0280208, clust_cross_entropy: 0.0942144, affinity: 2.38932e-05, balance: 0.0707076, coact: 0.0210382, frob: 0.000284986\n",
      "step 27700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.172824 \n",
      " Validation: accuracy: 0.992188 loss: 0.152654\n",
      " cross_entropy: 0.0852899, clust_cross_entropy: 0.0387739, affinity: 0.000245312, balance: 0.0979258, coact: 0.0174992, frob: 0.000285146\n",
      "step 27800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.384824 \n",
      " Validation: accuracy: 0.945312 loss: 0.398106\n",
      " cross_entropy: 0.145263, clust_cross_entropy: 0.0933324, affinity: 0.00121804, balance: 0.0575454, coact: 0.0159051, frob: 0.000283527\n",
      "step 27900/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.356668 \n",
      " Validation: accuracy: 0.976562 loss: 0.455891\n",
      " cross_entropy: 0.100879, clust_cross_entropy: 0.204949, affinity: 0.001319, balance: 0.0810853, coact: 0.00249776, frob: 0.000283725\n",
      "step 28000/50000 \n",
      " Train: accuracy: 1, loss: 0.162258 \n",
      " Validation: accuracy: 0.984375 loss: 0.291081\n",
      " cross_entropy: 0.0516595, clust_cross_entropy: 0.0938137, affinity: 0.00018626, balance: 0.0964293, coact: 0.0100676, frob: 0.000296725\n",
      "step 28100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.192258 \n",
      " Validation: accuracy: 0.992188 loss: 0.25199\n",
      " cross_entropy: 0.0238815, clust_cross_entropy: 0.0194822, affinity: 0.000931791, balance: 0.0641465, coact: 0.0190892, frob: 0.00030333\n",
      "step 28200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.360709 \n",
      " Validation: accuracy: 0.984375 loss: 0.356658\n",
      " cross_entropy: 0.0696841, clust_cross_entropy: 0.120698, affinity: 0.00112855, balance: 0.123189, coact: 0.0177205, frob: 0.000302585\n",
      "step 28300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.207396 \n",
      " Validation: accuracy: 0.984375 loss: 0.223932\n",
      " cross_entropy: 0.0800761, clust_cross_entropy: 0.16494, affinity: 0.000663519, balance: 0.0500372, coact: 0.00897369, frob: 0.000282521\n",
      "step 28400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.22805 \n",
      " Validation: accuracy: 0.976562 loss: 0.450799\n",
      " cross_entropy: 0.0360545, clust_cross_entropy: 0.0444672, affinity: 2.74733e-05, balance: 0.154163, coact: 0.0151424, frob: 0.000288367\n",
      "step 28500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.233485 \n",
      " Validation: accuracy: 0.984375 loss: 0.209943\n",
      " cross_entropy: 0.0345187, clust_cross_entropy: 0.0634066, affinity: 0.00147558, balance: 0.0972617, coact: 0.00702615, frob: 0.00028425\n",
      "step 28600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.228583 \n",
      " Validation: accuracy: 0.992188 loss: 0.131694\n",
      " cross_entropy: 0.0424246, clust_cross_entropy: 0.0719686, affinity: 0.00211597, balance: 0.0864139, coact: 0.0125776, frob: 0.000287314\n",
      "step 28700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.273711 \n",
      " Validation: accuracy: 0.984375 loss: 0.287614\n",
      " cross_entropy: 0.0311455, clust_cross_entropy: 0.0609711, affinity: 0.000535495, balance: 0.10304, coact: 0.0045343, frob: 0.000284256\n",
      "step 28800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.227645 \n",
      " Validation: accuracy: 1 loss: 0.0790758\n",
      " cross_entropy: 0.0443668, clust_cross_entropy: 0.0477991, affinity: 0.000869516, balance: 0.120141, coact: 0.00444475, frob: 0.000300342\n",
      "step 28900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.144649 \n",
      " Validation: accuracy: 0.960938 loss: 0.320933\n",
      " cross_entropy: 0.0357117, clust_cross_entropy: 0.0544676, affinity: 0.000741617, balance: 0.0426205, coact: 0.0134555, frob: 0.000296643\n",
      "step 29000/50000 \n",
      " Train: accuracy: 1, loss: 0.262014 \n",
      " Validation: accuracy: 0.984375 loss: 0.266857\n",
      " cross_entropy: 0.0585746, clust_cross_entropy: 0.08791, affinity: 0.000390473, balance: 0.0572373, coact: 0.0039358, frob: 0.000287176\n",
      "step 29100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.154635 \n",
      " Validation: accuracy: 0.96875 loss: 0.363726\n",
      " cross_entropy: 0.0637715, clust_cross_entropy: 0.0881394, affinity: 0.00116429, balance: 0.0648907, coact: 0.00130847, frob: 0.000291346\n",
      "step 29200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.250754 \n",
      " Validation: accuracy: 0.992188 loss: 0.260821\n",
      " cross_entropy: 0.044405, clust_cross_entropy: 0.152601, affinity: 0.00080527, balance: 0.128747, coact: 0.00495961, frob: 0.000288731\n",
      "step 29300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.288347 \n",
      " Validation: accuracy: 0.96875 loss: 0.313968\n",
      " cross_entropy: 0.0360806, clust_cross_entropy: 0.133639, affinity: 0.000578543, balance: 0.0690667, coact: 0.00534174, frob: 0.000300989\n",
      "step 29400/50000 \n",
      " Train: accuracy: 1, loss: 0.233511 \n",
      " Validation: accuracy: 0.984375 loss: 0.344312\n",
      " cross_entropy: 0.0347585, clust_cross_entropy: 0.0957642, affinity: 0.00160189, balance: 0.0915564, coact: 0.00276127, frob: 0.000292664\n",
      "step 29500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.322724 \n",
      " Validation: accuracy: 1 loss: 0.158322\n",
      " cross_entropy: 0.0406773, clust_cross_entropy: 0.106665, affinity: 0.00102162, balance: 0.163059, coact: 0.0121463, frob: 0.000292699\n",
      "step 29600/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.498867 \n",
      " Validation: accuracy: 0.984375 loss: 0.187512\n",
      " cross_entropy: 0.064688, clust_cross_entropy: 0.144281, affinity: 0.00120422, balance: 0.0997619, coact: 0.010605, frob: 0.000290741\n",
      "step 29700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.331742 \n",
      " Validation: accuracy: 0.984375 loss: 0.275049\n",
      " cross_entropy: 0.0402147, clust_cross_entropy: 0.176958, affinity: 0.00095325, balance: 0.163143, coact: 0.0136792, frob: 0.000291623\n",
      "step 29800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.300156 \n",
      " Validation: accuracy: 1 loss: 0.250326\n",
      " cross_entropy: 0.0791885, clust_cross_entropy: 0.148828, affinity: 0.00124782, balance: 0.10876, coact: 0.010715, frob: 0.0002976\n",
      "step 29900/50000 \n",
      " Train: accuracy: 1, loss: 0.107013 \n",
      " Validation: accuracy: 0.984375 loss: 0.316191\n",
      " cross_entropy: 0.0437103, clust_cross_entropy: 0.0170712, affinity: 0.00130202, balance: 0.0746359, coact: 0.00406252, frob: 0.00028012\n",
      "step 30000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.224458 \n",
      " Validation: accuracy: 0.976562 loss: 0.267996\n",
      " cross_entropy: 0.0198863, clust_cross_entropy: 0.0565621, affinity: 0.000608919, balance: 0.0803712, coact: 0.00720392, frob: 0.000294312\n",
      "step 30100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.246181 \n",
      " Validation: accuracy: 0.976562 loss: 0.335039\n",
      " cross_entropy: 0.0445682, clust_cross_entropy: 0.105792, affinity: 0.00135177, balance: 0.0903966, coact: 0.00408192, frob: 0.000283054\n",
      "step 30200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.214368 \n",
      " Validation: accuracy: 0.984375 loss: 0.238955\n",
      " cross_entropy: 0.0715769, clust_cross_entropy: 0.063345, affinity: 0.00122331, balance: 0.0965027, coact: 0.00127018, frob: 0.000295436\n",
      "step 30300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.150328 \n",
      " Validation: accuracy: 0.992188 loss: 0.25504\n",
      " cross_entropy: 0.0311915, clust_cross_entropy: 0.0551084, affinity: 0.000271206, balance: 0.0257049, coact: 0.00504712, frob: 0.000305367\n",
      "step 30400/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.337446 \n",
      " Validation: accuracy: 1 loss: 0.128074\n",
      " cross_entropy: 0.076831, clust_cross_entropy: 0.106876, affinity: 0.000417305, balance: 0.0595893, coact: 0.00856459, frob: 0.000288316\n",
      "step 30500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.346562 \n",
      " Validation: accuracy: 0.976562 loss: 0.29525\n",
      " cross_entropy: 0.0780625, clust_cross_entropy: 0.0426158, affinity: 0.000985261, balance: 0.172307, coact: 0.00475962, frob: 0.000299261\n",
      "step 30600/50000 \n",
      " Train: accuracy: 1, loss: 0.11661 \n",
      " Validation: accuracy: 0.984375 loss: 0.194502\n",
      " cross_entropy: 0.035453, clust_cross_entropy: 0.0297465, affinity: 0.00141124, balance: 0.0830771, coact: 0.0109443, frob: 0.000311404\n",
      "step 30700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.208931 \n",
      " Validation: accuracy: 0.992188 loss: 0.187123\n",
      " cross_entropy: 0.0136631, clust_cross_entropy: 0.0118394, affinity: 0.000470902, balance: 0.117812, coact: 0.00340091, frob: 0.000310271\n",
      "step 30800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.340758 \n",
      " Validation: accuracy: 0.976562 loss: 0.292892\n",
      " cross_entropy: 0.0426261, clust_cross_entropy: 0.174766, affinity: 0.000888048, balance: 0.105683, coact: 0.00404322, frob: 0.000296987\n",
      "step 30900/50000 \n",
      " Train: accuracy: 1, loss: 0.133359 \n",
      " Validation: accuracy: 0.992188 loss: 0.175113\n",
      " cross_entropy: 0.0369069, clust_cross_entropy: 0.02425, affinity: 0.00154865, balance: 0.0500102, coact: 0.00304368, frob: 0.000303891\n",
      "step 31000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.306324 \n",
      " Validation: accuracy: 0.984375 loss: 0.193949\n",
      " cross_entropy: 0.0587769, clust_cross_entropy: 0.111907, affinity: 0.00120255, balance: 0.120359, coact: 0.0131681, frob: 0.000299997\n",
      "step 31100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.17415 \n",
      " Validation: accuracy: 0.976562 loss: 0.229255\n",
      " cross_entropy: 0.0801904, clust_cross_entropy: 0.101971, affinity: 0.00173286, balance: 0.0610993, coact: 0.000876876, frob: 0.000306936\n",
      "step 31200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.275043 \n",
      " Validation: accuracy: 0.960938 loss: 0.47342\n",
      " cross_entropy: 0.0599105, clust_cross_entropy: 0.0589275, affinity: 0.00059655, balance: 0.0731542, coact: 0.00340083, frob: 0.000303413\n",
      "step 31300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.206348 \n",
      " Validation: accuracy: 1 loss: 0.0866803\n",
      " cross_entropy: 0.0278392, clust_cross_entropy: 0.0512019, affinity: 0.00164197, balance: 0.104888, coact: 0.0235403, frob: 0.000289008\n",
      "step 31400/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.33649 \n",
      " Validation: accuracy: 0.984375 loss: 0.215619\n",
      " cross_entropy: 0.0489966, clust_cross_entropy: 0.0663899, affinity: 0.000603949, balance: 0.158706, coact: 0.00724864, frob: 0.000289957\n",
      "step 31500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.230189 \n",
      " Validation: accuracy: 0.96875 loss: 0.180177\n",
      " cross_entropy: 0.0615347, clust_cross_entropy: 0.13013, affinity: 0.000942379, balance: 0.0724753, coact: 0.0125014, frob: 0.000289657\n",
      "step 31600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.138122 \n",
      " Validation: accuracy: 0.984375 loss: 0.21737\n",
      " cross_entropy: 0.0439654, clust_cross_entropy: 0.0642822, affinity: 0.00114932, balance: 0.0500765, coact: 0.0163806, frob: 0.00029311\n",
      "step 31700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.300112 \n",
      " Validation: accuracy: 0.992188 loss: 0.20374\n",
      " cross_entropy: 0.0280639, clust_cross_entropy: 0.151358, affinity: 0.000612566, balance: 0.154534, coact: 0.0190989, frob: 0.000315311\n",
      "step 31800/50000 \n",
      " Train: accuracy: 1, loss: 0.188288 \n",
      " Validation: accuracy: 0.984375 loss: 0.285685\n",
      " cross_entropy: 0.0500878, clust_cross_entropy: 0.0824729, affinity: 0.00106778, balance: 0.0876402, coact: 0.00300238, frob: 0.000291332\n",
      "step 31900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.111507 \n",
      " Validation: accuracy: 0.96875 loss: 0.475077\n",
      " cross_entropy: 0.0339158, clust_cross_entropy: 0.0179189, affinity: 0.000244496, balance: 0.0998273, coact: 0.0025934, frob: 0.00029962\n",
      "step 32000/50000 \n",
      " Train: accuracy: 1, loss: 0.109554 \n",
      " Validation: accuracy: 0.960938 loss: 0.304704\n",
      " cross_entropy: 0.0369951, clust_cross_entropy: 0.0504461, affinity: 0.00128105, balance: 0.0856621, coact: 0.00585039, frob: 0.000293002\n",
      "step 32100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.229812 \n",
      " Validation: accuracy: 1 loss: 0.103877\n",
      " cross_entropy: 0.0417078, clust_cross_entropy: 0.0709676, affinity: 0.000445549, balance: 0.145841, coact: 0.00770786, frob: 0.000304703\n",
      "step 32200/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.336325 \n",
      " Validation: accuracy: 0.992188 loss: 0.141772\n",
      " cross_entropy: 0.0809552, clust_cross_entropy: 0.114886, affinity: 0.00104274, balance: 0.147817, coact: 0.0136641, frob: 0.000302123\n",
      "step 32300/50000 \n",
      " Train: accuracy: 1, loss: 0.187907 \n",
      " Validation: accuracy: 0.976562 loss: 0.368207\n",
      " cross_entropy: 0.057929, clust_cross_entropy: 0.0782197, affinity: 0.00239764, balance: 0.0690956, coact: 0.0127213, frob: 0.0003026\n",
      "step 32400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.272102 \n",
      " Validation: accuracy: 0.976562 loss: 0.440226\n",
      " cross_entropy: 0.0687655, clust_cross_entropy: 0.0912028, affinity: 0.000522013, balance: 0.107605, coact: 0.0114902, frob: 0.000292968\n",
      "step 32500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.317393 \n",
      " Validation: accuracy: 1 loss: 0.240486\n",
      " cross_entropy: 0.0631176, clust_cross_entropy: 0.0627105, affinity: 0.000842835, balance: 0.0734007, coact: 0.0061424, frob: 0.000295975\n",
      "step 32600/50000 \n",
      " Train: accuracy: 0.960938, loss: 0.371272 \n",
      " Validation: accuracy: 0.984375 loss: 0.273261\n",
      " cross_entropy: 0.0953993, clust_cross_entropy: 0.172262, affinity: 0.000400523, balance: 0.10795, coact: 0.00498959, frob: 0.000283031\n",
      "step 32700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.272335 \n",
      " Validation: accuracy: 0.992188 loss: 0.248233\n",
      " cross_entropy: 0.0761651, clust_cross_entropy: 0.0848084, affinity: 0.000356457, balance: 0.118603, coact: 0.00108284, frob: 0.00029497\n",
      "step 32800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.341093 \n",
      " Validation: accuracy: 0.960938 loss: 0.275885\n",
      " cross_entropy: 0.0485759, clust_cross_entropy: 0.137178, affinity: 0.00172793, balance: 0.157501, coact: 0.00449924, frob: 0.00029708\n",
      "step 32900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.219612 \n",
      " Validation: accuracy: 0.992188 loss: 0.147022\n",
      " cross_entropy: 0.0830249, clust_cross_entropy: 0.0460287, affinity: 0.000538108, balance: 0.0167087, coact: 0.0056213, frob: 0.00030489\n",
      "step 33000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.221107 \n",
      " Validation: accuracy: 0.984375 loss: 0.292607\n",
      " cross_entropy: 0.0336422, clust_cross_entropy: 0.101515, affinity: 0.000617218, balance: 0.1154, coact: 7.81338e-05, frob: 0.000301821\n",
      "step 33100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.215372 \n",
      " Validation: accuracy: 0.992188 loss: 0.320486\n",
      " cross_entropy: 0.0155061, clust_cross_entropy: 0.0763876, affinity: 0.00033273, balance: 0.033835, coact: 0.00831729, frob: 0.000296995\n",
      "step 33200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.402729 \n",
      " Validation: accuracy: 0.976562 loss: 0.331517\n",
      " cross_entropy: 0.13014, clust_cross_entropy: 0.182747, affinity: 0.000278996, balance: 0.0457324, coact: 0.0110275, frob: 0.000292578\n",
      "step 33300/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.295079 \n",
      " Validation: accuracy: 0.984375 loss: 0.291574\n",
      " cross_entropy: 0.0520427, clust_cross_entropy: 0.0498125, affinity: 0.000647393, balance: 0.0891238, coact: 0.000176173, frob: 0.000297836\n",
      "step 33400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.248802 \n",
      " Validation: accuracy: 0.992188 loss: 0.160234\n",
      " cross_entropy: 0.0144009, clust_cross_entropy: 0.1435, affinity: 0.000126639, balance: 0.118243, coact: 0.00713586, frob: 0.000305863\n",
      "step 33500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.342074 \n",
      " Validation: accuracy: 0.984375 loss: 0.273739\n",
      " cross_entropy: 0.0713216, clust_cross_entropy: 0.0870388, affinity: 0.000516391, balance: 0.117616, coact: 0.00550621, frob: 0.000307734\n",
      "step 33600/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.275216 \n",
      " Validation: accuracy: 0.96875 loss: 0.466068\n",
      " cross_entropy: 0.0195884, clust_cross_entropy: 0.1092, affinity: 0.000180403, balance: 0.153956, coact: 0.0061085, frob: 0.000307943\n",
      "step 33700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.262595 \n",
      " Validation: accuracy: 0.984375 loss: 0.230628\n",
      " cross_entropy: 0.0672125, clust_cross_entropy: 0.0944826, affinity: 0.000926697, balance: 0.0695004, coact: 0.0113152, frob: 0.000297862\n",
      "step 33800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.359695 \n",
      " Validation: accuracy: 0.984375 loss: 0.200305\n",
      " cross_entropy: 0.0721881, clust_cross_entropy: 0.155499, affinity: 0.000340374, balance: 0.0735449, coact: 0.00352955, frob: 0.000308834\n",
      "step 33900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.26789 \n",
      " Validation: accuracy: 0.992188 loss: 0.195218\n",
      " cross_entropy: 0.0559631, clust_cross_entropy: 0.050589, affinity: 0.000916748, balance: 0.146845, coact: 0.00160767, frob: 0.000299833\n",
      "step 34000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.186429 \n",
      " Validation: accuracy: 1 loss: 0.17912\n",
      " cross_entropy: 0.0598112, clust_cross_entropy: 0.0422498, affinity: 0.000936549, balance: 0.114291, coact: 0.00941606, frob: 0.000304251\n",
      "step 34100/50000 \n",
      " Train: accuracy: 1, loss: 0.312732 \n",
      " Validation: accuracy: 1 loss: 0.230657\n",
      " cross_entropy: 0.0362287, clust_cross_entropy: 0.0498423, affinity: 0.00056646, balance: 0.180143, coact: 0.0118646, frob: 0.000318424\n",
      "step 34200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.309439 \n",
      " Validation: accuracy: 0.976562 loss: 0.347905\n",
      " cross_entropy: 0.0252054, clust_cross_entropy: 0.0882554, affinity: 0.000217173, balance: 0.164792, coact: 0.000607986, frob: 0.000301055\n",
      "step 34300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.198909 \n",
      " Validation: accuracy: 0.992188 loss: 0.103904\n",
      " cross_entropy: 0.0273945, clust_cross_entropy: 0.0368583, affinity: 0.000779888, balance: 0.0710939, coact: 0.0111623, frob: 0.000310847\n",
      "step 34400/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.334763 \n",
      " Validation: accuracy: 0.976562 loss: 0.366312\n",
      " cross_entropy: 0.0755237, clust_cross_entropy: 0.072563, affinity: 0.000950795, balance: 0.0306315, coact: 0.00417771, frob: 0.000313943\n",
      "step 34500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.257427 \n",
      " Validation: accuracy: 0.976562 loss: 0.167145\n",
      " cross_entropy: 0.0450246, clust_cross_entropy: 0.119913, affinity: 0.000246762, balance: 0.0714027, coact: 0.00130911, frob: 0.000299947\n",
      "step 34600/50000 \n",
      " Train: accuracy: 1, loss: 0.175777 \n",
      " Validation: accuracy: 1 loss: 0.145029\n",
      " cross_entropy: 0.0265921, clust_cross_entropy: 0.0498952, affinity: 0.000939958, balance: 0.107555, coact: 0.0318118, frob: 0.000311022\n",
      "step 34700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.180931 \n",
      " Validation: accuracy: 0.984375 loss: 0.164753\n",
      " cross_entropy: 0.0395805, clust_cross_entropy: 0.0544832, affinity: 0.000367609, balance: 0.108588, coact: 0.00363606, frob: 0.000312101\n",
      "step 34800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.222166 \n",
      " Validation: accuracy: 0.976562 loss: 0.279555\n",
      " cross_entropy: 0.0489375, clust_cross_entropy: 0.0847068, affinity: 0.000719761, balance: 0.093649, coact: 0.00267611, frob: 0.000309295\n",
      "step 34900/50000 \n",
      " Train: accuracy: 1, loss: 0.066973 \n",
      " Validation: accuracy: 0.992188 loss: 0.297665\n",
      " cross_entropy: 0.0188694, clust_cross_entropy: 0.0237887, affinity: 0.000377606, balance: 0.0513724, coact: 0.0150575, frob: 0.000303885\n",
      "step 35000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.202623 \n",
      " Validation: accuracy: 0.976562 loss: 0.408939\n",
      " cross_entropy: 0.0544972, clust_cross_entropy: 0.0558794, affinity: 8.27402e-05, balance: 0.140963, coact: 0.0048327, frob: 0.000314615\n",
      "step 35100/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.131985 \n",
      " Validation: accuracy: 1 loss: 0.0979814\n",
      " cross_entropy: 0.0571639, clust_cross_entropy: 0.0140955, affinity: 0.00133513, balance: 0.0589294, coact: 0.0118743, frob: 0.000308029\n",
      "step 35200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.198147 \n",
      " Validation: accuracy: 0.992188 loss: 0.170565\n",
      " cross_entropy: 0.0284138, clust_cross_entropy: 0.0451724, affinity: 8.53851e-05, balance: 0.145263, coact: 0.0130791, frob: 0.000317264\n",
      "step 35300/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.334093 \n",
      " Validation: accuracy: 0.984375 loss: 0.288261\n",
      " cross_entropy: 0.0744257, clust_cross_entropy: 0.118562, affinity: 0.000473369, balance: 0.117428, coact: 0.00590695, frob: 0.000314964\n",
      "step 35400/50000 \n",
      " Train: accuracy: 1, loss: 0.165726 \n",
      " Validation: accuracy: 0.984375 loss: 0.317043\n",
      " cross_entropy: 0.0579013, clust_cross_entropy: 0.135434, affinity: 0.000525291, balance: 0.0863195, coact: 0.0112057, frob: 0.000299074\n",
      "step 35500/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.324089 \n",
      " Validation: accuracy: 0.976562 loss: 0.305688\n",
      " cross_entropy: 0.0425362, clust_cross_entropy: 0.087406, affinity: 0.000592115, balance: 0.103145, coact: 0.0157693, frob: 0.00030182\n",
      "step 35600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.234406 \n",
      " Validation: accuracy: 0.992188 loss: 0.225288\n",
      " cross_entropy: 0.0427174, clust_cross_entropy: 0.0810598, affinity: 0.000453639, balance: 0.05927, coact: 0.00565078, frob: 0.000307403\n",
      "step 35700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.152386 \n",
      " Validation: accuracy: 0.992188 loss: 0.184252\n",
      " cross_entropy: 0.0313819, clust_cross_entropy: 0.0265193, affinity: 0.000486087, balance: 0.102125, coact: 0.00753892, frob: 0.000310993\n",
      "step 35800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.168604 \n",
      " Validation: accuracy: 0.984375 loss: 0.171472\n",
      " cross_entropy: 0.032946, clust_cross_entropy: 0.03365, affinity: 0.000524651, balance: 0.0597627, coact: 0, frob: 0.000308551\n",
      "step 35900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.233844 \n",
      " Validation: accuracy: 0.984375 loss: 0.201668\n",
      " cross_entropy: 0.0501424, clust_cross_entropy: 0.0217799, affinity: 0.000731503, balance: 0.0823236, coact: 0.00677134, frob: 0.000304418\n",
      "step 36000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.200004 \n",
      " Validation: accuracy: 0.992188 loss: 0.222408\n",
      " cross_entropy: 0.0457926, clust_cross_entropy: 0.109151, affinity: 0.00216259, balance: 0.101392, coact: 0.000504181, frob: 0.000309896\n",
      "step 36100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.163753 \n",
      " Validation: accuracy: 0.984375 loss: 0.272685\n",
      " cross_entropy: 0.0388702, clust_cross_entropy: 0.0459124, affinity: 0.000754126, balance: 0.0952354, coact: 0.00363237, frob: 0.000323166\n",
      "step 36200/50000 \n",
      " Train: accuracy: 1, loss: 0.144133 \n",
      " Validation: accuracy: 0.984375 loss: 0.178664\n",
      " cross_entropy: 0.0587498, clust_cross_entropy: 0.0696404, affinity: 0.000681075, balance: 0.0744234, coact: 0.0157775, frob: 0.000298528\n",
      "step 36300/50000 \n",
      " Train: accuracy: 1, loss: 0.173259 \n",
      " Validation: accuracy: 0.960938 loss: 0.278313\n",
      " cross_entropy: 0.015287, clust_cross_entropy: 0.0307885, affinity: 0.000263122, balance: 0.149117, coact: 0.0112577, frob: 0.000312404\n",
      "step 36400/50000 \n",
      " Train: accuracy: 1, loss: 0.183819 \n",
      " Validation: accuracy: 0.992188 loss: 0.220258\n",
      " cross_entropy: 0.0202595, clust_cross_entropy: 0.0238283, affinity: 0.000149629, balance: 0.101919, coact: 0.00135933, frob: 0.000322548\n",
      "step 36500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.213963 \n",
      " Validation: accuracy: 0.984375 loss: 0.214757\n",
      " cross_entropy: 0.0227709, clust_cross_entropy: 0.010713, affinity: 0, balance: 0.149783, coact: 0.00520031, frob: 0.00031118\n",
      "step 36600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.263639 \n",
      " Validation: accuracy: 0.984375 loss: 0.329141\n",
      " cross_entropy: 0.0503806, clust_cross_entropy: 0.0310738, affinity: 2.32819e-05, balance: 0.132986, coact: 0.0178978, frob: 0.000314134\n",
      "step 36700/50000 \n",
      " Train: accuracy: 1, loss: 0.140336 \n",
      " Validation: accuracy: 0.992188 loss: 0.206676\n",
      " cross_entropy: 0.0293663, clust_cross_entropy: 0.0464589, affinity: 0.000987195, balance: 0.0479946, coact: 0.00907853, frob: 0.000318861\n",
      "step 36800/50000 \n",
      " Train: accuracy: 1, loss: 0.142584 \n",
      " Validation: accuracy: 1 loss: 0.147485\n",
      " cross_entropy: 0.0117322, clust_cross_entropy: 0.0480739, affinity: 0.000635329, balance: 0.069459, coact: 0.00650587, frob: 0.000306567\n",
      "step 36900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.246729 \n",
      " Validation: accuracy: 0.96875 loss: 0.450938\n",
      " cross_entropy: 0.0437088, clust_cross_entropy: 0.0773149, affinity: 0.000651405, balance: 0.0948489, coact: 0.00288886, frob: 0.00031526\n",
      "step 37000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.231293 \n",
      " Validation: accuracy: 0.976562 loss: 0.283035\n",
      " cross_entropy: 0.0464173, clust_cross_entropy: 0.093647, affinity: 0, balance: 0.0476921, coact: 0, frob: 0.000318106\n",
      "step 37100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.2535 \n",
      " Validation: accuracy: 0.96875 loss: 0.412466\n",
      " cross_entropy: 0.0248086, clust_cross_entropy: 0.0813707, affinity: 0.000698232, balance: 0.0799906, coact: 0.00153931, frob: 0.00031376\n",
      "step 37200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.168401 \n",
      " Validation: accuracy: 0.992188 loss: 0.236753\n",
      " cross_entropy: 0.0228457, clust_cross_entropy: 0.0843769, affinity: 0.000790413, balance: 0.0809332, coact: 0.00444344, frob: 0.000329001\n",
      "step 37300/50000 \n",
      " Train: accuracy: 1, loss: 0.160742 \n",
      " Validation: accuracy: 0.976562 loss: 0.245951\n",
      " cross_entropy: 0.0657229, clust_cross_entropy: 0.0887891, affinity: 0.000868609, balance: 0.0787836, coact: 0.00638962, frob: 0.00030412\n",
      "step 37400/50000 \n",
      " Train: accuracy: 1, loss: 0.206977 \n",
      " Validation: accuracy: 0.984375 loss: 0.214564\n",
      " cross_entropy: 0.0492637, clust_cross_entropy: 0.0429264, affinity: 0.000616834, balance: 0.0875761, coact: 0.00715922, frob: 0.000311624\n",
      "step 37500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.176003 \n",
      " Validation: accuracy: 0.992188 loss: 0.306049\n",
      " cross_entropy: 0.0177332, clust_cross_entropy: 0.0423736, affinity: 0.000295387, balance: 0.0787068, coact: 0.0304388, frob: 0.0003196\n",
      "step 37600/50000 \n",
      " Train: accuracy: 1, loss: 0.226132 \n",
      " Validation: accuracy: 0.984375 loss: 0.281321\n",
      " cross_entropy: 0.0366319, clust_cross_entropy: 0.0377719, affinity: 0.000400227, balance: 0.136177, coact: 0.00855244, frob: 0.000307829\n",
      "step 37700/50000 \n",
      " Train: accuracy: 0.945312, loss: 0.328095 \n",
      " Validation: accuracy: 0.992188 loss: 0.152821\n",
      " cross_entropy: 0.0976589, clust_cross_entropy: 0.0687937, affinity: 0.00102212, balance: 0.10607, coact: 0.00635402, frob: 0.000315009\n",
      "step 37800/50000 \n",
      " Train: accuracy: 1, loss: 0.1174 \n",
      " Validation: accuracy: 0.984375 loss: 0.264429\n",
      " cross_entropy: 0.0151206, clust_cross_entropy: 0.0245109, affinity: 0.000165679, balance: 0.0835184, coact: 0.00421748, frob: 0.000314658\n",
      "step 37900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.243586 \n",
      " Validation: accuracy: 0.992188 loss: 0.11091\n",
      " cross_entropy: 0.0664397, clust_cross_entropy: 0.0620202, affinity: 0.00128266, balance: 0.0718052, coact: 0.00444876, frob: 0.000322331\n",
      "step 38000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.297444 \n",
      " Validation: accuracy: 0.992188 loss: 0.210447\n",
      " cross_entropy: 0.0236395, clust_cross_entropy: 0.0489914, affinity: 0.000230267, balance: 0.15271, coact: 0.00365508, frob: 0.000309239\n",
      "step 38100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.180616 \n",
      " Validation: accuracy: 1 loss: 0.100364\n",
      " cross_entropy: 0.0477808, clust_cross_entropy: 0.0528298, affinity: 0.000242992, balance: 0.0858896, coact: 0.0147346, frob: 0.000314186\n",
      "step 38200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.233922 \n",
      " Validation: accuracy: 1 loss: 0.0765651\n",
      " cross_entropy: 0.0335653, clust_cross_entropy: 0.0532566, affinity: 0.000294192, balance: 0.149697, coact: 0.00317242, frob: 0.000318232\n",
      "step 38300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.29396 \n",
      " Validation: accuracy: 0.992188 loss: 0.093836\n",
      " cross_entropy: 0.0525422, clust_cross_entropy: 0.0890998, affinity: 0.000620793, balance: 0.176158, coact: 0.00526401, frob: 0.000302773\n",
      "step 38400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.132534 \n",
      " Validation: accuracy: 1 loss: 0.112557\n",
      " cross_entropy: 0.0149273, clust_cross_entropy: 0.119289, affinity: 0.00119613, balance: 0.0675252, coact: 0.012018, frob: 0.000317709\n",
      "step 38500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.210847 \n",
      " Validation: accuracy: 0.992188 loss: 0.248434\n",
      " cross_entropy: 0.0280847, clust_cross_entropy: 0.0389449, affinity: 0.000630417, balance: 0.135848, coact: 0.0050286, frob: 0.000310432\n",
      "step 38600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.167376 \n",
      " Validation: accuracy: 0.976562 loss: 0.164388\n",
      " cross_entropy: 0.0282817, clust_cross_entropy: 0.034157, affinity: 0.000620715, balance: 0.0603809, coact: 0.0133945, frob: 0.000304899\n",
      "step 38700/50000 \n",
      " Train: accuracy: 1, loss: 0.0828072 \n",
      " Validation: accuracy: 0.984375 loss: 0.245029\n",
      " cross_entropy: 0.0234459, clust_cross_entropy: 0.0414158, affinity: 0.000851955, balance: 0.0554411, coact: 0.01403, frob: 0.000321035\n",
      "step 38800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.235364 \n",
      " Validation: accuracy: 1 loss: 0.131727\n",
      " cross_entropy: 0.0146615, clust_cross_entropy: 0.0436603, affinity: 0.000707064, balance: 0.0936705, coact: 0.0101732, frob: 0.00032029\n",
      "step 38900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.102674 \n",
      " Validation: accuracy: 1 loss: 0.131327\n",
      " cross_entropy: 0.0501308, clust_cross_entropy: 0.106106, affinity: 0.000321815, balance: 0.0270336, coact: 0.0122203, frob: 0.000319825\n",
      "step 39000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.241733 \n",
      " Validation: accuracy: 0.992188 loss: 0.210088\n",
      " cross_entropy: 0.0362811, clust_cross_entropy: 0.0825217, affinity: 0.000450892, balance: 0.0764245, coact: 0.0032418, frob: 0.000305043\n",
      "step 39100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.187061 \n",
      " Validation: accuracy: 0.984375 loss: 0.298032\n",
      " cross_entropy: 0.0204695, clust_cross_entropy: 0.0712556, affinity: 0.00105939, balance: 0.127091, coact: 0.00276335, frob: 0.000331106\n",
      "step 39200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.188775 \n",
      " Validation: accuracy: 0.992188 loss: 0.22239\n",
      " cross_entropy: 0.0490933, clust_cross_entropy: 0.0337388, affinity: 0.0005355, balance: 0.0670872, coact: 0.00330525, frob: 0.000312702\n",
      "step 39300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.17421 \n",
      " Validation: accuracy: 0.976562 loss: 0.210901\n",
      " cross_entropy: 0.0671001, clust_cross_entropy: 0.105674, affinity: 0.000707311, balance: 0.0450391, coact: 0.00592968, frob: 0.000311162\n",
      "step 39400/50000 \n",
      " Train: accuracy: 1, loss: 0.202278 \n",
      " Validation: accuracy: 0.992188 loss: 0.161182\n",
      " cross_entropy: 0.0301987, clust_cross_entropy: 0.0432902, affinity: 0.00114142, balance: 0.0699129, coact: 0.00729813, frob: 0.000312244\n",
      "step 39500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.208558 \n",
      " Validation: accuracy: 1 loss: 0.13829\n",
      " cross_entropy: 0.0527952, clust_cross_entropy: 0.0403324, affinity: 0.000722464, balance: 0.0549636, coact: 0.00486826, frob: 0.000317403\n",
      "step 39600/50000 \n",
      " Train: accuracy: 1, loss: 0.14636 \n",
      " Validation: accuracy: 0.984375 loss: 0.192365\n",
      " cross_entropy: 0.021717, clust_cross_entropy: 0.0227821, affinity: 0.000846135, balance: 0.128588, coact: 0.0020817, frob: 0.000310489\n",
      "step 39700/50000 \n",
      " Train: accuracy: 1, loss: 0.231091 \n",
      " Validation: accuracy: 0.976562 loss: 0.320535\n",
      " cross_entropy: 0.0320993, clust_cross_entropy: 0.111284, affinity: 0.000326557, balance: 0.127936, coact: 0.0169684, frob: 0.000321278\n",
      "step 39800/50000 \n",
      " Train: accuracy: 1, loss: 0.11625 \n",
      " Validation: accuracy: 0.992188 loss: 0.211652\n",
      " cross_entropy: 0.0396565, clust_cross_entropy: 0.0515117, affinity: 0.000334977, balance: 0.0353354, coact: 0.00699648, frob: 0.00030903\n",
      "step 39900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.188738 \n",
      " Validation: accuracy: 0.992188 loss: 0.119721\n",
      " cross_entropy: 0.0269763, clust_cross_entropy: 0.0202612, affinity: 0.00102736, balance: 0.10156, coact: 0.00340087, frob: 0.000317061\n",
      "step 40000/50000 \n",
      " Train: accuracy: 1, loss: 0.0811716 \n",
      " Validation: accuracy: 1 loss: 0.138564\n",
      " cross_entropy: 0.0415356, clust_cross_entropy: 0.0435945, affinity: 0.00142352, balance: 0.0454727, coact: 0.000603466, frob: 0.000316567\n",
      "step 40100/50000 \n",
      " Train: accuracy: 1, loss: 0.139949 \n",
      " Validation: accuracy: 0.992188 loss: 0.205687\n",
      " cross_entropy: 0.02292, clust_cross_entropy: 0.0920087, affinity: 0.000381469, balance: 0.0461268, coact: 0.00267811, frob: 0.00030599\n",
      "step 40200/50000 \n",
      " Train: accuracy: 1, loss: 0.237656 \n",
      " Validation: accuracy: 0.992188 loss: 0.141155\n",
      " cross_entropy: 0.0466271, clust_cross_entropy: 0.0735886, affinity: 0.000331214, balance: 0.12648, coact: 0.00202894, frob: 0.000313414\n",
      "step 40300/50000 \n",
      " Train: accuracy: 1, loss: 0.182823 \n",
      " Validation: accuracy: 0.984375 loss: 0.328073\n",
      " cross_entropy: 0.0166866, clust_cross_entropy: 0.0230691, affinity: 0.000669303, balance: 0.0873845, coact: 0.00755067, frob: 0.000314361\n",
      "step 40400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.296029 \n",
      " Validation: accuracy: 0.992188 loss: 0.224458\n",
      " cross_entropy: 0.028131, clust_cross_entropy: 0.088437, affinity: 0.000522958, balance: 0.171108, coact: 0.00937137, frob: 0.000316341\n",
      "step 40500/50000 \n",
      " Train: accuracy: 1, loss: 0.104723 \n",
      " Validation: accuracy: 0.976562 loss: 0.259295\n",
      " cross_entropy: 0.00959961, clust_cross_entropy: 0.0360865, affinity: 0.000100999, balance: 0.0814393, coact: 0.0165279, frob: 0.000320767\n",
      "step 40600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.116798 \n",
      " Validation: accuracy: 0.992188 loss: 0.11123\n",
      " cross_entropy: 0.0269664, clust_cross_entropy: 0.0398208, affinity: 0, balance: 0.0867851, coact: 0.0124128, frob: 0.000308081\n",
      "step 40700/50000 \n",
      " Train: accuracy: 1, loss: 0.17177 \n",
      " Validation: accuracy: 1 loss: 0.191821\n",
      " cross_entropy: 0.0153305, clust_cross_entropy: 0.023942, affinity: 0.000428433, balance: 0.150833, coact: 0.0019918, frob: 0.000316137\n",
      "step 40800/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.24817 \n",
      " Validation: accuracy: 1 loss: 0.170323\n",
      " cross_entropy: 0.0286203, clust_cross_entropy: 0.0661446, affinity: 0.00018194, balance: 0.0754269, coact: 0, frob: 0.000313904\n",
      "step 40900/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.323235 \n",
      " Validation: accuracy: 1 loss: 0.159405\n",
      " cross_entropy: 0.0885418, clust_cross_entropy: 0.113726, affinity: 0.00123234, balance: 0.0422251, coact: 0.00995997, frob: 0.000318017\n",
      "step 41000/50000 \n",
      " Train: accuracy: 1, loss: 0.18033 \n",
      " Validation: accuracy: 0.992188 loss: 0.134519\n",
      " cross_entropy: 0.0226315, clust_cross_entropy: 0.0235491, affinity: 0, balance: 0.0979543, coact: 0.00372616, frob: 0.000311568\n",
      "step 41100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.388532 \n",
      " Validation: accuracy: 0.984375 loss: 0.238628\n",
      " cross_entropy: 0.036204, clust_cross_entropy: 0.127485, affinity: 0.00248817, balance: 0.139528, coact: 0.0064406, frob: 0.000316656\n",
      "step 41200/50000 \n",
      " Train: accuracy: 1, loss: 0.162782 \n",
      " Validation: accuracy: 0.992188 loss: 0.255942\n",
      " cross_entropy: 0.0688858, clust_cross_entropy: 0.0238293, affinity: 8.38973e-05, balance: 0.102548, coact: 0.00734184, frob: 0.00031289\n",
      "step 41300/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.280083 \n",
      " Validation: accuracy: 0.984375 loss: 0.185581\n",
      " cross_entropy: 0.106995, clust_cross_entropy: 0.12642, affinity: 0.00114224, balance: 0.061211, coact: 0.00505571, frob: 0.000322594\n",
      "step 41400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.132536 \n",
      " Validation: accuracy: 0.992188 loss: 0.161805\n",
      " cross_entropy: 0.0129517, clust_cross_entropy: 0.0170537, affinity: 0.000109727, balance: 0.0501744, coact: 0.00662156, frob: 0.00032239\n",
      "step 41500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.197255 \n",
      " Validation: accuracy: 1 loss: 0.172854\n",
      " cross_entropy: 0.0312529, clust_cross_entropy: 0.0535412, affinity: 4.45801e-05, balance: 0.0669512, coact: 0.000733456, frob: 0.000316971\n",
      "step 41600/50000 \n",
      " Train: accuracy: 1, loss: 0.115738 \n",
      " Validation: accuracy: 0.976562 loss: 0.264746\n",
      " cross_entropy: 0.045263, clust_cross_entropy: 0.0434192, affinity: 0.000413181, balance: 0.0430641, coact: 0.00629833, frob: 0.000321493\n",
      "step 41700/50000 \n",
      " Train: accuracy: 1, loss: 0.121818 \n",
      " Validation: accuracy: 0.976562 loss: 0.431383\n",
      " cross_entropy: 0.0500558, clust_cross_entropy: 0.0685595, affinity: 7.11832e-05, balance: 0.118272, coact: 0.0069554, frob: 0.000319284\n",
      "step 41800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.199083 \n",
      " Validation: accuracy: 0.992188 loss: 0.176483\n",
      " cross_entropy: 0.032906, clust_cross_entropy: 0.0543253, affinity: 0.000133348, balance: 0.0412834, coact: 0.0093854, frob: 0.000310081\n",
      "step 41900/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.213048 \n",
      " Validation: accuracy: 0.976562 loss: 0.415144\n",
      " cross_entropy: 0.0397995, clust_cross_entropy: 0.014946, affinity: 0.000695965, balance: 0.12198, coact: 0, frob: 0.00031499\n",
      "step 42000/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.22645 \n",
      " Validation: accuracy: 0.984375 loss: 0.335782\n",
      " cross_entropy: 0.0353781, clust_cross_entropy: 0.0338328, affinity: 0.000512174, balance: 0.0959989, coact: 0.00958184, frob: 0.000335724\n",
      "step 42100/50000 \n",
      " Train: accuracy: 1, loss: 0.0964151 \n",
      " Validation: accuracy: 0.992188 loss: 0.216969\n",
      " cross_entropy: 0.00917388, clust_cross_entropy: 0.106653, affinity: 0.000107112, balance: 0.0518125, coact: 0.011198, frob: 0.000333646\n",
      "step 42200/50000 \n",
      " Train: accuracy: 1, loss: 0.213277 \n",
      " Validation: accuracy: 1 loss: 0.126311\n",
      " cross_entropy: 0.0403938, clust_cross_entropy: 0.117484, affinity: 0.000430587, balance: 0.0813135, coact: 0.00284135, frob: 0.000333258\n",
      "step 42300/50000 \n",
      " Train: accuracy: 1, loss: 0.196251 \n",
      " Validation: accuracy: 0.976562 loss: 0.350967\n",
      " cross_entropy: 0.040344, clust_cross_entropy: 0.0609994, affinity: 0.00047998, balance: 0.0499364, coact: 0.015881, frob: 0.000334713\n",
      "step 42400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.126559 \n",
      " Validation: accuracy: 0.992188 loss: 0.168802\n",
      " cross_entropy: 0.0156117, clust_cross_entropy: 0.0301447, affinity: 0.000639265, balance: 0.0414617, coact: 0.00378141, frob: 0.000325895\n",
      "step 42500/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.34988 \n",
      " Validation: accuracy: 0.992188 loss: 0.203098\n",
      " cross_entropy: 0.0539453, clust_cross_entropy: 0.107987, affinity: 0.000560247, balance: 0.096594, coact: 0.010733, frob: 0.000309115\n",
      "step 42600/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.220791 \n",
      " Validation: accuracy: 0.976562 loss: 0.244868\n",
      " cross_entropy: 0.0172678, clust_cross_entropy: 0.0565183, affinity: 0.000674654, balance: 0.0764393, coact: 0.00276055, frob: 0.000324291\n",
      "step 42700/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.303627 \n",
      " Validation: accuracy: 1 loss: 0.16477\n",
      " cross_entropy: 0.0766436, clust_cross_entropy: 0.0887563, affinity: 4.48567e-05, balance: 0.143462, coact: 0.00676512, frob: 0.000327047\n",
      "step 42800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.208638 \n",
      " Validation: accuracy: 0.992188 loss: 0.24771\n",
      " cross_entropy: 0.0252823, clust_cross_entropy: 0.0327631, affinity: 0.00056753, balance: 0.0710284, coact: 0.00761355, frob: 0.000322425\n",
      "step 42900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.212191 \n",
      " Validation: accuracy: 1 loss: 0.0791391\n",
      " cross_entropy: 0.0277176, clust_cross_entropy: 0.0852864, affinity: 0.000415993, balance: 0.0693691, coact: 9.66366e-05, frob: 0.000329592\n",
      "step 43000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.213344 \n",
      " Validation: accuracy: 0.984375 loss: 0.14879\n",
      " cross_entropy: 0.0365104, clust_cross_entropy: 0.102144, affinity: 7.95525e-05, balance: 0.0593851, coact: 0.0113466, frob: 0.000332258\n",
      "step 43100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.235497 \n",
      " Validation: accuracy: 1 loss: 0.163251\n",
      " cross_entropy: 0.0236431, clust_cross_entropy: 0.0653598, affinity: 0.00142987, balance: 0.0841224, coact: 0.00582341, frob: 0.000317328\n",
      "step 43200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.133055 \n",
      " Validation: accuracy: 1 loss: 0.16913\n",
      " cross_entropy: 0.0228133, clust_cross_entropy: 0.0368106, affinity: 0.000545218, balance: 0.0707133, coact: 0.0114184, frob: 0.000334093\n",
      "step 43300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.183063 \n",
      " Validation: accuracy: 0.96875 loss: 0.243567\n",
      " cross_entropy: 0.0499836, clust_cross_entropy: 0.116963, affinity: 0.000993514, balance: 0.0585377, coact: 0.0039141, frob: 0.000327233\n",
      "step 43400/50000 \n",
      " Train: accuracy: 1, loss: 0.218136 \n",
      " Validation: accuracy: 0.992188 loss: 0.215091\n",
      " cross_entropy: 0.0425281, clust_cross_entropy: 0.0405903, affinity: 0.00197719, balance: 0.162079, coact: 0.00253436, frob: 0.000319329\n",
      "step 43500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.310291 \n",
      " Validation: accuracy: 0.992188 loss: 0.244496\n",
      " cross_entropy: 0.0706092, clust_cross_entropy: 0.0846822, affinity: 4.55143e-05, balance: 0.140368, coact: 0.0101651, frob: 0.000322066\n",
      "step 43600/50000 \n",
      " Train: accuracy: 1, loss: 0.118827 \n",
      " Validation: accuracy: 0.976562 loss: 0.374513\n",
      " cross_entropy: 0.0254811, clust_cross_entropy: 0.0522057, affinity: 0.000227122, balance: 0.0513585, coact: 0.00940953, frob: 0.000323077\n",
      "step 43700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.153322 \n",
      " Validation: accuracy: 0.984375 loss: 0.208937\n",
      " cross_entropy: 0.0238541, clust_cross_entropy: 0.0536435, affinity: 9.68663e-05, balance: 0.0734702, coact: 0.00676497, frob: 0.000326883\n",
      "step 43800/50000 \n",
      " Train: accuracy: 1, loss: 0.142333 \n",
      " Validation: accuracy: 0.984375 loss: 0.280193\n",
      " cross_entropy: 0.026001, clust_cross_entropy: 0.0397247, affinity: 0.00047721, balance: 0.0686401, coact: 0.0031035, frob: 0.000329736\n",
      "step 43900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.302916 \n",
      " Validation: accuracy: 0.984375 loss: 0.189677\n",
      " cross_entropy: 0.113188, clust_cross_entropy: 0.071019, affinity: 0.00012003, balance: 0.0659674, coact: 0.00689659, frob: 0.000319301\n",
      "step 44000/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.17223 \n",
      " Validation: accuracy: 0.992188 loss: 0.150373\n",
      " cross_entropy: 0.0618908, clust_cross_entropy: 0.0824297, affinity: 0.00141694, balance: 0.0527679, coact: 0.00934325, frob: 0.000334206\n",
      "step 44100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.168641 \n",
      " Validation: accuracy: 0.992188 loss: 0.199029\n",
      " cross_entropy: 0.0301501, clust_cross_entropy: 0.0645541, affinity: 0.000203831, balance: 0.052947, coact: 0.00144864, frob: 0.000340153\n",
      "step 44200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.374722 \n",
      " Validation: accuracy: 0.992188 loss: 0.286862\n",
      " cross_entropy: 0.0327371, clust_cross_entropy: 0.0322403, affinity: 0.000291178, balance: 0.172325, coact: 0.00579897, frob: 0.000328042\n",
      "step 44300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.251046 \n",
      " Validation: accuracy: 0.992188 loss: 0.144663\n",
      " cross_entropy: 0.0183317, clust_cross_entropy: 0.0890367, affinity: 0.00080336, balance: 0.0935145, coact: 0.0151974, frob: 0.000327718\n",
      "step 44400/50000 \n",
      " Train: accuracy: 1, loss: 0.10443 \n",
      " Validation: accuracy: 1 loss: 0.220658\n",
      " cross_entropy: 0.0320014, clust_cross_entropy: 0.00528628, affinity: 0.000414488, balance: 0.0600913, coact: 0.0159876, frob: 0.000328345\n",
      "step 44500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.248039 \n",
      " Validation: accuracy: 0.992188 loss: 0.158039\n",
      " cross_entropy: 0.0297606, clust_cross_entropy: 0.21109, affinity: 0.000174349, balance: 0.108143, coact: 0.00785545, frob: 0.000319116\n",
      "step 44600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.129151 \n",
      " Validation: accuracy: 0.984375 loss: 0.259742\n",
      " cross_entropy: 0.0326962, clust_cross_entropy: 0.0646882, affinity: 0.00092666, balance: 0.0239781, coact: 0.00484112, frob: 0.000308005\n",
      "step 44700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.283117 \n",
      " Validation: accuracy: 0.992188 loss: 0.215667\n",
      " cross_entropy: 0.13041, clust_cross_entropy: 0.0752452, affinity: 0.000247326, balance: 0.118123, coact: 0.00577181, frob: 0.000332734\n",
      "step 44800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.194507 \n",
      " Validation: accuracy: 0.984375 loss: 0.208743\n",
      " cross_entropy: 0.0294401, clust_cross_entropy: 0.0258212, affinity: 0.000916673, balance: 0.0422722, coact: 0.000752618, frob: 0.000321603\n",
      "step 44900/50000 \n",
      " Train: accuracy: 1, loss: 0.116666 \n",
      " Validation: accuracy: 0.984375 loss: 0.25184\n",
      " cross_entropy: 0.0166834, clust_cross_entropy: 0.0404271, affinity: 0.000447279, balance: 0.0632552, coact: 0, frob: 0.000335116\n",
      "step 45000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.256759 \n",
      " Validation: accuracy: 0.984375 loss: 0.216346\n",
      " cross_entropy: 0.0303657, clust_cross_entropy: 0.135173, affinity: 0.00016112, balance: 0.0983878, coact: 0.00117996, frob: 0.000330606\n",
      "step 45100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.250552 \n",
      " Validation: accuracy: 0.992188 loss: 0.173351\n",
      " cross_entropy: 0.0599526, clust_cross_entropy: 0.0248314, affinity: 0.000128983, balance: 0.11615, coact: 0.021505, frob: 0.000324475\n",
      "step 45200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.245705 \n",
      " Validation: accuracy: 0.992188 loss: 0.207489\n",
      " cross_entropy: 0.0589824, clust_cross_entropy: 0.126616, affinity: 0.000286963, balance: 0.0579246, coact: 0.00405476, frob: 0.000329464\n",
      "step 45300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.238275 \n",
      " Validation: accuracy: 1 loss: 0.23827\n",
      " cross_entropy: 0.0430085, clust_cross_entropy: 0.0968849, affinity: 0.00135509, balance: 0.0587069, coact: 0.00442081, frob: 0.00032021\n",
      "step 45400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.186614 \n",
      " Validation: accuracy: 0.992188 loss: 0.172494\n",
      " cross_entropy: 0.0250321, clust_cross_entropy: 0.0340371, affinity: 0.000248201, balance: 0.137651, coact: 0.00718484, frob: 0.000327436\n",
      "step 45500/50000 \n",
      " Train: accuracy: 1, loss: 0.137972 \n",
      " Validation: accuracy: 1 loss: 0.0894412\n",
      " cross_entropy: 0.0224674, clust_cross_entropy: 0.0200287, affinity: 0.000433429, balance: 0.111723, coact: 0.0241307, frob: 0.000334733\n",
      "step 45600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.148695 \n",
      " Validation: accuracy: 0.976562 loss: 0.21931\n",
      " cross_entropy: 0.0541374, clust_cross_entropy: 0.0466936, affinity: 0.000578771, balance: 0.0442176, coact: 0.0136474, frob: 0.00032231\n",
      "step 45700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.252743 \n",
      " Validation: accuracy: 0.984375 loss: 0.216465\n",
      " cross_entropy: 0.0961973, clust_cross_entropy: 0.121613, affinity: 0.00015416, balance: 0.0734953, coact: 0.00433864, frob: 0.000319179\n",
      "step 45800/50000 \n",
      " Train: accuracy: 1, loss: 0.171103 \n",
      " Validation: accuracy: 0.984375 loss: 0.290696\n",
      " cross_entropy: 0.0534051, clust_cross_entropy: 0.0763061, affinity: 0.000686753, balance: 0.0728452, coact: 0.0158574, frob: 0.000324792\n",
      "step 45900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.117665 \n",
      " Validation: accuracy: 0.984375 loss: 0.146083\n",
      " cross_entropy: 0.0196436, clust_cross_entropy: 0.0134977, affinity: 0.000435942, balance: 0.066445, coact: 0.0183352, frob: 0.000337259\n",
      "step 46000/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.131828 \n",
      " Validation: accuracy: 0.992188 loss: 0.225314\n",
      " cross_entropy: 0.029164, clust_cross_entropy: 0.0497978, affinity: 0.000594461, balance: 0.0377517, coact: 0.00555837, frob: 0.000309827\n",
      "step 46100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.171865 \n",
      " Validation: accuracy: 1 loss: 0.10516\n",
      " cross_entropy: 0.0639168, clust_cross_entropy: 0.0633026, affinity: 0.000579364, balance: 0.0446538, coact: 0.0146751, frob: 0.000321075\n",
      "step 46200/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.161845 \n",
      " Validation: accuracy: 0.960938 loss: 0.340806\n",
      " cross_entropy: 0.0151758, clust_cross_entropy: 0.00674116, affinity: 0.000235143, balance: 0.127238, coact: 0, frob: 0.000315871\n",
      "step 46300/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.242675 \n",
      " Validation: accuracy: 0.992188 loss: 0.124025\n",
      " cross_entropy: 0.00764419, clust_cross_entropy: 0.115589, affinity: 0.0006489, balance: 0.0587286, coact: 0.0064443, frob: 0.000329284\n",
      "step 46400/50000 \n",
      " Train: accuracy: 1, loss: 0.118575 \n",
      " Validation: accuracy: 0.992188 loss: 0.106542\n",
      " cross_entropy: 0.0104084, clust_cross_entropy: 0.0209493, affinity: 0.000571862, balance: 0.0796906, coact: 0.00145404, frob: 0.000328326\n",
      "step 46500/50000 \n",
      " Train: accuracy: 1, loss: 0.117659 \n",
      " Validation: accuracy: 1 loss: 0.143153\n",
      " cross_entropy: 0.0145766, clust_cross_entropy: 0.0339638, affinity: 5.57157e-05, balance: 0.0494466, coact: 0.01095, frob: 0.000328345\n",
      "step 46600/50000 \n",
      " Train: accuracy: 1, loss: 0.108174 \n",
      " Validation: accuracy: 1 loss: 0.131309\n",
      " cross_entropy: 0.0312265, clust_cross_entropy: 0.0230073, affinity: 0.000740575, balance: 0.0484085, coact: 0.00864113, frob: 0.000332521\n",
      "step 46700/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.211264 \n",
      " Validation: accuracy: 1 loss: 0.115012\n",
      " cross_entropy: 0.0565798, clust_cross_entropy: 0.0294598, affinity: 0.000983905, balance: 0.0412694, coact: 0.00728821, frob: 0.000328419\n",
      "step 46800/50000 \n",
      " Train: accuracy: 1, loss: 0.217049 \n",
      " Validation: accuracy: 1 loss: 0.157594\n",
      " cross_entropy: 0.0226703, clust_cross_entropy: 0.0335089, affinity: 0.000295494, balance: 0.14947, coact: 0.00654082, frob: 0.000315479\n",
      "step 46900/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.221645 \n",
      " Validation: accuracy: 0.992188 loss: 0.145245\n",
      " cross_entropy: 0.0446021, clust_cross_entropy: 0.0647667, affinity: 0.000757399, balance: 0.0677042, coact: 0.00784675, frob: 0.000328852\n",
      "step 47000/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.268829 \n",
      " Validation: accuracy: 1 loss: 0.201358\n",
      " cross_entropy: 0.0317267, clust_cross_entropy: 0.0533148, affinity: 0.000564853, balance: 0.114184, coact: 4.06888e-05, frob: 0.000342094\n",
      "step 47100/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.153714 \n",
      " Validation: accuracy: 0.976562 loss: 0.240014\n",
      " cross_entropy: 0.0197125, clust_cross_entropy: 0.0286213, affinity: 0.000211039, balance: 0.0881565, coact: 0.00814191, frob: 0.000338604\n",
      "step 47200/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.203346 \n",
      " Validation: accuracy: 0.984375 loss: 0.237474\n",
      " cross_entropy: 0.0168762, clust_cross_entropy: 0.0506293, affinity: 0.000227643, balance: 0.0815161, coact: 0.0293657, frob: 0.00032355\n",
      "step 47300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.160261 \n",
      " Validation: accuracy: 0.992188 loss: 0.356007\n",
      " cross_entropy: 0.0274966, clust_cross_entropy: 0.105522, affinity: 0.000684336, balance: 0.0806849, coact: 0.0170901, frob: 0.000336416\n",
      "step 47400/50000 \n",
      " Train: accuracy: 1, loss: 0.175119 \n",
      " Validation: accuracy: 0.992188 loss: 0.0833788\n",
      " cross_entropy: 0.0341401, clust_cross_entropy: 0.0596919, affinity: 0.000503264, balance: 0.0576796, coact: 0.00853178, frob: 0.000334835\n",
      "step 47500/50000 \n",
      " Train: accuracy: 0.96875, loss: 0.225993 \n",
      " Validation: accuracy: 1 loss: 0.0696862\n",
      " cross_entropy: 0.0601134, clust_cross_entropy: 0.129645, affinity: 0.000165928, balance: 0.0762324, coact: 9.50669e-05, frob: 0.000329672\n",
      "step 47600/50000 \n",
      " Train: accuracy: 1, loss: 0.159597 \n",
      " Validation: accuracy: 0.992188 loss: 0.162125\n",
      " cross_entropy: 0.0428631, clust_cross_entropy: 0.0840829, affinity: 0.000745358, balance: 0.125642, coact: 0.00483342, frob: 0.000328083\n",
      "step 47700/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.175064 \n",
      " Validation: accuracy: 0.984375 loss: 0.220234\n",
      " cross_entropy: 0.0834258, clust_cross_entropy: 0.140464, affinity: 2.04393e-05, balance: 0.104159, coact: 7.37216e-05, frob: 0.000338203\n",
      "step 47800/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.247953 \n",
      " Validation: accuracy: 0.96875 loss: 0.262132\n",
      " cross_entropy: 0.0326837, clust_cross_entropy: 0.0663321, affinity: 0.000192559, balance: 0.11064, coact: 0.000294814, frob: 0.000346061\n",
      "step 47900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.156852 \n",
      " Validation: accuracy: 1 loss: 0.149981\n",
      " cross_entropy: 0.0155026, clust_cross_entropy: 0.0251223, affinity: 0.000291701, balance: 0.0679514, coact: 0.00888539, frob: 0.000324469\n",
      "step 48000/50000 \n",
      " Train: accuracy: 1, loss: 0.0857345 \n",
      " Validation: accuracy: 0.992188 loss: 0.169931\n",
      " cross_entropy: 0.0257976, clust_cross_entropy: 0.0270489, affinity: 2.40947e-05, balance: 0.0224644, coact: 0, frob: 0.000336249\n",
      "step 48100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.383192 \n",
      " Validation: accuracy: 0.992188 loss: 0.172062\n",
      " cross_entropy: 0.118061, clust_cross_entropy: 0.103399, affinity: 0.000830983, balance: 0.139543, coact: 0.00233152, frob: 0.000332803\n",
      "step 48200/50000 \n",
      " Train: accuracy: 1, loss: 0.209176 \n",
      " Validation: accuracy: 0.992188 loss: 0.116581\n",
      " cross_entropy: 0.0154328, clust_cross_entropy: 0.0247557, affinity: 0.000469941, balance: 0.168204, coact: 0.00576309, frob: 0.000337364\n",
      "step 48300/50000 \n",
      " Train: accuracy: 1, loss: 0.113657 \n",
      " Validation: accuracy: 0.96875 loss: 0.376951\n",
      " cross_entropy: 0.0680519, clust_cross_entropy: 0.0779881, affinity: 0.000269396, balance: 0.046093, coact: 0.00391652, frob: 0.000331694\n",
      "step 48400/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.179702 \n",
      " Validation: accuracy: 0.984375 loss: 0.189632\n",
      " cross_entropy: 0.0235035, clust_cross_entropy: 0.0379509, affinity: 0.000194991, balance: 0.144199, coact: 0.0242845, frob: 0.000335504\n",
      "step 48500/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.228779 \n",
      " Validation: accuracy: 1 loss: 0.157446\n",
      " cross_entropy: 0.0423, clust_cross_entropy: 0.0423541, affinity: 0.000388315, balance: 0.085283, coact: 0.00740756, frob: 0.000336939\n",
      "step 48600/50000 \n",
      " Train: accuracy: 1, loss: 0.131902 \n",
      " Validation: accuracy: 0.976562 loss: 0.350735\n",
      " cross_entropy: 0.0145273, clust_cross_entropy: 0.0152877, affinity: 0.000370812, balance: 0.0859581, coact: 0.000307565, frob: 0.000339422\n",
      "step 48700/50000 \n",
      " Train: accuracy: 1, loss: 0.12752 \n",
      " Validation: accuracy: 0.984375 loss: 0.243456\n",
      " cross_entropy: 0.0114135, clust_cross_entropy: 0.0478421, affinity: 0.000324397, balance: 0.039065, coact: 0.00461919, frob: 0.000345341\n",
      "step 48800/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.20085 \n",
      " Validation: accuracy: 0.992188 loss: 0.142919\n",
      " cross_entropy: 0.0614137, clust_cross_entropy: 0.0377125, affinity: 7.7006e-05, balance: 0.0947434, coact: 0.00388297, frob: 0.000328911\n",
      "step 48900/50000 \n",
      " Train: accuracy: 1, loss: 0.114016 \n",
      " Validation: accuracy: 0.992188 loss: 0.24868\n",
      " cross_entropy: 0.0113661, clust_cross_entropy: 0.0148885, affinity: 0.000850593, balance: 0.130283, coact: 0.0011491, frob: 0.000335092\n",
      "step 49000/50000 \n",
      " Train: accuracy: 1, loss: 0.156984 \n",
      " Validation: accuracy: 0.984375 loss: 0.156997\n",
      " cross_entropy: 0.0567526, clust_cross_entropy: 0.0369402, affinity: 0.000227858, balance: 0.117685, coact: 0.00753712, frob: 0.000337908\n",
      "step 49100/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.255938 \n",
      " Validation: accuracy: 0.984375 loss: 0.153444\n",
      " cross_entropy: 0.0278449, clust_cross_entropy: 0.0857924, affinity: 0.000245916, balance: 0.0568605, coact: 0.0072417, frob: 0.000327768\n",
      "step 49200/50000 \n",
      " Train: accuracy: 0.976562, loss: 0.261851 \n",
      " Validation: accuracy: 1 loss: 0.0948448\n",
      " cross_entropy: 0.0306606, clust_cross_entropy: 0.0518377, affinity: 7.39467e-07, balance: 0.128938, coact: 0.000279006, frob: 0.0003292\n",
      "step 49300/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.159477 \n",
      " Validation: accuracy: 1 loss: 0.119204\n",
      " cross_entropy: 0.0370985, clust_cross_entropy: 0.0839016, affinity: 0.000742028, balance: 0.100444, coact: 0.0197409, frob: 0.000337917\n",
      "step 49400/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.3805 \n",
      " Validation: accuracy: 1 loss: 0.0976387\n",
      " cross_entropy: 0.0324684, clust_cross_entropy: 0.0812907, affinity: 0.000483361, balance: 0.0786247, coact: 0.00611262, frob: 0.000340417\n",
      "step 49500/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.168278 \n",
      " Validation: accuracy: 0.992188 loss: 0.120709\n",
      " cross_entropy: 0.0213163, clust_cross_entropy: 0.0170702, affinity: 0.000196888, balance: 0.0791051, coact: 0.00310403, frob: 0.000340767\n",
      "step 49600/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.233066 \n",
      " Validation: accuracy: 0.976562 loss: 0.224224\n",
      " cross_entropy: 0.0515798, clust_cross_entropy: 0.0319435, affinity: 1.13198e-05, balance: 0.123164, coact: 0.0013453, frob: 0.00032879\n",
      "step 49700/50000 \n",
      " Train: accuracy: 0.984375, loss: 0.138162 \n",
      " Validation: accuracy: 0.992188 loss: 0.184189\n",
      " cross_entropy: 0.0250499, clust_cross_entropy: 0.044714, affinity: 0.000254183, balance: 0.0494024, coact: 0.00649641, frob: 0.000347902\n",
      "step 49800/50000 \n",
      " Train: accuracy: 1, loss: 0.0799198 \n",
      " Validation: accuracy: 0.992188 loss: 0.193605\n",
      " cross_entropy: 0.0368293, clust_cross_entropy: 0.0493739, affinity: 0.00139466, balance: 0.06905, coact: 0.00422036, frob: 0.000342142\n",
      "step 49900/50000 \n",
      " Train: accuracy: 0.992188, loss: 0.151433 \n",
      " Validation: accuracy: 0.992188 loss: 0.243296\n",
      " cross_entropy: 0.0558645, clust_cross_entropy: 0.0505295, affinity: 0.000115253, balance: 0.0826712, coact: 0.00957141, frob: 0.000323759\n"
     ]
    }
   ],
   "source": [
    "convy2 = y2\n",
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = mnist.train.next_batch(batchSize)\n",
    "    trainbatch = (trainbatch[0],np.array([y[np.argmax(trainbatch[1][j])] for j in range(len(trainbatch[1]))]),np.array([convy2[np.argmax(trainbatch[1][j])] for j in range(len(trainbatch[1]))]))\n",
    "    valbatch = mnist.validation.next_batch(batchSize)\n",
    "    valbatch = (valbatch[0],np.array([y[np.argmax(valbatch[1][j])] for j in range(len(valbatch[1]))]),np.array([convy2[np.argmax(valbatch[1][j])] for j in range(len(valbatch[1]))]))\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2]})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, affinity: %g, balance: %g, coact: %g, frob: %g\"%(cc0*entr, cc5*entr2 ,cc1*hist['affinity'][-1],cc2*(1-hist['balance'][-1]),cc3*hist['coactivity'][-1],cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2]}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: accuracy: 0.985, loss: 0.165459\n",
      "Test: accuracy: 0.985, loss: 0.240667\n",
      "Test: accuracy: 0.985, loss: 0.274094\n",
      "Test: accuracy: 0.985, loss: 0.194888\n",
      "Test: accuracy: 0.984, loss: 0.24409\n",
      "Test: accuracy: 0.993, loss: 0.0973943\n",
      "Test: accuracy: 0.985, loss: 0.148302\n",
      "Test: accuracy: 0.997, loss: 0.0515329\n",
      "Test: accuracy: 0.993, loss: 0.129807\n",
      "Test: accuracy: 0.99, loss: 0.149065\n",
      "Test: accuracy: 0.988, loss: 0.189946\n",
      "Test: accuracy: 0.986, loss: 0.162299\n",
      "Test: accuracy: 0.992, loss: 0.103851\n",
      "Test: accuracy: 0.987, loss: 0.178417\n",
      "Test: accuracy: 0.986, loss: 0.174916\n",
      "Test: accuracy: 0.989, loss: 0.149379\n",
      "Test: accuracy: 0.991, loss: 0.143906\n",
      "Test: accuracy: 0.992, loss: 0.147791\n",
      "Test: accuracy: 0.992, loss: 0.108638\n",
      "Test: accuracy: 0.985, loss: 0.161639\n",
      "Test: accuracy: 0.991, loss: 0.171466\n",
      "Test: accuracy: 0.989, loss: 0.175986\n",
      "Test: accuracy: 0.987, loss: 0.196283\n",
      "Test: accuracy: 0.99, loss: 0.171202\n",
      "Test: accuracy: 0.988, loss: 0.149969\n",
      "Test: accuracy: 0.994, loss: 0.169967\n",
      "Test: accuracy: 0.991, loss: 0.149239\n",
      "Test: accuracy: 0.989, loss: 0.151042\n",
      "Test: accuracy: 0.987, loss: 0.184856\n",
      "Test: accuracy: 0.988, loss: 0.159546\n",
      "Test: accuracy: 0.988, loss: 0.156018\n",
      "Test: accuracy: 0.988, loss: 0.176355\n",
      "Test: accuracy: 0.99, loss: 0.140942\n",
      "Test: accuracy: 0.99, loss: 0.132294\n",
      "Test: accuracy: 0.984, loss: 0.20194\n",
      "Test: accuracy: 0.988, loss: 0.14805\n",
      "Test: accuracy: 0.986, loss: 0.170297\n",
      "Test: accuracy: 0.989, loss: 0.140144\n",
      "Test: accuracy: 0.988, loss: 0.170312\n",
      "Test: accuracy: 0.987, loss: 0.1796\n",
      "Test: accuracy: 0.994, loss: 0.166007\n",
      "Test: accuracy: 0.988, loss: 0.18135\n",
      "Test: accuracy: 0.992, loss: 0.173319\n",
      "Test: accuracy: 0.989, loss: 0.209679\n",
      "Test: accuracy: 0.984, loss: 0.182544\n",
      "Test: accuracy: 0.984, loss: 0.220155\n",
      "Test: accuracy: 0.994, loss: 0.115706\n",
      "Test: accuracy: 0.989, loss: 0.154743\n",
      "Test: accuracy: 0.987, loss: 0.122361\n",
      "Test: accuracy: 0.987, loss: 0.173918\n",
      "Test: accuracy: 0.99, loss: 0.180047\n",
      "Test: accuracy: 0.989, loss: 0.177683\n",
      "Test: accuracy: 0.992, loss: 0.133409\n",
      "Test: accuracy: 0.989, loss: 0.121027\n",
      "Test: accuracy: 0.986, loss: 0.178381\n",
      "Test: accuracy: 0.988, loss: 0.142238\n",
      "Test: accuracy: 0.989, loss: 0.168344\n",
      "Test: accuracy: 0.987, loss: 0.153459\n",
      "Test: accuracy: 0.986, loss: 0.150825\n",
      "Test: accuracy: 0.986, loss: 0.177622\n",
      "Test: accuracy: 0.993, loss: 0.131669\n",
      "Test: accuracy: 0.989, loss: 0.148335\n",
      "Test: accuracy: 0.989, loss: 0.163348\n",
      "Test: accuracy: 0.986, loss: 0.174572\n",
      "Test: accuracy: 0.991, loss: 0.14481\n",
      "Test: accuracy: 0.992, loss: 0.134114\n",
      "Test: accuracy: 0.987, loss: 0.153521\n",
      "Test: accuracy: 0.989, loss: 0.179767\n",
      "Test: accuracy: 0.987, loss: 0.186409\n",
      "Test: accuracy: 0.982, loss: 0.199187\n",
      "Test: accuracy: 0.984, loss: 0.162904\n",
      "Test: accuracy: 0.99, loss: 0.121684\n",
      "Test: accuracy: 0.986, loss: 0.158564\n",
      "Test: accuracy: 0.992, loss: 0.146263\n",
      "Test: accuracy: 0.985, loss: 0.194521\n",
      "Test: accuracy: 0.991, loss: 0.1541\n",
      "Test: accuracy: 0.988, loss: 0.174395\n",
      "Test: accuracy: 0.98, loss: 0.180106\n",
      "Test: accuracy: 0.987, loss: 0.189184\n",
      "Test: accuracy: 0.991, loss: 0.12719\n",
      "Test: accuracy: 0.988, loss: 0.179517\n",
      "Test: accuracy: 0.992, loss: 0.129109\n",
      "Test: accuracy: 0.988, loss: 0.157367\n",
      "Test: accuracy: 0.984, loss: 0.20583\n",
      "Test: accuracy: 0.99, loss: 0.158847\n",
      "Test: accuracy: 0.988, loss: 0.19968\n",
      "Test: accuracy: 0.986, loss: 0.167343\n",
      "Test: accuracy: 0.992, loss: 0.144289\n",
      "Test: accuracy: 0.981, loss: 0.18265\n",
      "Test: accuracy: 0.991, loss: 0.183534\n",
      "Test: accuracy: 0.982, loss: 0.179492\n",
      "Test: accuracy: 0.986, loss: 0.12261\n",
      "Test: accuracy: 0.986, loss: 0.194704\n",
      "Test: accuracy: 0.991, loss: 0.169301\n",
      "Test: accuracy: 0.985, loss: 0.189036\n",
      "Test: accuracy: 0.988, loss: 0.184311\n",
      "Test: accuracy: 0.987, loss: 0.167689\n",
      "Test: accuracy: 0.984, loss: 0.179847\n",
      "Test: accuracy: 0.986, loss: 0.164772\n",
      "Test: accuracy: 0.992, loss: 0.117758\n",
      "0.98818\n"
     ]
    }
   ],
   "source": [
    "tAcc = []\n",
    "testSize = 1000\n",
    "for i in range(100):\n",
    "    testSize = 1000\n",
    "    testbatch = mnist.test.next_batch(testSize)\n",
    "    testbatch = (testbatch[0],np.array([y[np.argmax(testbatch[1][j])] for j in range(len(testbatch[1]))]),np.array([y2[np.argmax(testbatch[1][j])] for j in range(len(testbatch[1]))]))\n",
    "\n",
    "    test_loss,test_acc = sess.run([loss,accuracy],{x: testbatch[0], y_: testbatch[1], y2_: testbatch[2]})\n",
    "    tAcc.append(test_acc)\n",
    "    print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))\n",
    "print np.average(tAcc)\n",
    "testAcc = np.average(tAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8486330810>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAANSCAYAAAAtZYyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkqae+AXeqag0wVkmLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f845b75f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy and loss\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(211)\n",
    "plt.plot(hist['train_acc'],'-b',label='train_acc')\n",
    "plt.plot(hist['val_acc'],'-r',label='val_acc')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['val_loss'],'-r',label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f848619af10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAGfCAYAAAAHwBxKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgE6KQAgAAAAAndT/B5LJbfkk7FZXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f848625a2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "#plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['affinity'],'-r',label='affinity')\n",
    "plt.plot(np.subtract(1,hist['balance']),'-y',label='balance')\n",
    "plt.plot(hist['coactivity'],'-g',label='coactivity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digitTrace = np.zeros((classCount*clustCount,784))\n",
    "digitTraceCount = np.zeros((classCount*clustCount))\n",
    "digitCount = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    tb = mnist.test.next_batch(1)\n",
    "    digitCount[np.argmax(tb[1])]+=1\n",
    "    testbatch = (tb[0],np.array([y[np.argmax(tb[1][j])] for j in range(len(tb[1]))]))\n",
    "    smMat, acc = sess.run([softmaxMat,accuracy],feed_dict={x: testbatch[0], y_: testbatch[1]})\n",
    "    ypred = softmaxMat.eval({x: testbatch[0], y_: testbatch[1]})\n",
    "    digitTrace[np.argmax(ypred),:] += tb[0].ravel()\n",
    "    digitTraceCount[np.argmax(ypred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 104.  108.   99.  105.  101.   81.  103.   93.  105.  101.]\n",
      "[ 105.  107.   98.  103.  101.   82.  100.   93.  109.  102.]\n"
     ]
    }
   ],
   "source": [
    "print(digitCount)\n",
    "print(digitTraceCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAC4CAYAAACPdMm0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f848b76ca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stepCount = len(hist['train_acc'])*100\n",
    "with open('./trainlog.txt','ab') as f:\n",
    "    f.write('lr: %g, batchsize: %i, steps: %i, thresh: %g, c1: %g, c2: %g, c3: %g, c4: %g, test_acc: %g, test_loss: %g\\n'%\n",
    "            (lr,batchSize,stepCount,tresh.eval(), cc1, cc2, cc3, cc4, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy: 0.9807\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "tb = mnist.test.next_batch(10000)\n",
    "#tb[0][:,:] = threshold(tb[0][:,:],threshmin=0.5,newval=0)\n",
    "#tb[0][:,:] = threshold(tb[0][:,:],threshmax=0.49,newval=1)\n",
    "testbatch = (tb[0],np.array([y[np.argmax(tb[1][j])>4] for j in range(len(tb[1]))]))\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1]}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((tb[0].shape[0],clustCount*classCount))\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(tb[1][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(tb[1],1).astype('int32'))\n",
    "clustAcc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(clustAcc))\n",
    "print(ylookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notify(\"Superclass: %g \\nSubclass: %g\"%(testAcc,clustAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it to k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float argument required, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7d9304e2606c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mkm_correct_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm_yconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mkm1_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm_correct_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ACOL Accuracy: %g'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KMeans Accuracy: %g'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm0_accuracy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkm1_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float argument required, not Tensor"
     ]
    }
   ],
   "source": [
    "tb0 = [tb[0][np.argmax(tb[1],1)<5],tb[1][np.argmax(tb[1],1)<5]]\n",
    "tb1 = [tb[0][np.argmax(tb[1],1)>4],tb[1][np.argmax(tb[1],1)>4]]\n",
    "#<5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km0_ypred = kmeans.fit_transform(tb0[0])\n",
    "km0_ypred = np.argmax(km0_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb0[1][km0_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km0_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb0[1],1).astype('int32'))\n",
    "km0_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "#>4\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km1_ypred = kmeans.fit_transform(tb1[0])\n",
    "km1_ypred = np.argmax(km1_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb1[1][km1_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km1_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb1[1],1).astype('int32'))\n",
    "km1_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "print('ACOL Accuracy: %g'%(accuracy))\n",
    "print('KMeans Accuracy: %g'%((km0_accuracy+km1_accuracy)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualise kmeans\n",
    "digitTrace = np.concatenate([[np.sum(tb0[0][km0_ypred==i,:],axis=0) for i in range(clustCount)],\n",
    "                       [np.sum(tb1[0][km1_ypred==i,:],axis=0) for i in range(clustCount)]])\n",
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
