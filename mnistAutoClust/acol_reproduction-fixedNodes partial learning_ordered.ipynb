{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACOL replication tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#imports and settings:\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from jupyterthemes import jtplot\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import threshold\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "#jtplot.style()\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "\n",
    "nbName = \"acol_reproduction-fixedNodes partial learning\"\n",
    "\n",
    "local_file = base.maybe_download(TRAIN_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_images = mnist.extract_images(f)\n",
    "    \n",
    "local_file = base.maybe_download(TRAIN_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_labels = mnist.extract_labels(f, one_hot=True)\n",
    "\n",
    "local_file = base.maybe_download(TEST_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_images = mnist.extract_images(f)\n",
    "\n",
    "local_file = base.maybe_download(TEST_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_labels = mnist.extract_labels(f, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustCount = 5\n",
    "classCount = 2\n",
    "net = 0\n",
    "#trainsteps = 50000\n",
    "trainsteps = 30000\n",
    "perc = 0.01\n",
    "validation_size=5000\n",
    "_epochs_completed_train = 0\n",
    "_index_in_epoch_train = 0\n",
    "_epochs_completed_val = 0\n",
    "_index_in_epoch_val = 0\n",
    "_epochs_completed_test = 0\n",
    "_index_in_epoch_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][1,0] = 1\n",
    "y2[6][1,1] = 1\n",
    "y2[7][1,2] = 1\n",
    "y2[8][1,3] = 1\n",
    "y2[9][1,4] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_super_labels = np.array([y[np.argmax(train_labels[j])] for j in range(train_labels.shape[0])])\n",
    "test_super_labels = np.array([y[np.argmax(test_labels[j])] for j in range(test_labels.shape[0])])\n",
    "\n",
    "train_labels = np.array([y2[np.argmax(train_labels[j])] for j in range(train_labels.shape[0])])\n",
    "test_labels = np.array([y2[np.argmax(test_labels[j])] for j in range(test_labels.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not 0 <= validation_size <= len(train_images):\n",
    "    raise ValueError(\n",
    "        'Validation size should be between 0 and {}. Received: {}.'\n",
    "        .format(len(train_images), validation_size))\n",
    "\n",
    "validation_images = train_images[:validation_size]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "validation_super_labels = train_super_labels[:validation_size]\n",
    "#validation_labels_clipped = train_labels_clipped[:validation_size]\n",
    "train_images = train_images[validation_size:]\n",
    "train_labels = train_labels[validation_size:]\n",
    "train_super_labels = train_super_labels[validation_size:]\n",
    "#train_labels_clipped = train_labels_clipped[validation_size:]\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1] * train_images.shape[2])\n",
    "train_images = train_images.astype(np.float32)\n",
    "train_images = np.multiply(train_images, 1.0 / 255.0)\n",
    "\n",
    "validation_images = validation_images.reshape(validation_images.shape[0],validation_images.shape[1] * validation_images.shape[2])\n",
    "validation_images = validation_images.astype(np.float32)\n",
    "validation_images = np.multiply(validation_images, 1.0 / 255.0)\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1] * test_images.shape[2])\n",
    "test_images = test_images.astype(np.float32)\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "train_labels_labelled_only = np.array([y2[np.argmax(train_labels[j])] for j in range(int(train_labels.shape[0]*perc))])\n",
    "train_labels_clipped = np.concatenate([train_labels_labelled_only,np.array([emptyy2[np.argmax(train_labels[j])] for j in range(int(train_labels.shape[0]*perc),train_labels.shape[0])])])\n",
    "\n",
    "train_images_labelled_only = train_images[range(int(train_labels.shape[0]*perc)),:]\n",
    "train_super_labels_labelled_only = train_super_labels[range(int(train_labels.shape[0]*perc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, shuffle, images, labels, superlabels, ep_compl, ep_ind):\n",
    "    _epochs_completed = ep_compl\n",
    "    _index_in_epoch = ep_ind\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = _index_in_epoch\n",
    "    _num_examples = images.shape[0]\n",
    "    # Shuffle for the first epoch\n",
    "    if _epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      _images = images[perm0]\n",
    "      _labels = labels[perm0]\n",
    "      _super_labels = superlabels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = _num_examples - start\n",
    "      images_rest_part = _images[start:_num_examples]\n",
    "      labels_rest_part = _labels[start:_num_examples]\n",
    "      super_labels_rest_part = _super_labels[start:_num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(_num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        _images = images[perm]\n",
    "        _labels = labels[perm]\n",
    "        _super_labels = superlabels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size - rest_num_examples\n",
    "      end = _index_in_epoch\n",
    "      images_new_part = _images[start:end]\n",
    "      labels_new_part = _labels[start:end]\n",
    "      super_labels_new_part = _super_labels[start:end]\n",
    "      return np.concatenate((images_rest_part, images_new_part), axis=0), np.concatenate((super_labels_rest_part, super_labels_new_part), axis=0), np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "    else:\n",
    "      _index_in_epoch += batch_size\n",
    "      end = _index_in_epoch\n",
    "      return _images[start:end], _super_labels[start:end], _labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper funcs\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def matrix_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    return tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "\n",
    "def avg_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_sum(totalSoft,2)\n",
    "\n",
    "def max_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_max(totalSoft,2)\n",
    "\n",
    "def initACOL(in_size,clust,clss):\n",
    "    acolLayers = []\n",
    "    for i in range(clss):\n",
    "        acolLayers.append([\n",
    "            weight_variable([in_size, clustCount]),\n",
    "            bias_variable([clustCount])\n",
    "        ])\n",
    "    return acolLayers\n",
    "        \n",
    "def connectACOL(inLayer,acol):\n",
    "    clust = []\n",
    "    for l in range(0,len(acol)):\n",
    "        clust.append(tf.matmul(inLayer, acol[l][0]) + acol[l][1])\n",
    "    return clust\n",
    "        \n",
    "def acol(input,clust_count, class_count):\n",
    "    acolLayers = []\n",
    "    for i in range(class_count):\n",
    "        if isinstance(input, tuple):\n",
    "                input = input[0]\n",
    "\n",
    "        #I don't know what this bit does, but I don't think it'll hurt anything\n",
    "        #Or maybe it does, who knows\n",
    "        input_shape = input.get_shape()\n",
    "        if input_shape.ndims == 4:\n",
    "            dim = 1\n",
    "            for d in input_shape[1:].as_list():\n",
    "                dim *= d\n",
    "        #    feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n",
    "        else:\n",
    "            feed_in, dim = (input, int(input_shape[-1]))\n",
    "\n",
    "        init_weights = tf.truncated_normal_initializer(0.0, stddev=0.1)#(0.0, stddev=0.01)\n",
    "        init_biases = tf.constant_initializer(1.0)#(0.1)\n",
    "\n",
    "        weights = weight_variable([dim, clust_count])\n",
    "        biases = bias_variable([clust_count])\n",
    "\n",
    "        acoll = tf.nn.xw_plus_b(input,weights,biases)\n",
    "        acolLayers.append(acol)\n",
    "    return acolLayers    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders (weights&biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    acol = initACOL(1024,clustCount,classCount)\n",
    "\n",
    "    #final fc layer\n",
    "    W_fc2 = weight_variable([1024, classCount])\n",
    "    b_fc2 = bias_variable([classCount])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    dropout=keep_prob\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    l_pool1 = max_pool_2x2(l_conv1)\n",
    "\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_pool1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_pool2, [-1, 7*7*64])\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, dropout)\n",
    "\n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y2_ = tf.placeholder(tf.float32, shape=[None,classCount,clustCount])\n",
    "    \n",
    "    #keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([3,3,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([3,3,32,32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "\n",
    "    #conv_layer3\n",
    "    W_conv3 = weight_variable([3,3,32,64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "\n",
    "    #conv_layer4\n",
    "    W_conv4 = weight_variable([3,3,64,64])\n",
    "    b_conv4 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    acol = initACOL(2048,clustCount,classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if net==1:\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_conv1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    l_drop1 = tf.nn.dropout(l_pool2, tf.constant(0.25))\n",
    "\n",
    "    #conv 3\n",
    "    l_conv3 = tf.nn.relu(conv2d(l_drop1, W_conv3) + b_conv3)\n",
    "    #conv 4\n",
    "    l_conv4 = tf.nn.relu(conv2d(l_conv3, W_conv4) + b_conv4)\n",
    "    l_pool4 = max_pool_2x2(l_conv4)\n",
    "\n",
    "    l_drop2 = tf.nn.dropout(l_pool4, tf.constant(0.25))\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_drop2, [-1, 7*7*64])\n",
    "\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, tf.constant(0.5))\n",
    "    \n",
    "    l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    stackedClusts = tf.stack(l_acol,1)\n",
    "    softmaxMat = matrix_softmax(stackedClusts)\n",
    "    smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper loss funcs\n",
    "def zBar(x):\n",
    "    xshape = x.shape.as_list()\n",
    "    s=[-1,xshape[1]*xshape[2]]\n",
    "    return tf.maximum(tf.reshape(x,s),0)\n",
    "    \n",
    "def bigU(zb):\n",
    "    return tf.matmul(tf.transpose(zb),zb)\n",
    "\n",
    "def selectNonDiag(x):\n",
    "    selection = np.ones(x.shape.as_list()[0],dtype='float32') - np.eye(x.shape.as_list()[0],dtype='float32')\n",
    "    return tf.reduce_sum(tf.multiply(x,selection))\n",
    "\n",
    "def bigV(x):\n",
    "    smallNu=tf.reshape(tf.reduce_sum(x,axis=0),[1,-1])\n",
    "    return tf.multiply(tf.transpose(smallNu),smallNu)\n",
    "\n",
    "def specialNormalise(x):\n",
    "    top = selectNonDiag(x)\n",
    "    bottom = tf.multiply(tf.to_float(x.shape[1]-1),tf.reduce_sum(tf.multiply(x,np.eye(x.shape[1],dtype='float32'))))\n",
    "    return tf.divide(top,bottom)\n",
    "\n",
    "def frobNorm(x):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "\n",
    "def silhouetteScore(X,clusts):\n",
    "    r = tf.reduce_sum(X*X, 1)\n",
    "    # turn r into column vector\n",
    "    r = tf.reshape(r, [-1, 1])\n",
    "    dists = r - 2*tf.matmul(X, tf.transpose(X)) + tf.transpose(r)\n",
    "    #interClust0 = \n",
    "    \n",
    "    \n",
    "\n",
    "tresh = tf.constant(0.03)\n",
    "cc0=1.0\n",
    "cc1=1.0\n",
    "cc2=1.0\n",
    "cc3=0.0003\n",
    "cc4=0.000001\n",
    "cc5=1.0\n",
    "c0 = tf.constant(cc0)\n",
    "c1 = tf.constant(cc1)\n",
    "c2 = tf.constant(cc2)\n",
    "c3val = tf.constant(cc3)\n",
    "c3 = lambda affinity: tf.cond(tf.less(affinity,tresh),lambda: c3val,lambda: tf.constant(0.0))\n",
    "c4 =tf.constant(cc4)\n",
    "c5 = tf.constant(cc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate losses\n",
    "#affinity\n",
    "bZ = zBar(stackedClusts)#softmaxMat)\n",
    "bU = bigU(bZ)\n",
    "coact = selectNonDiag(bU)\n",
    "affinity = specialNormalise(bU)\n",
    "\n",
    "#balance\n",
    "bV=bigV(bZ)\n",
    "balance = specialNormalise(bV)\n",
    "\n",
    "#cluster cross entropy (added if secondary label is set for that input, hard to do with batches?)\n",
    "clust_cross_entropy = tf.reduce_mean(-tf.reduce_sum(y2_ * tf.log(tf.clip_by_value(softmaxMat,1e-10,1.0)), reduction_indices=[1,2]))\n",
    "\n",
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))\n",
    "\n",
    "frob = frobNorm(stackedClusts)#softmaxMat)\n",
    "\n",
    "loss = c0*cross_entropy + c5*clust_cross_entropy + c1*affinity + c2*tf.subtract(tf.constant(1.0),balance) + c3(affinity)*coact + c4*frob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y = {0:[0,1], 1:[1,0]}\n",
    "y = {0:[1,0,0,0,0],\n",
    "     1:[1,0,0,0,0],\n",
    "     2:[0,1,0,0,0],\n",
    "     3:[0,1,0,0,0],\n",
    "     4:[0,0,1,0,0],\n",
    "     5:[0,0,1,0,0],\n",
    "     6:[0,0,0,1,0],\n",
    "     7:[0,0,0,1,0],\n",
    "     8:[0,0,0,0,1],\n",
    "     9:[0,0,0,0,1]}\n",
    "\n",
    "y = {0:[1,0],\n",
    "     1:[1,0],\n",
    "     2:[1,0],\n",
    "     3:[1,0],\n",
    "     4:[1,0],\n",
    "     5:[0,1],\n",
    "     6:[0,1],\n",
    "     7:[0,1],\n",
    "     8:[0,1],\n",
    "     9:[0,1]}\n",
    "\n",
    "y2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "y2[0][0,0] = 1\n",
    "y2[1][0,1] = 1\n",
    "y2[2][0,2] = 1\n",
    "y2[3][0,3] = 1\n",
    "y2[4][0,4] = 1\n",
    "y2[5][1,0] = 1\n",
    "y2[6][1,1] = 1\n",
    "y2[7][1,2] = 1\n",
    "y2[8][1,3] = 1\n",
    "y2[9][1,4] = 1\n",
    "\n",
    "emptyy2 = {\n",
    "    0:np.zeros((classCount,clustCount)),\n",
    "    1:np.zeros((classCount,clustCount)),\n",
    "    2:np.zeros((classCount,clustCount)),\n",
    "    3:np.zeros((classCount,clustCount)),\n",
    "    4:np.zeros((classCount,clustCount)),\n",
    "    5:np.zeros((classCount,clustCount)),\n",
    "    6:np.zeros((classCount,clustCount)),\n",
    "    7:np.zeros((classCount,clustCount)),\n",
    "    8:np.zeros((classCount,clustCount)),\n",
    "    9:np.zeros((classCount,clustCount))\n",
    "}\n",
    "\n",
    "totalSteps = trainsteps\n",
    "stepCount=0\n",
    "batchSize = 128\n",
    "hist = {\n",
    "    'train_acc':[],\n",
    "    'val_acc':[],\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'affinity':[],\n",
    "    'balance':[],\n",
    "    'coactivity':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "step 0/30000 \n",
      " Train: accuracy: 0.507812, loss: 16.6317 \n",
      " Validation: accuracy: 0.460938 loss: 17.9173\n",
      " cross_entropy: 3.90061, clust_cross_entropy: 13.2706, affinity: 0.39073, balance: 0.325773, coact: 65.9839, frob: 0.0003437\n",
      "step 100/30000 \n",
      " Train: accuracy: 0.515625, loss: 12.5265 \n",
      " Validation: accuracy: 0.59375 loss: 12.0806\n",
      " cross_entropy: 2.50325, clust_cross_entropy: 9.33249, affinity: 0.374831, balance: 0.0287455, coact: 35.4057, frob: 0.000239175\n",
      "step 200/30000 \n",
      " Train: accuracy: 0.570312, loss: 7.69606 \n",
      " Validation: accuracy: 0.625 loss: 8.09229\n",
      " cross_entropy: 1.5609, clust_cross_entropy: 7.06322, affinity: 0.351386, balance: 0.0186884, coact: 21.7665, frob: 0.000197239\n",
      "step 300/30000 \n",
      " Train: accuracy: 0.648438, loss: 5.13721 \n",
      " Validation: accuracy: 0.53125 loss: 6.42824\n",
      " cross_entropy: 1.47462, clust_cross_entropy: 4.16229, affinity: 0.317157, balance: 0.0240343, coact: 12.935, frob: 0.000171904\n",
      "step 400/30000 \n",
      " Train: accuracy: 0.6875, loss: 4.57385 \n",
      " Validation: accuracy: 0.671875 loss: 4.64626\n",
      " cross_entropy: 1.15911, clust_cross_entropy: 2.39995, affinity: 0.265377, balance: 0.0287783, coact: 7.66377, frob: 0.000153588\n",
      "step 500/30000 \n",
      " Train: accuracy: 0.75, loss: 2.99974 \n",
      " Validation: accuracy: 0.664062 loss: 4.56216\n",
      " cross_entropy: 0.825345, clust_cross_entropy: 1.98174, affinity: 0.206236, balance: 0.0108141, coact: 6.13425, frob: 0.000153482\n",
      "step 600/30000 \n",
      " Train: accuracy: 0.75, loss: 2.92178 \n",
      " Validation: accuracy: 0.679688 loss: 3.54023\n",
      " cross_entropy: 0.754207, clust_cross_entropy: 1.61879, affinity: 0.195857, balance: 0.0183435, coact: 3.5585, frob: 0.000135691\n",
      "step 700/30000 \n",
      " Train: accuracy: 0.804688, loss: 2.13618 \n",
      " Validation: accuracy: 0.765625 loss: 2.33198\n",
      " cross_entropy: 0.561705, clust_cross_entropy: 1.38264, affinity: 0.1791, balance: 0.0247238, coact: 3.19509, frob: 0.000145664\n",
      "step 800/30000 \n",
      " Train: accuracy: 0.8125, loss: 2.11543 \n",
      " Validation: accuracy: 0.796875 loss: 2.08707\n",
      " cross_entropy: 0.628339, clust_cross_entropy: 1.41596, affinity: 0.154309, balance: 0.0219569, coact: 2.79197, frob: 0.00013783\n",
      "step 900/30000 \n",
      " Train: accuracy: 0.84375, loss: 1.7637 \n",
      " Validation: accuracy: 0.820312 loss: 2.13652\n",
      " cross_entropy: 0.487291, clust_cross_entropy: 0.961965, affinity: 0.13151, balance: 0.0241383, coact: 2.12581, frob: 0.000137416\n",
      "step 1000/30000 \n",
      " Train: accuracy: 0.835938, loss: 1.5536 \n",
      " Validation: accuracy: 0.804688 loss: 2.16307\n",
      " cross_entropy: 0.542325, clust_cross_entropy: 0.963377, affinity: 0.135193, balance: 0.0303562, coact: 1.60792, frob: 0.000140689\n",
      "step 1100/30000 \n",
      " Train: accuracy: 0.851562, loss: 1.38837 \n",
      " Validation: accuracy: 0.875 loss: 1.5197\n",
      " cross_entropy: 0.410623, clust_cross_entropy: 0.67575, affinity: 0.116232, balance: 0.0295536, coact: 1.76262, frob: 0.000141675\n",
      "step 1200/30000 \n",
      " Train: accuracy: 0.867188, loss: 1.41266 \n",
      " Validation: accuracy: 0.820312 loss: 1.86102\n",
      " cross_entropy: 0.379509, clust_cross_entropy: 0.714722, affinity: 0.119261, balance: 0.0453913, coact: 1.59895, frob: 0.000137908\n",
      "step 1300/30000 \n",
      " Train: accuracy: 0.890625, loss: 1.30379 \n",
      " Validation: accuracy: 0.773438 loss: 1.91059\n",
      " cross_entropy: 0.392283, clust_cross_entropy: 0.664061, affinity: 0.11483, balance: 0.040557, coact: 1.73941, frob: 0.000137302\n",
      "step 1400/30000 \n",
      " Train: accuracy: 0.929688, loss: 1.10778 \n",
      " Validation: accuracy: 0.875 loss: 1.35511\n",
      " cross_entropy: 0.360254, clust_cross_entropy: 0.615206, affinity: 0.0953633, balance: 0.0757228, coact: 1.54601, frob: 0.000139242\n",
      "step 1500/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.877167 \n",
      " Validation: accuracy: 0.867188 loss: 1.33474\n",
      " cross_entropy: 0.317671, clust_cross_entropy: 0.445951, affinity: 0.0989491, balance: 0.0297254, coact: 1.68004, frob: 0.000147382\n",
      "step 1600/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.944616 \n",
      " Validation: accuracy: 0.882812 loss: 1.50793\n",
      " cross_entropy: 0.28692, clust_cross_entropy: 0.638414, affinity: 0.0861669, balance: 0.00665897, coact: 1.39154, frob: 0.000142313\n",
      "step 1700/30000 \n",
      " Train: accuracy: 0.929688, loss: 0.788181 \n",
      " Validation: accuracy: 0.835938 loss: 1.77373\n",
      " cross_entropy: 0.288254, clust_cross_entropy: 0.291412, affinity: 0.0891332, balance: 0.032095, coact: 1.56887, frob: 0.000144321\n",
      "step 1800/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.765787 \n",
      " Validation: accuracy: 0.859375 loss: 1.48884\n",
      " cross_entropy: 0.270061, clust_cross_entropy: 0.324318, affinity: 0.097397, balance: 0.0392888, coact: 1.45038, frob: 0.000145924\n",
      "step 1900/30000 \n",
      " Train: accuracy: 0.921875, loss: 0.800832 \n",
      " Validation: accuracy: 0.875 loss: 1.47562\n",
      " cross_entropy: 0.261954, clust_cross_entropy: 0.493551, affinity: 0.0915151, balance: 0.0253736, coact: 1.27725, frob: 0.000143984\n",
      "step 2000/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.671352 \n",
      " Validation: accuracy: 0.882812 loss: 1.17957\n",
      " cross_entropy: 0.22437, clust_cross_entropy: 0.348006, affinity: 0.0756691, balance: 0.0231234, coact: 1.46279, frob: 0.000151336\n",
      "step 2100/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.572032 \n",
      " Validation: accuracy: 0.882812 loss: 1.30255\n",
      " cross_entropy: 0.12733, clust_cross_entropy: 0.315961, affinity: 0.0888376, balance: 0.0316206, coact: 1.55301, frob: 0.000148154\n",
      "step 2200/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.64904 \n",
      " Validation: accuracy: 0.882812 loss: 1.30163\n",
      " cross_entropy: 0.213704, clust_cross_entropy: 0.312042, affinity: 0.0890583, balance: 0.0501636, coact: 1.51942, frob: 0.000150744\n",
      "step 2300/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.590104 \n",
      " Validation: accuracy: 0.929688 loss: 0.903719\n",
      " cross_entropy: 0.147836, clust_cross_entropy: 0.284577, affinity: 0.0830143, balance: 0.0333403, coact: 1.26286, frob: 0.000145787\n",
      "step 2400/30000 \n",
      " Train: accuracy: 0.945312, loss: 0.510723 \n",
      " Validation: accuracy: 0.890625 loss: 1.48709\n",
      " cross_entropy: 0.177477, clust_cross_entropy: 0.22344, affinity: 0.0777334, balance: 0.0348315, coact: 1.36185, frob: 0.000150112\n",
      "step 2500/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.557134 \n",
      " Validation: accuracy: 0.914062 loss: 1.23676\n",
      " cross_entropy: 0.198205, clust_cross_entropy: 0.244205, affinity: 0.0698228, balance: 0.0694697, coact: 1.30417, frob: 0.00015575\n",
      "step 2600/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.423477 \n",
      " Validation: accuracy: 0.875 loss: 1.19845\n",
      " cross_entropy: 0.130451, clust_cross_entropy: 0.196427, affinity: 0.0674745, balance: 0.077442, coact: 1.45908, frob: 0.000154074\n",
      "step 2700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.457563 \n",
      " Validation: accuracy: 0.851562 loss: 1.22466\n",
      " cross_entropy: 0.135944, clust_cross_entropy: 0.153937, affinity: 0.0624655, balance: 0.0297258, coact: 1.30112, frob: 0.000153456\n",
      "step 2800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.391554 \n",
      " Validation: accuracy: 0.898438 loss: 1.04426\n",
      " cross_entropy: 0.14844, clust_cross_entropy: 0.218102, affinity: 0.0702115, balance: 0.0293073, coact: 1.60016, frob: 0.000150314\n",
      "step 2900/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.406415 \n",
      " Validation: accuracy: 0.890625 loss: 1.57338\n",
      " cross_entropy: 0.118743, clust_cross_entropy: 0.292972, affinity: 0.0724747, balance: 0.0350811, coact: 1.19741, frob: 0.000158709\n",
      "step 3000/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.431946 \n",
      " Validation: accuracy: 0.90625 loss: 1.12538\n",
      " cross_entropy: 0.141966, clust_cross_entropy: 0.193771, affinity: 0.0690911, balance: 0.0318255, coact: 1.10687, frob: 0.00016427\n",
      "step 3100/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.251045 \n",
      " Validation: accuracy: 0.890625 loss: 0.960934\n",
      " cross_entropy: 0.0982353, clust_cross_entropy: 0.234615, affinity: 0.0613835, balance: 0.0306215, coact: 1.40068, frob: 0.000157411\n",
      "step 3200/30000 \n",
      " Train: accuracy: 1, loss: 0.40977 \n",
      " Validation: accuracy: 0.890625 loss: 1.25215\n",
      " cross_entropy: 0.111879, clust_cross_entropy: 0.154402, affinity: 0.0513947, balance: 0.0855271, coact: 1.36087, frob: 0.000167031\n",
      "step 3300/30000 \n",
      " Train: accuracy: 0.9375, loss: 0.482609 \n",
      " Validation: accuracy: 0.835938 loss: 1.43598\n",
      " cross_entropy: 0.0984703, clust_cross_entropy: 0.145601, affinity: 0.0563086, balance: 0.121886, coact: 1.55666, frob: 0.000163252\n",
      "step 3400/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.519239 \n",
      " Validation: accuracy: 0.945312 loss: 0.803944\n",
      " cross_entropy: 0.0974623, clust_cross_entropy: 0.189948, affinity: 0.056117, balance: 0.0375817, coact: 1.27894, frob: 0.000167559\n",
      "step 3500/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.309821 \n",
      " Validation: accuracy: 0.945312 loss: 0.857204\n",
      " cross_entropy: 0.0967018, clust_cross_entropy: 0.168987, affinity: 0.0620095, balance: 0.0791659, coact: 1.19328, frob: 0.000166783\n",
      "step 3600/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.218841 \n",
      " Validation: accuracy: 0.898438 loss: 0.991454\n",
      " cross_entropy: 0.0690132, clust_cross_entropy: 0.0582214, affinity: 0.0560139, balance: 0.0649087, coact: 1.24321, frob: 0.000176344\n",
      "step 3700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.446297 \n",
      " Validation: accuracy: 0.90625 loss: 1.05706\n",
      " cross_entropy: 0.114383, clust_cross_entropy: 0.193822, affinity: 0.0555762, balance: 0.0708861, coact: 1.1553, frob: 0.00016854\n",
      "step 3800/30000 \n",
      " Train: accuracy: 0.960938, loss: 0.374494 \n",
      " Validation: accuracy: 0.875 loss: 1.11695\n",
      " cross_entropy: 0.0837545, clust_cross_entropy: 0.0957872, affinity: 0.0563374, balance: 0.0370315, coact: 1.06592, frob: 0.000171117\n",
      "step 3900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.307049 \n",
      " Validation: accuracy: 0.945312 loss: 0.798159\n",
      " cross_entropy: 0.0755145, clust_cross_entropy: 0.0994797, affinity: 0.0571154, balance: 0.0484206, coact: 1.09936, frob: 0.00017779\n",
      "step 4000/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.2892 \n",
      " Validation: accuracy: 0.898438 loss: 1.14703\n",
      " cross_entropy: 0.086762, clust_cross_entropy: 0.112607, affinity: 0.0493176, balance: 0.0555708, coact: 1.11716, frob: 0.000172321\n",
      "step 4100/30000 \n",
      " Train: accuracy: 1, loss: 0.316831 \n",
      " Validation: accuracy: 0.875 loss: 1.20832\n",
      " cross_entropy: 0.0399199, clust_cross_entropy: 0.072742, affinity: 0.0517892, balance: 0.0683002, coact: 1.18197, frob: 0.000177871\n",
      "step 4200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.210399 \n",
      " Validation: accuracy: 0.90625 loss: 0.98991\n",
      " cross_entropy: 0.040771, clust_cross_entropy: 0.0723386, affinity: 0.0464274, balance: 0.0477173, coact: 1.07293, frob: 0.000175892\n",
      "step 4300/30000 \n",
      " Train: accuracy: 1, loss: 0.293962 \n",
      " Validation: accuracy: 0.921875 loss: 1.06199\n",
      " cross_entropy: 0.063066, clust_cross_entropy: 0.0709876, affinity: 0.0398317, balance: 0.121527, coact: 1.03125, frob: 0.000193401\n",
      "step 4400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.291358 \n",
      " Validation: accuracy: 0.90625 loss: 1.12826\n",
      " cross_entropy: 0.0699395, clust_cross_entropy: 0.114074, affinity: 0.0465335, balance: 0.032247, coact: 1.1931, frob: 0.000182197\n",
      "step 4500/30000 \n",
      " Train: accuracy: 1, loss: 0.197372 \n",
      " Validation: accuracy: 0.859375 loss: 1.30171\n",
      " cross_entropy: 0.0381458, clust_cross_entropy: 0.0972255, affinity: 0.0395698, balance: 0.0531517, coact: 1.09849, frob: 0.000183255\n",
      "step 4600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.203583 \n",
      " Validation: accuracy: 0.914062 loss: 0.840701\n",
      " cross_entropy: 0.0553936, clust_cross_entropy: 0.0475314, affinity: 0.0500319, balance: 0.0451844, coact: 1.25172, frob: 0.000189614\n",
      "step 4700/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.299967 \n",
      " Validation: accuracy: 0.9375 loss: 1.00901\n",
      " cross_entropy: 0.0641563, clust_cross_entropy: 0.128103, affinity: 0.0397839, balance: 0.0410497, coact: 0.882699, frob: 0.00018436\n",
      "step 4800/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.173071 \n",
      " Validation: accuracy: 0.890625 loss: 1.11627\n",
      " cross_entropy: 0.039262, clust_cross_entropy: 0.0203966, affinity: 0.0429358, balance: 0.0354464, coact: 1.00965, frob: 0.00018512\n",
      "step 4900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.116111 \n",
      " Validation: accuracy: 0.914062 loss: 1.11429\n",
      " cross_entropy: 0.0258467, clust_cross_entropy: 0.0603466, affinity: 0.040579, balance: 0.0183994, coact: 1.11134, frob: 0.000194235\n",
      "step 5000/30000 \n",
      " Train: accuracy: 1, loss: 0.120538 \n",
      " Validation: accuracy: 0.945312 loss: 0.824003\n",
      " cross_entropy: 0.0433781, clust_cross_entropy: 0.0540972, affinity: 0.0298513, balance: 0.0618005, coact: 0.80959, frob: 0.000186367\n",
      "step 5100/30000 \n",
      " Train: accuracy: 0.96875, loss: 0.407123 \n",
      " Validation: accuracy: 0.890625 loss: 1.14076\n",
      " cross_entropy: 0.080098, clust_cross_entropy: 0.133678, affinity: 0.00684512, balance: 0.108044, coact: 0.0616953, frob: 0.000239231\n",
      "step 5200/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.250235 \n",
      " Validation: accuracy: 0.914062 loss: 1.10698\n",
      " cross_entropy: 0.0675561, clust_cross_entropy: 0.0755163, affinity: 0.00815281, balance: 0.0205328, coact: 0.0244019, frob: 0.000241322\n",
      "step 5300/30000 \n",
      " Train: accuracy: 1, loss: 0.357263 \n",
      " Validation: accuracy: 0.953125 loss: 0.861477\n",
      " cross_entropy: 0.0825939, clust_cross_entropy: 0.0943359, affinity: 0.00988884, balance: 0.088515, coact: 0.0497903, frob: 0.000229822\n",
      "step 5400/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.229662 \n",
      " Validation: accuracy: 0.875 loss: 1.16994\n",
      " cross_entropy: 0.0533341, clust_cross_entropy: 0.0645756, affinity: 0.00252711, balance: 0.129493, coact: 0.0583513, frob: 0.000244567\n",
      "step 5500/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.308775 \n",
      " Validation: accuracy: 0.890625 loss: 1.44944\n",
      " cross_entropy: 0.0784321, clust_cross_entropy: 0.0566083, affinity: 0.00231895, balance: 0.105055, coact: 0.0332123, frob: 0.00025059\n",
      "step 5600/30000 \n",
      " Train: accuracy: 1, loss: 0.297276 \n",
      " Validation: accuracy: 0.890625 loss: 1.26166\n",
      " cross_entropy: 0.050238, clust_cross_entropy: 0.0767664, affinity: 0.00460863, balance: 0.0896643, coact: 0.0517798, frob: 0.000241796\n",
      "step 5700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.379548 \n",
      " Validation: accuracy: 0.921875 loss: 0.917893\n",
      " cross_entropy: 0.065899, clust_cross_entropy: 0.0752111, affinity: 0.00449022, balance: 0.11752, coact: 0.083697, frob: 0.000237493\n",
      "step 5800/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.276559 \n",
      " Validation: accuracy: 0.929688 loss: 1.07314\n",
      " cross_entropy: 0.0361613, clust_cross_entropy: 0.0876832, affinity: 0.00323941, balance: 0.149415, coact: 0.0239135, frob: 0.000250757\n",
      "step 5900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.265712 \n",
      " Validation: accuracy: 0.90625 loss: 1.11523\n",
      " cross_entropy: 0.0478209, clust_cross_entropy: 0.0654604, affinity: 0.0055394, balance: 0.141479, coact: 0.0265613, frob: 0.000240638\n",
      "step 6000/30000 \n",
      " Train: accuracy: 1, loss: 0.17367 \n",
      " Validation: accuracy: 0.898438 loss: 1.34279\n",
      " cross_entropy: 0.03739, clust_cross_entropy: 0.0725197, affinity: 0.00552434, balance: 0.0778918, coact: 0.0181621, frob: 0.000242359\n",
      "step 6100/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.233813 \n",
      " Validation: accuracy: 0.90625 loss: 1.04209\n",
      " cross_entropy: 0.0527221, clust_cross_entropy: 0.0709356, affinity: 0.00458024, balance: 0.0428743, coact: 0.0336995, frob: 0.000236251\n",
      "step 6200/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.2054 \n",
      " Validation: accuracy: 0.859375 loss: 1.24355\n",
      " cross_entropy: 0.04589, clust_cross_entropy: 0.0340767, affinity: 0.00395149, balance: 0.0787517, coact: 0.0170539, frob: 0.000249308\n",
      "step 6300/30000 \n",
      " Train: accuracy: 1, loss: 0.155999 \n",
      " Validation: accuracy: 0.90625 loss: 1.27165\n",
      " cross_entropy: 0.0383644, clust_cross_entropy: 0.0219823, affinity: 0.00389333, balance: 0.0516657, coact: 0.0474092, frob: 0.000252471\n",
      "step 6400/30000 \n",
      " Train: accuracy: 0.976562, loss: 0.265619 \n",
      " Validation: accuracy: 0.914062 loss: 0.974842\n",
      " cross_entropy: 0.0498453, clust_cross_entropy: 0.0345829, affinity: 0.000955924, balance: 0.0650513, coact: 0.0368977, frob: 0.000253043\n",
      "step 6500/30000 \n",
      " Train: accuracy: 1, loss: 0.196425 \n",
      " Validation: accuracy: 0.90625 loss: 0.898365\n",
      " cross_entropy: 0.044613, clust_cross_entropy: 0.0663227, affinity: 0.00188973, balance: 0.101434, coact: 0.0106873, frob: 0.000256754\n",
      "step 6600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.192481 \n",
      " Validation: accuracy: 0.914062 loss: 0.923337\n",
      " cross_entropy: 0.0359653, clust_cross_entropy: 0.0735989, affinity: 0.00229435, balance: 0.0727006, coact: 0.019051, frob: 0.00025511\n",
      "step 6700/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.220079 \n",
      " Validation: accuracy: 0.945312 loss: 1.05434\n",
      " cross_entropy: 0.0417294, clust_cross_entropy: 0.0450778, affinity: 0.00305263, balance: 0.0258918, coact: 0.0109964, frob: 0.000252461\n",
      "step 6800/30000 \n",
      " Train: accuracy: 1, loss: 0.186566 \n",
      " Validation: accuracy: 0.929688 loss: 0.874936\n",
      " cross_entropy: 0.0428376, clust_cross_entropy: 0.0426858, affinity: 0.00334654, balance: 0.124674, coact: 0.0301584, frob: 0.000268389\n",
      "step 6900/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.160156 \n",
      " Validation: accuracy: 0.9375 loss: 0.651576\n",
      " cross_entropy: 0.0332354, clust_cross_entropy: 0.0550344, affinity: 0.0018998, balance: 0.0691494, coact: 0.0158656, frob: 0.000253883\n",
      "step 7000/30000 \n",
      " Train: accuracy: 1, loss: 0.190535 \n",
      " Validation: accuracy: 0.867188 loss: 1.6755\n",
      " cross_entropy: 0.0325372, clust_cross_entropy: 0.0712249, affinity: 0.00685625, balance: 0.117156, coact: 0.019315, frob: 0.000271614\n",
      "step 7100/30000 \n",
      " Train: accuracy: 1, loss: 0.150436 \n",
      " Validation: accuracy: 0.945312 loss: 0.717621\n",
      " cross_entropy: 0.0368546, clust_cross_entropy: 0.0384682, affinity: 0.00421741, balance: 0.0828351, coact: 0.0363225, frob: 0.000268941\n",
      "step 7200/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.158084 \n",
      " Validation: accuracy: 0.953125 loss: 0.958797\n",
      " cross_entropy: 0.0498559, clust_cross_entropy: 0.0534131, affinity: 0.00217361, balance: 0.0454609, coact: 0.00984767, frob: 0.000274142\n",
      "step 7300/30000 \n",
      " Train: accuracy: 1, loss: 0.122192 \n",
      " Validation: accuracy: 0.945312 loss: 0.859562\n",
      " cross_entropy: 0.029347, clust_cross_entropy: 0.01601, affinity: 0.00361285, balance: 0.0736531, coact: 0.0264649, frob: 0.000272683\n",
      "step 7400/30000 \n",
      " Train: accuracy: 1, loss: 0.0792426 \n",
      " Validation: accuracy: 0.953125 loss: 0.685669\n",
      " cross_entropy: 0.0293014, clust_cross_entropy: 0.025304, affinity: 0.00124413, balance: 0.0406941, coact: 0.0428676, frob: 0.000274792\n",
      "step 7500/30000 \n",
      " Train: accuracy: 1, loss: 0.163509 \n",
      " Validation: accuracy: 0.9375 loss: 0.777311\n",
      " cross_entropy: 0.0319127, clust_cross_entropy: 0.0190265, affinity: 0.00284827, balance: 0.0595298, coact: 0.027117, frob: 0.000262724\n",
      "step 7600/30000 \n",
      " Train: accuracy: 1, loss: 0.0963418 \n",
      " Validation: accuracy: 0.90625 loss: 1.20259\n",
      " cross_entropy: 0.0195905, clust_cross_entropy: 0.0428986, affinity: 0.00136837, balance: 0.0301186, coact: 0.0115425, frob: 0.00027287\n",
      "step 7700/30000 \n",
      " Train: accuracy: 1, loss: 0.188475 \n",
      " Validation: accuracy: 0.921875 loss: 0.965657\n",
      " cross_entropy: 0.0156009, clust_cross_entropy: 0.0352855, affinity: 0.00134616, balance: 0.0262526, coact: 0.0344568, frob: 0.000270719\n",
      "step 7800/30000 \n",
      " Train: accuracy: 1, loss: 0.21602 \n",
      " Validation: accuracy: 0.945312 loss: 0.908167\n",
      " cross_entropy: 0.0310871, clust_cross_entropy: 0.0338371, affinity: 0.000919604, balance: 0.0897971, coact: 0.0449004, frob: 0.000264162\n",
      "step 7900/30000 \n",
      " Train: accuracy: 1, loss: 0.126484 \n",
      " Validation: accuracy: 0.9375 loss: 1.04974\n",
      " cross_entropy: 0.0232431, clust_cross_entropy: 0.0263432, affinity: 0.0026571, balance: 0.0451338, coact: 0.0430108, frob: 0.000263296\n",
      "step 8000/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.121744 \n",
      " Validation: accuracy: 0.945312 loss: 1.02316\n",
      " cross_entropy: 0.0143672, clust_cross_entropy: 0.032345, affinity: 0.000867151, balance: 0.0736179, coact: 0.0227208, frob: 0.000260974\n",
      "step 8100/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.230343 \n",
      " Validation: accuracy: 0.921875 loss: 0.854489\n",
      " cross_entropy: 0.0134491, clust_cross_entropy: 0.0264414, affinity: 0.000509589, balance: 0.109473, coact: 0.0201562, frob: 0.000276512\n",
      "step 8200/30000 \n",
      " Train: accuracy: 1, loss: 0.120695 \n",
      " Validation: accuracy: 0.882812 loss: 1.28834\n",
      " cross_entropy: 0.0147706, clust_cross_entropy: 0.0349374, affinity: 0.000243487, balance: 0.0306678, coact: 0.00470606, frob: 0.000268099\n",
      "step 8300/30000 \n",
      " Train: accuracy: 1, loss: 0.12508 \n",
      " Validation: accuracy: 0.882812 loss: 0.975372\n",
      " cross_entropy: 0.0263496, clust_cross_entropy: 0.0289543, affinity: 0.0011598, balance: 0.0426919, coact: 0.0107378, frob: 0.000278192\n",
      "step 8400/30000 \n",
      " Train: accuracy: 1, loss: 0.157648 \n",
      " Validation: accuracy: 0.96875 loss: 0.720435\n",
      " cross_entropy: 0.02221, clust_cross_entropy: 0.0140166, affinity: 0.00215112, balance: 0.114663, coact: 0.0160733, frob: 0.000281048\n",
      "step 8500/30000 \n",
      " Train: accuracy: 1, loss: 0.0780523 \n",
      " Validation: accuracy: 0.890625 loss: 1.02272\n",
      " cross_entropy: 0.015268, clust_cross_entropy: 0.0208189, affinity: 0.000375354, balance: 0.0442082, coact: 0.0145481, frob: 0.000278925\n",
      "step 8600/30000 \n",
      " Train: accuracy: 1, loss: 0.120211 \n",
      " Validation: accuracy: 0.945312 loss: 0.810362\n",
      " cross_entropy: 0.0157661, clust_cross_entropy: 0.0334699, affinity: 0.00106508, balance: 0.0663472, coact: 0.00571821, frob: 0.000275308\n",
      "step 8700/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.216094 \n",
      " Validation: accuracy: 0.90625 loss: 1.05388\n",
      " cross_entropy: 0.0103563, clust_cross_entropy: 0.0298235, affinity: 0.000637712, balance: 0.0976138, coact: 0.00509579, frob: 0.00026946\n",
      "step 8800/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.150605 \n",
      " Validation: accuracy: 0.9375 loss: 0.927714\n",
      " cross_entropy: 0.0202195, clust_cross_entropy: 0.0240798, affinity: 0.000188068, balance: 0.0799565, coact: 0.0262668, frob: 0.000280498\n",
      "step 8900/30000 \n",
      " Train: accuracy: 1, loss: 0.0915529 \n",
      " Validation: accuracy: 0.929688 loss: 0.96779\n",
      " cross_entropy: 0.00975024, clust_cross_entropy: 0.0205332, affinity: 0.0002139, balance: 0.058615, coact: 0.00814704, frob: 0.00027144\n",
      "step 9000/30000 \n",
      " Train: accuracy: 1, loss: 0.145401 \n",
      " Validation: accuracy: 0.890625 loss: 1.31519\n",
      " cross_entropy: 0.0196262, clust_cross_entropy: 0.0246245, affinity: 0.00140999, balance: 0.0861431, coact: 0.0176006, frob: 0.000282602\n",
      "step 9100/30000 \n",
      " Train: accuracy: 1, loss: 0.143505 \n",
      " Validation: accuracy: 0.921875 loss: 0.956656\n",
      " cross_entropy: 0.0111643, clust_cross_entropy: 0.0280449, affinity: 0.00115511, balance: 0.0555545, coact: 0.00672636, frob: 0.000288995\n",
      "step 9200/30000 \n",
      " Train: accuracy: 1, loss: 0.163227 \n",
      " Validation: accuracy: 0.929688 loss: 0.985261\n",
      " cross_entropy: 0.0164513, clust_cross_entropy: 0.0073145, affinity: 0.00119727, balance: 0.0702738, coact: 0.00307104, frob: 0.000286399\n",
      "step 9300/30000 \n",
      " Train: accuracy: 1, loss: 0.130967 \n",
      " Validation: accuracy: 0.945312 loss: 0.941028\n",
      " cross_entropy: 0.00804468, clust_cross_entropy: 0.0369361, affinity: 0.000482159, balance: 0.0912363, coact: 0.00219426, frob: 0.000285535\n",
      "step 9400/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.114143 \n",
      " Validation: accuracy: 0.945312 loss: 0.749646\n",
      " cross_entropy: 0.013971, clust_cross_entropy: 0.0148335, affinity: 0.00137668, balance: 0.0823597, coact: 0.00721652, frob: 0.000289142\n",
      "step 9500/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.140044 \n",
      " Validation: accuracy: 0.960938 loss: 0.69294\n",
      " cross_entropy: 0.0211481, clust_cross_entropy: 0.0124559, affinity: 0.00102039, balance: 0.0631623, coact: 0.0132292, frob: 0.000276745\n",
      "step 9600/30000 \n",
      " Train: accuracy: 1, loss: 0.135741 \n",
      " Validation: accuracy: 0.929688 loss: 0.666879\n",
      " cross_entropy: 0.0268434, clust_cross_entropy: 0.00887578, affinity: 0.00110065, balance: 0.0943427, coact: 0.00648855, frob: 0.000286331\n",
      "step 9700/30000 \n",
      " Train: accuracy: 1, loss: 0.0703617 \n",
      " Validation: accuracy: 0.921875 loss: 0.913289\n",
      " cross_entropy: 0.0212489, clust_cross_entropy: 0.0150596, affinity: 0.00210255, balance: 0.03471, coact: 0.0175457, frob: 0.000297482\n",
      "step 9800/30000 \n",
      " Train: accuracy: 1, loss: 0.177165 \n",
      " Validation: accuracy: 0.929688 loss: 0.883174\n",
      " cross_entropy: 0.0185869, clust_cross_entropy: 0.0100388, affinity: 0.000448714, balance: 0.176948, coact: 0.0145165, frob: 0.000278544\n",
      "step 9900/30000 \n",
      " Train: accuracy: 1, loss: 0.225372 \n",
      " Validation: accuracy: 0.929688 loss: 0.850922\n",
      " cross_entropy: 0.0131332, clust_cross_entropy: 0.0223357, affinity: 0.00115829, balance: 0.145143, coact: 0.0170699, frob: 0.000282752\n",
      "step 10000/30000 \n",
      " Train: accuracy: 1, loss: 0.139002 \n",
      " Validation: accuracy: 0.914062 loss: 1.1631\n",
      " cross_entropy: 0.0211689, clust_cross_entropy: 0.0219478, affinity: 0.00138251, balance: 0.0645524, coact: 0.00567304, frob: 0.000288312\n",
      "step 10100/30000 \n",
      " Train: accuracy: 1, loss: 0.0553296 \n",
      " Validation: accuracy: 0.953125 loss: 0.661087\n",
      " cross_entropy: 0.0140493, clust_cross_entropy: 0.0164804, affinity: 0.001705, balance: 0.0357764, coact: 0.0171075, frob: 0.000298734\n",
      "step 10200/30000 \n",
      " Train: accuracy: 1, loss: 0.0963406 \n",
      " Validation: accuracy: 0.960938 loss: 0.752992\n",
      " cross_entropy: 0.0120772, clust_cross_entropy: 0.0126254, affinity: 0.000683745, balance: 0.0265342, coact: 0.00345142, frob: 0.000284013\n",
      "step 10300/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.127272 \n",
      " Validation: accuracy: 0.914062 loss: 0.924885\n",
      " cross_entropy: 0.00994897, clust_cross_entropy: 0.0113938, affinity: 0, balance: 0.108843, coact: 0.0154966, frob: 0.000293724\n",
      "step 10400/30000 \n",
      " Train: accuracy: 1, loss: 0.182272 \n",
      " Validation: accuracy: 0.9375 loss: 0.726887\n",
      " cross_entropy: 0.023357, clust_cross_entropy: 0.00977037, affinity: 0.000255375, balance: 0.149949, coact: 0.0187652, frob: 0.000287174\n",
      "step 10500/30000 \n",
      " Train: accuracy: 1, loss: 0.136926 \n",
      " Validation: accuracy: 0.96875 loss: 0.624371\n",
      " cross_entropy: 0.00579323, clust_cross_entropy: 0.00969804, affinity: 0.000823981, balance: 0.100724, coact: 0.0170405, frob: 0.000293309\n",
      "step 10600/30000 \n",
      " Train: accuracy: 1, loss: 0.0902207 \n",
      " Validation: accuracy: 0.9375 loss: 0.934174\n",
      " cross_entropy: 0.0218966, clust_cross_entropy: 0.0113752, affinity: 0.000372214, balance: 0.0843956, coact: 0.00848928, frob: 0.00029074\n",
      "step 10700/30000 \n",
      " Train: accuracy: 1, loss: 0.109821 \n",
      " Validation: accuracy: 0.914062 loss: 0.701715\n",
      " cross_entropy: 0.0114913, clust_cross_entropy: 0.00590759, affinity: 0.00117821, balance: 0.0546177, coact: 0.0112052, frob: 0.000291178\n",
      "step 10800/30000 \n",
      " Train: accuracy: 1, loss: 0.0918558 \n",
      " Validation: accuracy: 0.960938 loss: 0.777326\n",
      " cross_entropy: 0.00959606, clust_cross_entropy: 0.0113786, affinity: 0.00112373, balance: 0.0430863, coact: 0.00854089, frob: 0.000297521\n",
      "step 10900/30000 \n",
      " Train: accuracy: 1, loss: 0.143136 \n",
      " Validation: accuracy: 0.9375 loss: 0.761721\n",
      " cross_entropy: 0.00944347, clust_cross_entropy: 0.00821625, affinity: 0.00245108, balance: 0.0683354, coact: 0.00639999, frob: 0.000293927\n",
      "step 11000/30000 \n",
      " Train: accuracy: 1, loss: 0.131509 \n",
      " Validation: accuracy: 0.9375 loss: 0.864771\n",
      " cross_entropy: 0.0153908, clust_cross_entropy: 0.00799077, affinity: 0.000637958, balance: 0.0823977, coact: 0, frob: 0.000307196\n",
      "step 11100/30000 \n",
      " Train: accuracy: 1, loss: 0.0709947 \n",
      " Validation: accuracy: 0.90625 loss: 0.714348\n",
      " cross_entropy: 0.0060532, clust_cross_entropy: 0.00561731, affinity: 0.00102561, balance: 0.0649318, coact: 0, frob: 0.000301274\n",
      "step 11200/30000 \n",
      " Train: accuracy: 1, loss: 0.107091 \n",
      " Validation: accuracy: 0.90625 loss: 0.923667\n",
      " cross_entropy: 0.017589, clust_cross_entropy: 0.0134158, affinity: 2.8269e-05, balance: 0.0419756, coact: 0.0074416, frob: 0.00029832\n",
      "step 11300/30000 \n",
      " Train: accuracy: 1, loss: 0.146858 \n",
      " Validation: accuracy: 0.945312 loss: 0.875824\n",
      " cross_entropy: 0.00914069, clust_cross_entropy: 0.0159171, affinity: 0.00014619, balance: 0.0714483, coact: 0.0103119, frob: 0.000298541\n",
      "step 11400/30000 \n",
      " Train: accuracy: 1, loss: 0.201187 \n",
      " Validation: accuracy: 0.96875 loss: 0.784829\n",
      " cross_entropy: 0.0071984, clust_cross_entropy: 0.0104761, affinity: 0.00081128, balance: 0.096758, coact: 0.0221228, frob: 0.000290407\n",
      "step 11500/30000 \n",
      " Train: accuracy: 1, loss: 0.10778 \n",
      " Validation: accuracy: 0.960938 loss: 0.551635\n",
      " cross_entropy: 0.00587086, clust_cross_entropy: 0.0135567, affinity: 0.00167565, balance: 0.0831616, coact: 0.00500596, frob: 0.000297306\n",
      "step 11600/30000 \n",
      " Train: accuracy: 1, loss: 0.0521927 \n",
      " Validation: accuracy: 0.9375 loss: 0.659691\n",
      " cross_entropy: 0.00985659, clust_cross_entropy: 0.00915369, affinity: 0.000286641, balance: 0.0416819, coact: 0.012693, frob: 0.000300538\n",
      "step 11700/30000 \n",
      " Train: accuracy: 1, loss: 0.091157 \n",
      " Validation: accuracy: 0.945312 loss: 0.82263\n",
      " cross_entropy: 0.00853965, clust_cross_entropy: 0.00967909, affinity: 9.99639e-05, balance: 0.0617477, coact: 0.015568, frob: 0.000300845\n",
      "step 11800/30000 \n",
      " Train: accuracy: 0.984375, loss: 0.154605 \n",
      " Validation: accuracy: 0.945312 loss: 0.907084\n",
      " cross_entropy: 0.0082435, clust_cross_entropy: 0.0127686, affinity: 0.000335192, balance: 0.0629697, coact: 0.0015682, frob: 0.000307067\n",
      "step 11900/30000 \n",
      " Train: accuracy: 1, loss: 0.0853796 \n",
      " Validation: accuracy: 0.90625 loss: 1.0198\n",
      " cross_entropy: 0.0226163, clust_cross_entropy: 0.00850243, affinity: 0.00116538, balance: 0.081135, coact: 0, frob: 0.00029863\n",
      "step 12000/30000 \n",
      " Train: accuracy: 1, loss: 0.117392 \n",
      " Validation: accuracy: 0.953125 loss: 0.986207\n",
      " cross_entropy: 0.00829123, clust_cross_entropy: 0.0035881, affinity: 0.00101563, balance: 0.10643, coact: 0.0131618, frob: 0.000299778\n",
      "step 12100/30000 \n",
      " Train: accuracy: 1, loss: 0.159711 \n",
      " Validation: accuracy: 0.9375 loss: 0.86671\n",
      " cross_entropy: 0.0108861, clust_cross_entropy: 0.00976359, affinity: 0.00098092, balance: 0.0867251, coact: 0.000800819, frob: 0.000300476\n",
      "step 12200/30000 \n",
      " Train: accuracy: 1, loss: 0.214023 \n",
      " Validation: accuracy: 0.914062 loss: 1.19654\n",
      " cross_entropy: 0.00911469, clust_cross_entropy: 0.0129283, affinity: 0.000139462, balance: 0.171613, coact: 0, frob: 0.000300143\n",
      "step 12300/30000 \n",
      " Train: accuracy: 1, loss: 0.0470801 \n",
      " Validation: accuracy: 0.960938 loss: 0.610768\n",
      " cross_entropy: 0.00694914, clust_cross_entropy: 0.00705136, affinity: 0.00146624, balance: 0.0386816, coact: 0.0155958, frob: 0.000303427\n",
      "step 12400/30000 \n",
      " Train: accuracy: 1, loss: 0.0829717 \n",
      " Validation: accuracy: 0.9375 loss: 0.724845\n",
      " cross_entropy: 0.00300083, clust_cross_entropy: 0.00515131, affinity: 5.11848e-05, balance: 0.0660339, coact: 0.00395313, frob: 0.000320106\n",
      "step 12500/30000 \n",
      " Train: accuracy: 1, loss: 0.0542873 \n",
      " Validation: accuracy: 0.898438 loss: 1.13362\n",
      " cross_entropy: 0.00970129, clust_cross_entropy: 0.00554018, affinity: 0.000804132, balance: 0.0312804, coact: 0.00675874, frob: 0.000306095\n",
      "step 12600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.0560789 \n",
      " Validation: accuracy: 0.929688 loss: 0.95398\n",
      " cross_entropy: 0.00578516, clust_cross_entropy: 0.0040021, affinity: 0.000303517, balance: 0.0403818, coact: 0.00567563, frob: 0.000303356\n",
      "step 12700/30000 \n",
      " Train: accuracy: 1, loss: 0.11464 \n",
      " Validation: accuracy: 0.9375 loss: 0.756967\n",
      " cross_entropy: 0.0146214, clust_cross_entropy: 0.00280582, affinity: 0.000730601, balance: 0.0780901, coact: 0.0072189, frob: 0.000307961\n",
      "step 12800/30000 \n",
      " Train: accuracy: 1, loss: 0.0769775 \n",
      " Validation: accuracy: 0.929688 loss: 0.84872\n",
      " cross_entropy: 0.00644858, clust_cross_entropy: 0.00526337, affinity: 0.000554291, balance: 0.0949133, coact: 0.0109813, frob: 0.000309078\n",
      "step 12900/30000 \n",
      " Train: accuracy: 1, loss: 0.127058 \n",
      " Validation: accuracy: 0.9375 loss: 0.946846\n",
      " cross_entropy: 0.002402, clust_cross_entropy: 0.00905738, affinity: 0.0017876, balance: 0.0407827, coact: 0.00233632, frob: 0.000322164\n",
      "step 13000/30000 \n",
      " Train: accuracy: 1, loss: 0.15518 \n",
      " Validation: accuracy: 0.898438 loss: 0.931064\n",
      " cross_entropy: 0.00873184, clust_cross_entropy: 0.0128749, affinity: 1.22334e-05, balance: 0.0965971, coact: 0.00477164, frob: 0.000317449\n",
      "step 13100/30000 \n",
      " Train: accuracy: 1, loss: 0.095884 \n",
      " Validation: accuracy: 0.921875 loss: 1.13551\n",
      " cross_entropy: 0.00905707, clust_cross_entropy: 0.0136515, affinity: 3.67263e-05, balance: 0.0555852, coact: 0.000206095, frob: 0.000308785\n",
      "step 13200/30000 \n",
      " Train: accuracy: 1, loss: 0.140283 \n",
      " Validation: accuracy: 0.914062 loss: 1.06501\n",
      " cross_entropy: 0.00995314, clust_cross_entropy: 0.00695457, affinity: 0.000450472, balance: 0.108241, coact: 0.00619697, frob: 0.000307396\n",
      "step 13300/30000 \n",
      " Train: accuracy: 1, loss: 0.0927747 \n",
      " Validation: accuracy: 0.960938 loss: 0.629295\n",
      " cross_entropy: 0.00225792, clust_cross_entropy: 0.00555308, affinity: 0.00129409, balance: 0.0731647, coact: 0.00382541, frob: 0.000305299\n",
      "step 13400/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.145638 \n",
      " Validation: accuracy: 0.976562 loss: 0.86232\n",
      " cross_entropy: 0.00665366, clust_cross_entropy: 0.00246378, affinity: 0.000406965, balance: 0.0764004, coact: 0.00603895, frob: 0.000313412\n",
      "step 13500/30000 \n",
      " Train: accuracy: 1, loss: 0.0790827 \n",
      " Validation: accuracy: 0.953125 loss: 0.44626\n",
      " cross_entropy: 0.00972421, clust_cross_entropy: 0.0129331, affinity: 0.00140184, balance: 0.0593438, coact: 0.00238703, frob: 0.000303128\n",
      "step 13600/30000 \n",
      " Train: accuracy: 1, loss: 0.0689109 \n",
      " Validation: accuracy: 0.898438 loss: 1.03088\n",
      " cross_entropy: 0.0147078, clust_cross_entropy: 0.00284841, affinity: 0.000983565, balance: 0.0628141, coact: 0.00639224, frob: 0.000306973\n",
      "step 13700/30000 \n",
      " Train: accuracy: 1, loss: 0.189485 \n",
      " Validation: accuracy: 0.960938 loss: 0.614354\n",
      " cross_entropy: 0.00197925, clust_cross_entropy: 0.00500887, affinity: 0.000251942, balance: 0.14384, coact: 0.0010074, frob: 0.000299949\n",
      "step 13800/30000 \n",
      " Train: accuracy: 1, loss: 0.111736 \n",
      " Validation: accuracy: 0.914062 loss: 0.937211\n",
      " cross_entropy: 0.00210674, clust_cross_entropy: 0.00623601, affinity: 0.000563299, balance: 0.0658721, coact: 0.0083077, frob: 0.000312772\n",
      "step 13900/30000 \n",
      " Train: accuracy: 1, loss: 0.0696187 \n",
      " Validation: accuracy: 0.921875 loss: 0.995806\n",
      " cross_entropy: 0.00921497, clust_cross_entropy: 0.00330877, affinity: 0.00138641, balance: 0.0430516, coact: 0.00311582, frob: 0.000305703\n",
      "step 14000/30000 \n",
      " Train: accuracy: 1, loss: 0.0738172 \n",
      " Validation: accuracy: 0.960938 loss: 0.70293\n",
      " cross_entropy: 0.0043779, clust_cross_entropy: 0.00651634, affinity: 3.56764e-05, balance: 0.0416301, coact: 0.0020286, frob: 0.000309136\n",
      "step 14100/30000 \n",
      " Train: accuracy: 1, loss: 0.0903445 \n",
      " Validation: accuracy: 0.929688 loss: 0.942219\n",
      " cross_entropy: 0.00276542, clust_cross_entropy: 0.0120458, affinity: 0.000170982, balance: 0.0960565, coact: 0.00592535, frob: 0.000313167\n",
      "step 14200/30000 \n",
      " Train: accuracy: 1, loss: 0.102035 \n",
      " Validation: accuracy: 0.921875 loss: 0.681483\n",
      " cross_entropy: 0.00353085, clust_cross_entropy: 0.00671755, affinity: 7.20596e-05, balance: 0.0527493, coact: 0.0155507, frob: 0.000311774\n",
      "step 14300/30000 \n",
      " Train: accuracy: 1, loss: 0.0498562 \n",
      " Validation: accuracy: 0.984375 loss: 0.509628\n",
      " cross_entropy: 0.011804, clust_cross_entropy: 0.00528131, affinity: 0.000182348, balance: 0.0270939, coact: 0.00678652, frob: 0.000296202\n",
      "step 14400/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.0555512 \n",
      " Validation: accuracy: 0.921875 loss: 0.813297\n",
      " cross_entropy: 0.00400357, clust_cross_entropy: 0.00316626, affinity: 0.00126229, balance: 0.0502676, coact: 0.00333698, frob: 0.000311195\n",
      "step 14500/30000 \n",
      " Train: accuracy: 1, loss: 0.0518724 \n",
      " Validation: accuracy: 0.929688 loss: 1.04206\n",
      " cross_entropy: 0.0117859, clust_cross_entropy: 0.00393996, affinity: 4.09801e-05, balance: 0.0532877, coact: 0.0024623, frob: 0.000308553\n",
      "step 14600/30000 \n",
      " Train: accuracy: 1, loss: 0.0769119 \n",
      " Validation: accuracy: 0.929688 loss: 0.889058\n",
      " cross_entropy: 0.003878, clust_cross_entropy: 0.00532777, affinity: 0.000598782, balance: 0.0498791, coact: 0, frob: 0.000312659\n",
      "step 14700/30000 \n",
      " Train: accuracy: 1, loss: 0.0661097 \n",
      " Validation: accuracy: 0.9375 loss: 1.02467\n",
      " cross_entropy: 0.00262422, clust_cross_entropy: 0.00445104, affinity: 3.11629e-05, balance: 0.0633017, coact: 0, frob: 0.000318848\n",
      "step 14800/30000 \n",
      " Train: accuracy: 1, loss: 0.087962 \n",
      " Validation: accuracy: 0.921875 loss: 0.688325\n",
      " cross_entropy: 0.00940526, clust_cross_entropy: 0.00401802, affinity: 0.000172639, balance: 0.0651186, coact: 0.012374, frob: 0.00030692\n",
      "step 14900/30000 \n",
      " Train: accuracy: 1, loss: 0.0794528 \n",
      " Validation: accuracy: 0.960938 loss: 0.625299\n",
      " cross_entropy: 0.00191911, clust_cross_entropy: 0.00388665, affinity: 0.000965917, balance: 0.0786732, coact: 0, frob: 0.000316659\n",
      "step 15000/30000 \n",
      " Train: accuracy: 1, loss: 0.101754 \n",
      " Validation: accuracy: 0.96875 loss: 0.522037\n",
      " cross_entropy: 0.00781506, clust_cross_entropy: 0.00144114, affinity: 0.000145886, balance: 0.0807782, coact: 0.0011816, frob: 0.000310597\n",
      "step 15100/30000 \n",
      " Train: accuracy: 1, loss: 0.0902193 \n",
      " Validation: accuracy: 0.929688 loss: 0.839406\n",
      " cross_entropy: 0.00247388, clust_cross_entropy: 0.00262469, affinity: 0.000521008, balance: 0.0416138, coact: 0.0181249, frob: 0.00031875\n",
      "step 15200/30000 \n",
      " Train: accuracy: 1, loss: 0.0688752 \n",
      " Validation: accuracy: 0.945312 loss: 0.756195\n",
      " cross_entropy: 0.0123149, clust_cross_entropy: 0.00601961, affinity: 0.000307954, balance: 0.0774927, coact: 0.00244915, frob: 0.000318286\n",
      "step 15300/30000 \n",
      " Train: accuracy: 1, loss: 0.0756779 \n",
      " Validation: accuracy: 0.945312 loss: 0.563767\n",
      " cross_entropy: 0.00425698, clust_cross_entropy: 0.00533731, affinity: 0.000359203, balance: 0.098404, coact: 0.0133449, frob: 0.00031218\n",
      "step 15400/30000 \n",
      " Train: accuracy: 1, loss: 0.111793 \n",
      " Validation: accuracy: 0.929688 loss: 0.685198\n",
      " cross_entropy: 0.00775729, clust_cross_entropy: 0.00324397, affinity: 0.000168643, balance: 0.10032, coact: 0.00892097, frob: 0.000318196\n",
      "step 15500/30000 \n",
      " Train: accuracy: 1, loss: 0.103523 \n",
      " Validation: accuracy: 0.898438 loss: 1.23913\n",
      " cross_entropy: 0.0034242, clust_cross_entropy: 0.00578429, affinity: 0.000201305, balance: 0.0636454, coact: 0.00554084, frob: 0.000314444\n",
      "step 15600/30000 \n",
      " Train: accuracy: 1, loss: 0.101813 \n",
      " Validation: accuracy: 0.945312 loss: 0.796447\n",
      " cross_entropy: 0.00322473, clust_cross_entropy: 0.00295948, affinity: 0.000875391, balance: 0.0590949, coact: 0.0101432, frob: 0.00031513\n",
      "step 15700/30000 \n",
      " Train: accuracy: 1, loss: 0.0702934 \n",
      " Validation: accuracy: 0.945312 loss: 0.79421\n",
      " cross_entropy: 0.00271627, clust_cross_entropy: 0.00519292, affinity: 0.000580233, balance: 0.0571935, coact: 0, frob: 0.000322241\n",
      "step 15800/30000 \n",
      " Train: accuracy: 1, loss: 0.0531417 \n",
      " Validation: accuracy: 0.929688 loss: 1.00843\n",
      " cross_entropy: 0.00169375, clust_cross_entropy: 0.002413, affinity: 9.63734e-05, balance: 0.0706666, coact: 0.0088678, frob: 0.000321226\n",
      "step 15900/30000 \n",
      " Train: accuracy: 1, loss: 0.0515629 \n",
      " Validation: accuracy: 0.945312 loss: 0.809703\n",
      " cross_entropy: 0.00302632, clust_cross_entropy: 0.00370763, affinity: 0.000307611, balance: 0.0535887, coact: 0.00578359, frob: 0.000317183\n",
      "step 16000/30000 \n",
      " Train: accuracy: 1, loss: 0.036742 \n",
      " Validation: accuracy: 0.9375 loss: 0.899219\n",
      " cross_entropy: 0.0019693, clust_cross_entropy: 0.00334247, affinity: 0.000261784, balance: 0.0135918, coact: 0, frob: 0.000316207\n",
      "step 16100/30000 \n",
      " Train: accuracy: 1, loss: 0.0788331 \n",
      " Validation: accuracy: 0.945312 loss: 0.584287\n",
      " cross_entropy: 0.0069735, clust_cross_entropy: 0.00546292, affinity: 0.00108653, balance: 0.053277, coact: 0.00724019, frob: 0.000313878\n",
      "step 16200/30000 \n",
      " Train: accuracy: 1, loss: 0.0907539 \n",
      " Validation: accuracy: 0.953125 loss: 0.610555\n",
      " cross_entropy: 0.0066599, clust_cross_entropy: 0.00192428, affinity: 0.000856721, balance: 0.0802509, coact: 0.00922237, frob: 0.000320615\n",
      "step 16300/30000 \n",
      " Train: accuracy: 1, loss: 0.0723744 \n",
      " Validation: accuracy: 0.90625 loss: 1.05651\n",
      " cross_entropy: 0.00385677, clust_cross_entropy: 0.00983015, affinity: 6.59727e-05, balance: 0.0810482, coact: 0.00761543, frob: 0.00032201\n",
      "step 16400/30000 \n",
      " Train: accuracy: 1, loss: 0.16186 \n",
      " Validation: accuracy: 0.929688 loss: 0.726435\n",
      " cross_entropy: 0.00318777, clust_cross_entropy: 0.00418038, affinity: 0.00178231, balance: 0.150167, coact: 0.000919193, frob: 0.000316171\n",
      "step 16500/30000 \n",
      " Train: accuracy: 1, loss: 0.0589852 \n",
      " Validation: accuracy: 0.929688 loss: 0.893783\n",
      " cross_entropy: 0.00457738, clust_cross_entropy: 0.00252476, affinity: 6.24949e-05, balance: 0.0561161, coact: 0.00620018, frob: 0.000332979\n",
      "step 16600/30000 \n",
      " Train: accuracy: 1, loss: 0.0909845 \n",
      " Validation: accuracy: 0.890625 loss: 1.38673\n",
      " cross_entropy: 0.00720484, clust_cross_entropy: 0.00239478, affinity: 0.000172423, balance: 0.0471175, coact: 0.00518507, frob: 0.000320502\n",
      "step 16700/30000 \n",
      " Train: accuracy: 1, loss: 0.101165 \n",
      " Validation: accuracy: 0.945312 loss: 0.825196\n",
      " cross_entropy: 0.00251921, clust_cross_entropy: 0.0054935, affinity: 0.000389349, balance: 0.0833794, coact: 0, frob: 0.00031601\n",
      "step 16800/30000 \n",
      " Train: accuracy: 1, loss: 0.0609376 \n",
      " Validation: accuracy: 0.929688 loss: 0.794736\n",
      " cross_entropy: 0.00164572, clust_cross_entropy: 0.0013862, affinity: 0, balance: 0.0885335, coact: 0.00188147, frob: 0.000309393\n",
      "step 16900/30000 \n",
      " Train: accuracy: 1, loss: 0.0700623 \n",
      " Validation: accuracy: 0.929688 loss: 0.806381\n",
      " cross_entropy: 0.00171216, clust_cross_entropy: 0.00313118, affinity: 3.98295e-05, balance: 0.0652087, coact: 0.00250742, frob: 0.00032609\n",
      "step 17000/30000 \n",
      " Train: accuracy: 1, loss: 0.11953 \n",
      " Validation: accuracy: 0.9375 loss: 0.940117\n",
      " cross_entropy: 0.00580185, clust_cross_entropy: 0.00905358, affinity: 0.00144035, balance: 0.118906, coact: 0.00373805, frob: 0.00033061\n",
      "step 17100/30000 \n",
      " Train: accuracy: 1, loss: 0.0975187 \n",
      " Validation: accuracy: 0.953125 loss: 0.811242\n",
      " cross_entropy: 0.00224641, clust_cross_entropy: 0.0026861, affinity: 0, balance: 0.0688923, coact: 0.000496899, frob: 0.000321288\n",
      "step 17200/30000 \n",
      " Train: accuracy: 1, loss: 0.0596222 \n",
      " Validation: accuracy: 0.929688 loss: 0.880107\n",
      " cross_entropy: 0.00247695, clust_cross_entropy: 0.0021883, affinity: 0.000100998, balance: 0.0377167, coact: 0.0014724, frob: 0.000326252\n",
      "step 17300/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.106174 \n",
      " Validation: accuracy: 0.921875 loss: 0.745849\n",
      " cross_entropy: 0.00456891, clust_cross_entropy: 0.00357125, affinity: 0.000390506, balance: 0.0741658, coact: 0.00815023, frob: 0.000327142\n",
      "step 17400/30000 \n",
      " Train: accuracy: 1, loss: 0.182227 \n",
      " Validation: accuracy: 0.945312 loss: 0.912067\n",
      " cross_entropy: 0.00726611, clust_cross_entropy: 0.00284621, affinity: 0.000100933, balance: 0.120882, coact: 0.00144136, frob: 0.000309889\n",
      "step 17500/30000 \n",
      " Train: accuracy: 1, loss: 0.0950098 \n",
      " Validation: accuracy: 0.929688 loss: 0.873838\n",
      " cross_entropy: 0.00255481, clust_cross_entropy: 0.00131769, affinity: 9.17813e-05, balance: 0.0838245, coact: 0.00355845, frob: 0.000337781\n",
      "step 17600/30000 \n",
      " Train: accuracy: 1, loss: 0.105408 \n",
      " Validation: accuracy: 0.953125 loss: 0.610272\n",
      " cross_entropy: 0.00278271, clust_cross_entropy: 0.00177143, affinity: 0.000439565, balance: 0.0746456, coact: 7.30419e-05, frob: 0.00032313\n",
      "step 17700/30000 \n",
      " Train: accuracy: 1, loss: 0.0487241 \n",
      " Validation: accuracy: 0.90625 loss: 1.00946\n",
      " cross_entropy: 0.0105129, clust_cross_entropy: 0.00254493, affinity: 0.000491039, balance: 0.0560685, coact: 0.00186051, frob: 0.000316986\n",
      "step 17800/30000 \n",
      " Train: accuracy: 1, loss: 0.0675714 \n",
      " Validation: accuracy: 0.929688 loss: 0.821191\n",
      " cross_entropy: 0.00261877, clust_cross_entropy: 0.00128704, affinity: 0.00030987, balance: 0.0601974, coact: 0, frob: 0.000320544\n",
      "step 17900/30000 \n",
      " Train: accuracy: 1, loss: 0.133443 \n",
      " Validation: accuracy: 0.921875 loss: 0.947339\n",
      " cross_entropy: 0.00220312, clust_cross_entropy: 0.00396226, affinity: 0.000254859, balance: 0.120864, coact: 0, frob: 0.000314408\n",
      "step 18000/30000 \n",
      " Train: accuracy: 1, loss: 0.0782604 \n",
      " Validation: accuracy: 0.9375 loss: 1.10748\n",
      " cross_entropy: 0.0039891, clust_cross_entropy: 0.00278933, affinity: 0.000561157, balance: 0.0557045, coact: 0.00228608, frob: 0.000334356\n",
      "step 18100/30000 \n",
      " Train: accuracy: 1, loss: 0.0596451 \n",
      " Validation: accuracy: 0.90625 loss: 1.06454\n",
      " cross_entropy: 0.0018494, clust_cross_entropy: 0.00197722, affinity: 0, balance: 0.0650945, coact: 0.00607677, frob: 0.000323542\n",
      "step 18200/30000 \n",
      " Train: accuracy: 1, loss: 0.12258 \n",
      " Validation: accuracy: 0.945312 loss: 0.819387\n",
      " cross_entropy: 0.0023026, clust_cross_entropy: 0.00296985, affinity: 0.000878931, balance: 0.114828, coact: 0.000789532, frob: 0.000320101\n",
      "step 18300/30000 \n",
      " Train: accuracy: 1, loss: 0.123932 \n",
      " Validation: accuracy: 0.953125 loss: 1.09564\n",
      " cross_entropy: 0.00192261, clust_cross_entropy: 0.00353636, affinity: 6.69983e-05, balance: 0.104721, coact: 0.000569986, frob: 0.000321054\n",
      "step 18400/30000 \n",
      " Train: accuracy: 1, loss: 0.106833 \n",
      " Validation: accuracy: 0.976562 loss: 0.527832\n",
      " cross_entropy: 0.00645144, clust_cross_entropy: 0.00393581, affinity: 6.99821e-05, balance: 0.0990429, coact: 0.0104893, frob: 0.000326126\n",
      "step 18500/30000 \n",
      " Train: accuracy: 1, loss: 0.0437395 \n",
      " Validation: accuracy: 0.945312 loss: 0.706197\n",
      " cross_entropy: 0.00184059, clust_cross_entropy: 0.00144067, affinity: 7.55207e-05, balance: 0.0335366, coact: 0.00616779, frob: 0.000322209\n",
      "step 18600/30000 \n",
      " Train: accuracy: 1, loss: 0.0801951 \n",
      " Validation: accuracy: 0.921875 loss: 0.74802\n",
      " cross_entropy: 0.00126835, clust_cross_entropy: 0.00211994, affinity: 0, balance: 0.0380129, coact: 0.00156411, frob: 0.000334744\n",
      "step 18700/30000 \n",
      " Train: accuracy: 1, loss: 0.0749846 \n",
      " Validation: accuracy: 0.945312 loss: 0.795946\n",
      " cross_entropy: 0.00189334, clust_cross_entropy: 0.00161186, affinity: 0.00020093, balance: 0.0684386, coact: 0.00442879, frob: 0.000325001\n",
      "step 18800/30000 \n",
      " Train: accuracy: 1, loss: 0.0709046 \n",
      " Validation: accuracy: 0.960938 loss: 0.668642\n",
      " cross_entropy: 0.00644345, clust_cross_entropy: 0.00346587, affinity: 0, balance: 0.0870267, coact: 0.00452675, frob: 0.000314142\n",
      "step 18900/30000 \n",
      " Train: accuracy: 1, loss: 0.121273 \n",
      " Validation: accuracy: 0.890625 loss: 0.912011\n",
      " cross_entropy: 0.00238208, clust_cross_entropy: 0.00144896, affinity: 0, balance: 0.136678, coact: 0.00593535, frob: 0.000329803\n",
      "step 19000/30000 \n",
      " Train: accuracy: 1, loss: 0.112934 \n",
      " Validation: accuracy: 0.9375 loss: 0.86443\n",
      " cross_entropy: 0.00212742, clust_cross_entropy: 0.00112455, affinity: 0.00024016, balance: 0.057247, coact: 0.00848832, frob: 0.00032177\n",
      "step 19100/30000 \n",
      " Train: accuracy: 1, loss: 0.0760502 \n",
      " Validation: accuracy: 0.9375 loss: 0.954237\n",
      " cross_entropy: 0.00174415, clust_cross_entropy: 0.00185719, affinity: 0, balance: 0.0385591, coact: 0, frob: 0.000315897\n",
      "step 19200/30000 \n",
      " Train: accuracy: 1, loss: 0.0880232 \n",
      " Validation: accuracy: 0.929688 loss: 0.736686\n",
      " cross_entropy: 0.00221486, clust_cross_entropy: 0.00165092, affinity: 0.00046417, balance: 0.0376722, coact: 0, frob: 0.000321697\n",
      "step 19300/30000 \n",
      " Train: accuracy: 1, loss: 0.0343022 \n",
      " Validation: accuracy: 0.9375 loss: 0.894882\n",
      " cross_entropy: 0.00166055, clust_cross_entropy: 0.00180268, affinity: 0, balance: 0.0488045, coact: 0.000113515, frob: 0.000316735\n",
      "step 19400/30000 \n",
      " Train: accuracy: 1, loss: 0.119357 \n",
      " Validation: accuracy: 0.929688 loss: 0.743077\n",
      " cross_entropy: 0.0020637, clust_cross_entropy: 0.00285023, affinity: 0.000203343, balance: 0.0879151, coact: 0.00353587, frob: 0.000339095\n",
      "step 19500/30000 \n",
      " Train: accuracy: 1, loss: 0.048634 \n",
      " Validation: accuracy: 0.953125 loss: 0.749614\n",
      " cross_entropy: 0.00278491, clust_cross_entropy: 0.00130072, affinity: 8.15704e-06, balance: 0.0441136, coact: 0.000489878, frob: 0.000323058\n",
      "step 19600/30000 \n",
      " Train: accuracy: 1, loss: 0.0406262 \n",
      " Validation: accuracy: 0.945312 loss: 0.936772\n",
      " cross_entropy: 0.000865557, clust_cross_entropy: 0.00193183, affinity: 0.000246821, balance: 0.0563748, coact: 0.00351036, frob: 0.000325952\n",
      "step 19700/30000 \n",
      " Train: accuracy: 1, loss: 0.0929422 \n",
      " Validation: accuracy: 0.921875 loss: 1.0063\n",
      " cross_entropy: 0.00116297, clust_cross_entropy: 0.00181776, affinity: 0.000651911, balance: 0.113936, coact: 0, frob: 0.00032873\n",
      "step 19800/30000 \n",
      " Train: accuracy: 1, loss: 0.0961672 \n",
      " Validation: accuracy: 0.898438 loss: 0.869718\n",
      " cross_entropy: 0.00278698, clust_cross_entropy: 0.00108675, affinity: 0.000315358, balance: 0.0990511, coact: 0, frob: 0.000338389\n",
      "step 19900/30000 \n",
      " Train: accuracy: 1, loss: 0.0549191 \n",
      " Validation: accuracy: 0.929688 loss: 0.710168\n",
      " cross_entropy: 0.00342397, clust_cross_entropy: 0.00533881, affinity: 0.000964257, balance: 0.037436, coact: 0, frob: 0.000317602\n",
      "step 20000/30000 \n",
      " Train: accuracy: 1, loss: 0.0553889 \n",
      " Validation: accuracy: 0.945312 loss: 0.990648\n",
      " cross_entropy: 0.00155796, clust_cross_entropy: 0.00125999, affinity: 0, balance: 0.0516234, coact: 0.00347815, frob: 0.000331237\n",
      "step 20100/30000 \n",
      " Train: accuracy: 1, loss: 0.146033 \n",
      " Validation: accuracy: 0.945312 loss: 0.891486\n",
      " cross_entropy: 0.00283543, clust_cross_entropy: 0.00440501, affinity: 0.000213469, balance: 0.116593, coact: 0, frob: 0.000328659\n",
      "step 20200/30000 \n",
      " Train: accuracy: 1, loss: 0.0950541 \n",
      " Validation: accuracy: 0.945312 loss: 0.77556\n",
      " cross_entropy: 0.00444388, clust_cross_entropy: 0.00262791, affinity: 0.000593388, balance: 0.0784688, coact: 0.00504164, frob: 0.000332068\n",
      "step 20300/30000 \n",
      " Train: accuracy: 1, loss: 0.070724 \n",
      " Validation: accuracy: 0.929688 loss: 1.02847\n",
      " cross_entropy: 0.00370903, clust_cross_entropy: 0.00312798, affinity: 3.7236e-05, balance: 0.047266, coact: 0.000300974, frob: 0.000326839\n",
      "step 20400/30000 \n",
      " Train: accuracy: 1, loss: 0.055003 \n",
      " Validation: accuracy: 0.9375 loss: 1.06573\n",
      " cross_entropy: 0.00122145, clust_cross_entropy: 0.00944368, affinity: 4.49221e-05, balance: 0.039271, coact: 0.000993449, frob: 0.000316879\n",
      "step 20500/30000 \n",
      " Train: accuracy: 1, loss: 0.0562899 \n",
      " Validation: accuracy: 0.898438 loss: 1.37046\n",
      " cross_entropy: 0.00146576, clust_cross_entropy: 0.00179237, affinity: 0, balance: 0.0636367, coact: 0.00367612, frob: 0.000327038\n",
      "step 20600/30000 \n",
      " Train: accuracy: 1, loss: 0.0748198 \n",
      " Validation: accuracy: 0.9375 loss: 0.662274\n",
      " cross_entropy: 0.00134332, clust_cross_entropy: 0.00149793, affinity: 0, balance: 0.0578956, coact: 0.00109567, frob: 0.000321598\n",
      "step 20700/30000 \n",
      " Train: accuracy: 1, loss: 0.0928631 \n",
      " Validation: accuracy: 0.953125 loss: 0.826059\n",
      " cross_entropy: 0.00387735, clust_cross_entropy: 0.00243905, affinity: 1.59471e-07, balance: 0.0823957, coact: 0.00207397, frob: 0.000318925\n",
      "step 20800/30000 \n",
      " Train: accuracy: 1, loss: 0.0280068 \n",
      " Validation: accuracy: 0.929688 loss: 1.18351\n",
      " cross_entropy: 0.00135713, clust_cross_entropy: 0.00512327, affinity: 0.000102549, balance: 0.0207795, coact: 0.00785975, frob: 0.000338694\n",
      "step 20900/30000 \n",
      " Train: accuracy: 1, loss: 0.0531515 \n",
      " Validation: accuracy: 0.890625 loss: 1.01774\n",
      " cross_entropy: 0.00162859, clust_cross_entropy: 0.00124585, affinity: 0, balance: 0.0183539, coact: 0, frob: 0.000333785\n",
      "step 21000/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.0705134 \n",
      " Validation: accuracy: 0.96875 loss: 0.421152\n",
      " cross_entropy: 0.000689642, clust_cross_entropy: 0.00318399, affinity: 0.000112258, balance: 0.049027, coact: 0.00178476, frob: 0.000328786\n",
      "step 21100/30000 \n",
      " Train: accuracy: 1, loss: 0.0797527 \n",
      " Validation: accuracy: 0.953125 loss: 0.601601\n",
      " cross_entropy: 0.00122163, clust_cross_entropy: 0.00101047, affinity: 0.00071808, balance: 0.0787659, coact: 0.00319808, frob: 0.000315272\n",
      "step 21200/30000 \n",
      " Train: accuracy: 1, loss: 0.162985 \n",
      " Validation: accuracy: 0.945312 loss: 0.800171\n",
      " cross_entropy: 0.00112022, clust_cross_entropy: 0.00142021, affinity: 0.000157743, balance: 0.120808, coact: 0, frob: 0.000321837\n",
      "step 21300/30000 \n",
      " Train: accuracy: 1, loss: 0.0955387 \n",
      " Validation: accuracy: 0.945312 loss: 0.652654\n",
      " cross_entropy: 0.0019602, clust_cross_entropy: 0.00101868, affinity: 0, balance: 0.106222, coact: 0, frob: 0.000330417\n",
      "step 21400/30000 \n",
      " Train: accuracy: 1, loss: 0.0701125 \n",
      " Validation: accuracy: 0.953125 loss: 1.20246\n",
      " cross_entropy: 0.00100771, clust_cross_entropy: 0.00199874, affinity: 0.00107865, balance: 0.0524628, coact: 0.000229984, frob: 0.000329954\n",
      "step 21500/30000 \n",
      " Train: accuracy: 1, loss: 0.0349702 \n",
      " Validation: accuracy: 0.953125 loss: 0.543986\n",
      " cross_entropy: 0.00113311, clust_cross_entropy: 0.000753968, affinity: 2.40541e-05, balance: 0.0355607, coact: 0, frob: 0.000325285\n",
      "step 21600/30000 \n",
      " Train: accuracy: 1, loss: 0.0390401 \n",
      " Validation: accuracy: 0.96875 loss: 0.813206\n",
      " cross_entropy: 0.00122097, clust_cross_entropy: 0.00116279, affinity: 1.37094e-05, balance: 0.0388708, coact: 0.00214055, frob: 0.000323002\n",
      "step 21700/30000 \n",
      " Train: accuracy: 1, loss: 0.111753 \n",
      " Validation: accuracy: 0.9375 loss: 0.802652\n",
      " cross_entropy: 0.00154697, clust_cross_entropy: 0.0059075, affinity: 0, balance: 0.0465804, coact: 0.000216188, frob: 0.000338935\n",
      "step 21800/30000 \n",
      " Train: accuracy: 1, loss: 0.0898873 \n",
      " Validation: accuracy: 0.960938 loss: 0.951909\n",
      " cross_entropy: 0.000737024, clust_cross_entropy: 0.00170494, affinity: 0.000279646, balance: 0.0608414, coact: 0, frob: 0.000331842\n",
      "step 21900/30000 \n",
      " Train: accuracy: 1, loss: 0.100585 \n",
      " Validation: accuracy: 0.953125 loss: 0.692213\n",
      " cross_entropy: 0.00647335, clust_cross_entropy: 0.00121808, affinity: 0, balance: 0.0944577, coact: 0, frob: 0.00032595\n",
      "step 22000/30000 \n",
      " Train: accuracy: 1, loss: 0.0519058 \n",
      " Validation: accuracy: 0.9375 loss: 0.784656\n",
      " cross_entropy: 0.000609675, clust_cross_entropy: 0.00129705, affinity: 7.94308e-05, balance: 0.0170574, coact: 0, frob: 0.000329859\n",
      "step 22100/30000 \n",
      " Train: accuracy: 1, loss: 0.0811773 \n",
      " Validation: accuracy: 0.976562 loss: 0.707375\n",
      " cross_entropy: 0.00138454, clust_cross_entropy: 0.00103864, affinity: 0.000442451, balance: 0.0665978, coact: 0.00119634, frob: 0.000339628\n",
      "step 22200/30000 \n",
      " Train: accuracy: 1, loss: 0.0897981 \n",
      " Validation: accuracy: 0.9375 loss: 0.924367\n",
      " cross_entropy: 0.00178067, clust_cross_entropy: 0.00094208, affinity: 0.000225315, balance: 0.0576631, coact: 0.00125519, frob: 0.000327779\n",
      "step 22300/30000 \n",
      " Train: accuracy: 1, loss: 0.0707742 \n",
      " Validation: accuracy: 0.929688 loss: 0.835918\n",
      " cross_entropy: 0.000883972, clust_cross_entropy: 0.00130606, affinity: 1.06999e-06, balance: 0.0561126, coact: 0, frob: 0.00031227\n",
      "step 22400/30000 \n",
      " Train: accuracy: 1, loss: 0.1314 \n",
      " Validation: accuracy: 0.90625 loss: 1.13469\n",
      " cross_entropy: 0.00599069, clust_cross_entropy: 0.00244472, affinity: 0.000444133, balance: 0.0843107, coact: 0.0104758, frob: 0.000327913\n",
      "step 22500/30000 \n",
      " Train: accuracy: 1, loss: 0.0471524 \n",
      " Validation: accuracy: 0.9375 loss: 0.860541\n",
      " cross_entropy: 0.00240982, clust_cross_entropy: 0.000852046, affinity: 9.98902e-05, balance: 0.0540164, coact: 0, frob: 0.000329401\n",
      "step 22600/30000 \n",
      " Train: accuracy: 1, loss: 0.086695 \n",
      " Validation: accuracy: 0.945312 loss: 0.503523\n",
      " cross_entropy: 0.00185688, clust_cross_entropy: 0.00154279, affinity: 9.83899e-05, balance: 0.0917585, coact: 0.00279025, frob: 0.000318194\n",
      "step 22700/30000 \n",
      " Train: accuracy: 1, loss: 0.0741007 \n",
      " Validation: accuracy: 0.96875 loss: 0.465495\n",
      " cross_entropy: 0.00115911, clust_cross_entropy: 0.00309497, affinity: 0.000186757, balance: 0.0966759, coact: 0, frob: 0.000329606\n",
      "step 22800/30000 \n",
      " Train: accuracy: 1, loss: 0.052073 \n",
      " Validation: accuracy: 0.921875 loss: 0.641441\n",
      " cross_entropy: 0.000756304, clust_cross_entropy: 0.00131395, affinity: 0.000259628, balance: 0.057449, coact: 0, frob: 0.00033268\n",
      "step 22900/30000 \n",
      " Train: accuracy: 1, loss: 0.0541425 \n",
      " Validation: accuracy: 0.953125 loss: 1.01508\n",
      " cross_entropy: 0.000784616, clust_cross_entropy: 0.00177831, affinity: 0.000357327, balance: 0.0574986, coact: 0.000627397, frob: 0.000332017\n",
      "step 23000/30000 \n",
      " Train: accuracy: 1, loss: 0.0306612 \n",
      " Validation: accuracy: 0.9375 loss: 0.98976\n",
      " cross_entropy: 0.000741156, clust_cross_entropy: 0.00119874, affinity: 0.000669361, balance: 0.0371788, coact: 0.00723964, frob: 0.000338169\n",
      "step 23100/30000 \n",
      " Train: accuracy: 1, loss: 0.0384084 \n",
      " Validation: accuracy: 0.96875 loss: 0.537109\n",
      " cross_entropy: 0.00386444, clust_cross_entropy: 0.000894603, affinity: 0, balance: 0.0233261, coact: 0.00246665, frob: 0.000325771\n",
      "step 23200/30000 \n",
      " Train: accuracy: 1, loss: 0.0516997 \n",
      " Validation: accuracy: 0.945312 loss: 0.674418\n",
      " cross_entropy: 0.00124114, clust_cross_entropy: 0.00156823, affinity: 2.58201e-05, balance: 0.0467278, coact: 0.00214534, frob: 0.000336564\n",
      "step 23300/30000 \n",
      " Train: accuracy: 1, loss: 0.0571593 \n",
      " Validation: accuracy: 0.875 loss: 1.50862\n",
      " cross_entropy: 0.000800768, clust_cross_entropy: 0.00167422, affinity: 0.000131095, balance: 0.0512802, coact: 0.00301309, frob: 0.000326523\n",
      "step 23400/30000 \n",
      " Train: accuracy: 1, loss: 0.0915994 \n",
      " Validation: accuracy: 0.921875 loss: 0.946681\n",
      " cross_entropy: 0.000638387, clust_cross_entropy: 0.000869713, affinity: 2.71181e-05, balance: 0.0815139, coact: 0, frob: 0.000340609\n",
      "step 23500/30000 \n",
      " Train: accuracy: 1, loss: 0.0672531 \n",
      " Validation: accuracy: 0.953125 loss: 0.981631\n",
      " cross_entropy: 0.000952451, clust_cross_entropy: 0.00189772, affinity: 0.000132622, balance: 0.0536502, coact: 0.00215659, frob: 0.000332079\n",
      "step 23600/30000 \n",
      " Train: accuracy: 1, loss: 0.100662 \n",
      " Validation: accuracy: 0.953125 loss: 0.6627\n",
      " cross_entropy: 0.00154527, clust_cross_entropy: 0.00287739, affinity: 0, balance: 0.106848, coact: 0.000128062, frob: 0.000327263\n",
      "step 23700/30000 \n",
      " Train: accuracy: 1, loss: 0.0957241 \n",
      " Validation: accuracy: 0.921875 loss: 0.701174\n",
      " cross_entropy: 0.00107739, clust_cross_entropy: 0.00244045, affinity: 0.000216198, balance: 0.113744, coact: 0.00520506, frob: 0.00032387\n",
      "step 23800/30000 \n",
      " Train: accuracy: 1, loss: 0.0796743 \n",
      " Validation: accuracy: 0.929688 loss: 0.967936\n",
      " cross_entropy: 0.000904714, clust_cross_entropy: 0.0011288, affinity: 0.000122723, balance: 0.0642846, coact: 0.0123822, frob: 0.000329387\n",
      "step 23900/30000 \n",
      " Train: accuracy: 1, loss: 0.0911884 \n",
      " Validation: accuracy: 0.953125 loss: 0.473677\n",
      " cross_entropy: 0.00101936, clust_cross_entropy: 0.00206766, affinity: 0, balance: 0.05342, coact: 0.00572365, frob: 0.000338731\n",
      "step 24000/30000 \n",
      " Train: accuracy: 1, loss: 0.0823348 \n",
      " Validation: accuracy: 0.96875 loss: 0.807821\n",
      " cross_entropy: 0.00104725, clust_cross_entropy: 0.000989923, affinity: 4.037e-06, balance: 0.0741939, coact: 0.00106173, frob: 0.00032614\n",
      "step 24100/30000 \n",
      " Train: accuracy: 1, loss: 0.115732 \n",
      " Validation: accuracy: 0.9375 loss: 0.846802\n",
      " cross_entropy: 0.00258044, clust_cross_entropy: 0.000674421, affinity: 7.93743e-07, balance: 0.102883, coact: 0, frob: 0.000342594\n",
      "step 24200/30000 \n",
      " Train: accuracy: 1, loss: 0.109058 \n",
      " Validation: accuracy: 0.929688 loss: 0.926777\n",
      " cross_entropy: 0.000697235, clust_cross_entropy: 0.00109508, affinity: 3.61222e-05, balance: 0.0812544, coact: 0.0100309, frob: 0.000328908\n",
      "step 24300/30000 \n",
      " Train: accuracy: 1, loss: 0.0798047 \n",
      " Validation: accuracy: 0.9375 loss: 0.691896\n",
      " cross_entropy: 0.00164019, clust_cross_entropy: 0.00129649, affinity: 0.000370553, balance: 0.0500344, coact: 0.000868198, frob: 0.000334323\n",
      "step 24400/30000 \n",
      " Train: accuracy: 1, loss: 0.0751985 \n",
      " Validation: accuracy: 0.96875 loss: 0.671432\n",
      " cross_entropy: 0.00402445, clust_cross_entropy: 0.000966066, affinity: 0, balance: 0.0712733, coact: 0.00162203, frob: 0.00033003\n",
      "step 24500/30000 \n",
      " Train: accuracy: 1, loss: 0.0746789 \n",
      " Validation: accuracy: 0.945312 loss: 1.09367\n",
      " cross_entropy: 0.0011661, clust_cross_entropy: 0.00139649, affinity: 0, balance: 0.0592167, coact: 0.000989721, frob: 0.00032619\n",
      "step 24600/30000 \n",
      " Train: accuracy: 1, loss: 0.0716293 \n",
      " Validation: accuracy: 0.945312 loss: 0.985755\n",
      " cross_entropy: 0.00123262, clust_cross_entropy: 0.000965464, affinity: 9.50671e-05, balance: 0.0748104, coact: 0.000546527, frob: 0.00032753\n",
      "step 24700/30000 \n",
      " Train: accuracy: 1, loss: 0.155632 \n",
      " Validation: accuracy: 0.898438 loss: 1.18462\n",
      " cross_entropy: 0.000815665, clust_cross_entropy: 0.00122996, affinity: 0, balance: 0.0947595, coact: 0, frob: 0.000328257\n",
      "step 24800/30000 \n",
      " Train: accuracy: 1, loss: 0.0667632 \n",
      " Validation: accuracy: 0.890625 loss: 0.929969\n",
      " cross_entropy: 0.00172744, clust_cross_entropy: 0.0021734, affinity: 4.33967e-05, balance: 0.0419254, coact: 0.00746036, frob: 0.000335549\n",
      "step 24900/30000 \n",
      " Train: accuracy: 1, loss: 0.086532 \n",
      " Validation: accuracy: 0.945312 loss: 0.614856\n",
      " cross_entropy: 0.00116742, clust_cross_entropy: 0.000421001, affinity: 0.000114189, balance: 0.115632, coact: 0, frob: 0.0003266\n",
      "step 25000/30000 \n",
      " Train: accuracy: 1, loss: 0.0644744 \n",
      " Validation: accuracy: 0.90625 loss: 0.919618\n",
      " cross_entropy: 0.000418565, clust_cross_entropy: 0.00127819, affinity: 0, balance: 0.0521352, coact: 0.00268023, frob: 0.00033663\n",
      "step 25100/30000 \n",
      " Train: accuracy: 1, loss: 0.0518994 \n",
      " Validation: accuracy: 0.953125 loss: 0.717465\n",
      " cross_entropy: 0.00108722, clust_cross_entropy: 0.000377801, affinity: 0.000171552, balance: 0.0543927, coact: 0.011254, frob: 0.000326345\n",
      "step 25200/30000 \n",
      " Train: accuracy: 1, loss: 0.0669675 \n",
      " Validation: accuracy: 0.945312 loss: 0.607645\n",
      " cross_entropy: 0.00222848, clust_cross_entropy: 0.00118657, affinity: 4.30509e-05, balance: 0.0657416, coact: 0.00205327, frob: 0.000335312\n",
      "step 25300/30000 \n",
      " Train: accuracy: 1, loss: 0.126223 \n",
      " Validation: accuracy: 0.9375 loss: 1.15283\n",
      " cross_entropy: 0.000606918, clust_cross_entropy: 0.00102167, affinity: 0.000616125, balance: 0.106072, coact: 0.00109199, frob: 0.000334723\n",
      "step 25400/30000 \n",
      " Train: accuracy: 1, loss: 0.0857338 \n",
      " Validation: accuracy: 0.96875 loss: 0.534067\n",
      " cross_entropy: 0.000944001, clust_cross_entropy: 0.00247926, affinity: 2.19492e-05, balance: 0.0828984, coact: 0, frob: 0.0003219\n",
      "step 25500/30000 \n",
      " Train: accuracy: 1, loss: 0.0736322 \n",
      " Validation: accuracy: 0.945312 loss: 0.512958\n",
      " cross_entropy: 0.00143896, clust_cross_entropy: 0.000443296, affinity: 1.80016e-06, balance: 0.0898056, coact: 0.00208106, frob: 0.000329663\n",
      "step 25600/30000 \n",
      " Train: accuracy: 0.992188, loss: 0.0534801 \n",
      " Validation: accuracy: 0.882812 loss: 1.29521\n",
      " cross_entropy: 0.00147717, clust_cross_entropy: 0.00114804, affinity: 0, balance: 0.0609236, coact: 0.00725764, frob: 0.000334188\n",
      "step 25700/30000 \n",
      " Train: accuracy: 1, loss: 0.0478288 \n",
      " Validation: accuracy: 0.945312 loss: 0.985781\n",
      " cross_entropy: 0.000440358, clust_cross_entropy: 0.00209214, affinity: 0.00012656, balance: 0.0384036, coact: 0.00214701, frob: 0.000334926\n",
      "step 25800/30000 \n",
      " Train: accuracy: 1, loss: 0.0736662 \n",
      " Validation: accuracy: 0.976562 loss: 0.632305\n",
      " cross_entropy: 0.000785037, clust_cross_entropy: 0.000643047, affinity: 0, balance: 0.0761819, coact: 0.00408677, frob: 0.000340147\n",
      "step 25900/30000 \n",
      " Train: accuracy: 1, loss: 0.0530544 \n",
      " Validation: accuracy: 0.929688 loss: 0.576645\n",
      " cross_entropy: 0.00220309, clust_cross_entropy: 0.000939635, affinity: 0, balance: 0.0539687, coact: 0.00283238, frob: 0.000327154\n",
      "step 26000/30000 \n",
      " Train: accuracy: 1, loss: 0.0771531 \n",
      " Validation: accuracy: 0.929688 loss: 0.793447\n",
      " cross_entropy: 0.000537668, clust_cross_entropy: 0.000535016, affinity: 0, balance: 0.0691826, coact: 0, frob: 0.000343538\n",
      "step 26100/30000 \n",
      " Train: accuracy: 1, loss: 0.0633707 \n",
      " Validation: accuracy: 0.914062 loss: 0.967319\n",
      " cross_entropy: 0.000654565, clust_cross_entropy: 0.0014215, affinity: 0.000572161, balance: 0.0554666, coact: 6.84881e-05, frob: 0.000330233\n",
      "step 26200/30000 \n",
      " Train: accuracy: 1, loss: 0.0389955 \n",
      " Validation: accuracy: 0.945312 loss: 0.587522\n",
      " cross_entropy: 0.00228013, clust_cross_entropy: 0.0014168, affinity: 2.00244e-06, balance: 0.0553803, coact: 0, frob: 0.000318972\n",
      "step 26300/30000 \n",
      " Train: accuracy: 1, loss: 0.0557924 \n",
      " Validation: accuracy: 0.9375 loss: 0.731393\n",
      " cross_entropy: 0.00092448, clust_cross_entropy: 0.00113301, affinity: 0, balance: 0.085793, coact: 0, frob: 0.000335963\n",
      "step 26400/30000 \n",
      " Train: accuracy: 1, loss: 0.115782 \n",
      " Validation: accuracy: 0.914062 loss: 0.804162\n",
      " cross_entropy: 0.000446661, clust_cross_entropy: 0.00117904, affinity: 8.44457e-05, balance: 0.0876595, coact: 7.88333e-05, frob: 0.000345461\n",
      "step 26500/30000 \n",
      " Train: accuracy: 1, loss: 0.0627458 \n",
      " Validation: accuracy: 0.914062 loss: 0.915762\n",
      " cross_entropy: 0.000555142, clust_cross_entropy: 0.00212876, affinity: 4.29606e-05, balance: 0.0585458, coact: 0, frob: 0.000338039\n",
      "step 26600/30000 \n",
      " Train: accuracy: 1, loss: 0.0678181 \n",
      " Validation: accuracy: 0.945312 loss: 0.428738\n",
      " cross_entropy: 0.00122101, clust_cross_entropy: 0.000994697, affinity: 0, balance: 0.0758083, coact: 0, frob: 0.000336313\n",
      "step 26700/30000 \n",
      " Train: accuracy: 1, loss: 0.0874182 \n",
      " Validation: accuracy: 0.960938 loss: 0.426601\n",
      " cross_entropy: 0.00424813, clust_cross_entropy: 0.00207965, affinity: 0.000222612, balance: 0.0847744, coact: 0.00232861, frob: 0.000336844\n",
      "step 26800/30000 \n",
      " Train: accuracy: 1, loss: 0.0222191 \n",
      " Validation: accuracy: 0.921875 loss: 0.893718\n",
      " cross_entropy: 0.00045942, clust_cross_entropy: 0.0010127, affinity: 0.0001384, balance: 0.0292059, coact: 0.00842643, frob: 0.000325686\n",
      "step 26900/30000 \n",
      " Train: accuracy: 1, loss: 0.117287 \n",
      " Validation: accuracy: 0.914062 loss: 1.18096\n",
      " cross_entropy: 0.000517091, clust_cross_entropy: 0.00263134, affinity: 0, balance: 0.152295, coact: 0.00590759, frob: 0.000338074\n",
      "step 27000/30000 \n",
      " Train: accuracy: 1, loss: 0.0573682 \n",
      " Validation: accuracy: 0.929688 loss: 0.809132\n",
      " cross_entropy: 0.00083909, clust_cross_entropy: 0.00134455, affinity: 1.70025e-05, balance: 0.0415068, coact: 0, frob: 0.000327877\n",
      "step 27100/30000 \n",
      " Train: accuracy: 1, loss: 0.0676717 \n",
      " Validation: accuracy: 0.953125 loss: 0.756327\n",
      " cross_entropy: 0.000483079, clust_cross_entropy: 0.000500285, affinity: 0.000265599, balance: 0.0559846, coact: 0.00689719, frob: 0.0003378\n",
      "step 27200/30000 \n",
      " Train: accuracy: 1, loss: 0.112761 \n",
      " Validation: accuracy: 0.953125 loss: 0.600437\n",
      " cross_entropy: 0.00050003, clust_cross_entropy: 0.00275887, affinity: 0, balance: 0.134545, coact: 0.0206399, frob: 0.000336766\n",
      "step 27300/30000 \n",
      " Train: accuracy: 1, loss: 0.0710425 \n",
      " Validation: accuracy: 0.90625 loss: 1.14708\n",
      " cross_entropy: 0.00117065, clust_cross_entropy: 0.000728323, affinity: 0.000131254, balance: 0.0423087, coact: 0.00708176, frob: 0.000338857\n",
      "step 27400/30000 \n",
      " Train: accuracy: 1, loss: 0.0655596 \n",
      " Validation: accuracy: 0.960938 loss: 0.81864\n",
      " cross_entropy: 0.00206661, clust_cross_entropy: 0.00140328, affinity: 0, balance: 0.0989926, coact: 0, frob: 0.000347551\n",
      "step 27500/30000 \n",
      " Train: accuracy: 1, loss: 0.0969228 \n",
      " Validation: accuracy: 0.9375 loss: 0.831211\n",
      " cross_entropy: 0.00142181, clust_cross_entropy: 0.00199833, affinity: 9.42865e-06, balance: 0.0977427, coact: 0, frob: 0.000336227\n",
      "step 27600/30000 \n",
      " Train: accuracy: 1, loss: 0.0856824 \n",
      " Validation: accuracy: 0.929688 loss: 0.92005\n",
      " cross_entropy: 0.000695678, clust_cross_entropy: 0.00191205, affinity: 0.000492848, balance: 0.0910751, coact: 0.00678312, frob: 0.00033518\n",
      "step 27700/30000 \n",
      " Train: accuracy: 1, loss: 0.0783718 \n",
      " Validation: accuracy: 0.96875 loss: 0.720455\n",
      " cross_entropy: 0.000791983, clust_cross_entropy: 0.00157713, affinity: 0, balance: 0.0918106, coact: 0.00772216, frob: 0.000335314\n",
      "step 27800/30000 \n",
      " Train: accuracy: 1, loss: 0.0750662 \n",
      " Validation: accuracy: 0.890625 loss: 1.13787\n",
      " cross_entropy: 0.00118143, clust_cross_entropy: 0.000466462, affinity: 1.02658e-05, balance: 0.0586855, coact: 0, frob: 0.000340665\n",
      "step 27900/30000 \n",
      " Train: accuracy: 1, loss: 0.123724 \n",
      " Validation: accuracy: 0.945312 loss: 1.03643\n",
      " cross_entropy: 0.000448199, clust_cross_entropy: 0.00110904, affinity: 0.000189662, balance: 0.138595, coact: 0, frob: 0.000347598\n",
      "step 28000/30000 \n",
      " Train: accuracy: 1, loss: 0.0551281 \n",
      " Validation: accuracy: 0.914062 loss: 1.03101\n",
      " cross_entropy: 0.000578721, clust_cross_entropy: 0.000406289, affinity: 0.000585691, balance: 0.041357, coact: 0.00306263, frob: 0.000330185\n",
      "step 28100/30000 \n",
      " Train: accuracy: 1, loss: 0.0486833 \n",
      " Validation: accuracy: 0.90625 loss: 0.712814\n",
      " cross_entropy: 0.000418109, clust_cross_entropy: 0.00216905, affinity: 1.97416e-05, balance: 0.0389951, coact: 0, frob: 0.000318959\n",
      "step 28200/30000 \n",
      " Train: accuracy: 1, loss: 0.0701052 \n",
      " Validation: accuracy: 0.960938 loss: 0.663961\n",
      " cross_entropy: 0.00279815, clust_cross_entropy: 0.000409986, affinity: 0.00048677, balance: 0.0779499, coact: 0.00538503, frob: 0.000339457\n",
      "step 28300/30000 \n",
      " Train: accuracy: 1, loss: 0.121855 \n",
      " Validation: accuracy: 0.953125 loss: 0.663282\n",
      " cross_entropy: 0.000609867, clust_cross_entropy: 0.000669435, affinity: 5.94256e-05, balance: 0.103061, coact: 0, frob: 0.000339277\n",
      "step 28400/30000 \n",
      " Train: accuracy: 1, loss: 0.0778535 \n",
      " Validation: accuracy: 0.960938 loss: 0.752112\n",
      " cross_entropy: 0.000845016, clust_cross_entropy: 0.00130176, affinity: 0.000358618, balance: 0.104415, coact: 0, frob: 0.00033358\n",
      "step 28500/30000 \n",
      " Train: accuracy: 1, loss: 0.0773491 \n",
      " Validation: accuracy: 0.929688 loss: 0.745005\n",
      " cross_entropy: 0.000917342, clust_cross_entropy: 0.000257791, affinity: 0, balance: 0.0667408, coact: 0.00092038, frob: 0.000341128\n",
      "step 28600/30000 \n",
      " Train: accuracy: 1, loss: 0.0721602 \n",
      " Validation: accuracy: 0.914062 loss: 0.759431\n",
      " cross_entropy: 0.000903215, clust_cross_entropy: 0.00125006, affinity: 0.000110025, balance: 0.0754209, coact: 0.00941148, frob: 0.000334417\n",
      "step 28700/30000 \n",
      " Train: accuracy: 1, loss: 0.0720086 \n",
      " Validation: accuracy: 0.914062 loss: 0.849301\n",
      " cross_entropy: 0.00132682, clust_cross_entropy: 0.000873107, affinity: 0.000142732, balance: 0.0673199, coact: 0.0149856, frob: 0.000337018\n",
      "step 28800/30000 \n",
      " Train: accuracy: 1, loss: 0.0746997 \n",
      " Validation: accuracy: 0.953125 loss: 0.566638\n",
      " cross_entropy: 0.000593218, clust_cross_entropy: 0.00140986, affinity: 0.000266889, balance: 0.0725398, coact: 0.00262316, frob: 0.000330252\n",
      "step 28900/30000 \n",
      " Train: accuracy: 1, loss: 0.0903798 \n",
      " Validation: accuracy: 0.945312 loss: 0.957438\n",
      " cross_entropy: 0.0010606, clust_cross_entropy: 0.00101404, affinity: 0.000270795, balance: 0.0844744, coact: 0, frob: 0.000335536\n",
      "step 29000/30000 \n",
      " Train: accuracy: 1, loss: 0.0590288 \n",
      " Validation: accuracy: 0.9375 loss: 0.803553\n",
      " cross_entropy: 0.000894035, clust_cross_entropy: 0.00139883, affinity: 0.000190553, balance: 0.0320068, coact: 0.00903574, frob: 0.000331022\n",
      "step 29100/30000 \n",
      " Train: accuracy: 1, loss: 0.0541108 \n",
      " Validation: accuracy: 0.90625 loss: 0.968468\n",
      " cross_entropy: 0.000759343, clust_cross_entropy: 0.00157174, affinity: 0, balance: 0.0471559, coact: 0, frob: 0.000335516\n",
      "step 29200/30000 \n",
      " Train: accuracy: 1, loss: 0.0449247 \n",
      " Validation: accuracy: 0.945312 loss: 0.712127\n",
      " cross_entropy: 0.0029366, clust_cross_entropy: 0.00172403, affinity: 0, balance: 0.0354894, coact: 0, frob: 0.000335355\n",
      "step 29300/30000 \n",
      " Train: accuracy: 1, loss: 0.0247319 \n",
      " Validation: accuracy: 0.945312 loss: 0.719083\n",
      " cross_entropy: 0.000785827, clust_cross_entropy: 0.0003733, affinity: 0.000491629, balance: 0.0309492, coact: 0, frob: 0.000339145\n",
      "step 29400/30000 \n",
      " Train: accuracy: 1, loss: 0.0920486 \n",
      " Validation: accuracy: 0.921875 loss: 1.2313\n",
      " cross_entropy: 0.000534668, clust_cross_entropy: 0.00041444, affinity: 2.21531e-05, balance: 0.0661578, coact: 0, frob: 0.000331145\n",
      "step 29500/30000 \n",
      " Train: accuracy: 1, loss: 0.0293307 \n",
      " Validation: accuracy: 0.898438 loss: 0.972277\n",
      " cross_entropy: 0.000950947, clust_cross_entropy: 0.000484656, affinity: 0, balance: 0.0378827, coact: 0, frob: 0.000334939\n",
      "step 29600/30000 \n",
      " Train: accuracy: 1, loss: 0.0476572 \n",
      " Validation: accuracy: 0.945312 loss: 0.795227\n",
      " cross_entropy: 0.000599884, clust_cross_entropy: 0.000412321, affinity: 0.000513808, balance: 0.0615276, coact: 0.000350797, frob: 0.00033488\n",
      "step 29700/30000 \n",
      " Train: accuracy: 1, loss: 0.0572466 \n",
      " Validation: accuracy: 0.914062 loss: 0.994474\n",
      " cross_entropy: 0.000896776, clust_cross_entropy: 0.00175264, affinity: 4.59117e-05, balance: 0.0330763, coact: 0, frob: 0.000332824\n",
      "step 29800/30000 \n",
      " Train: accuracy: 1, loss: 0.0748397 \n",
      " Validation: accuracy: 0.96875 loss: 0.624097\n",
      " cross_entropy: 0.000808082, clust_cross_entropy: 0.00058236, affinity: 0, balance: 0.0696124, coact: 0, frob: 0.000350557\n",
      "step 29900/30000 \n",
      " Train: accuracy: 1, loss: 0.0914277 \n",
      " Validation: accuracy: 0.945312 loss: 0.49483\n",
      " cross_entropy: 0.000737511, clust_cross_entropy: 0.00167868, affinity: 0.000434876, balance: 0.0902913, coact: 0.000594673, frob: 0.000339762\n"
     ]
    }
   ],
   "source": [
    "#Learning with only the labelled part -> step 1\n",
    "\n",
    "convy2 = y2\n",
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images_labelled_only, train_labels_labelled_only, train_super_labels_labelled_only,_epochs_completed_train,_index_in_epoch_train)\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels, validation_super_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2],keep_prob: 0.3})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, affinity: %g, balance: %g, coact: %g, frob: %g\"%(cc0*entr, cc5*entr2 ,cc1*hist['affinity'][-1],cc2*(1-hist['balance'][-1]),cc3*hist['coactivity'][-1],cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "step 0/20000 \n",
      " Train: accuracy: 0.914062, loss: 0.448303 \n",
      " Validation: accuracy: 0.960938 loss: 0.734796\n",
      " cross_entropy: 0.279142, clust_cross_entropy: 1.61313e-05, affinity: 0.000504037, balance: 0.171221, coact: 0.0218717, frob: 0.000318642\n",
      "step 100/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.275905 \n",
      " Validation: accuracy: 0.9375 loss: 0.562485\n",
      " cross_entropy: 0.181273, clust_cross_entropy: 4.47254e-06, affinity: 0.00109437, balance: 0.0736154, coact: 0.00771861, frob: 0.000307784\n",
      "step 200/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.428464 \n",
      " Validation: accuracy: 0.953125 loss: 0.479607\n",
      " cross_entropy: 0.120009, clust_cross_entropy: 4.36679e-06, affinity: 0.00087539, balance: 0.184797, coact: 0.0105738, frob: 0.000308164\n",
      "step 300/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.252784 \n",
      " Validation: accuracy: 0.960938 loss: 0.510963\n",
      " cross_entropy: 0.21293, clust_cross_entropy: 3.476e-06, affinity: 0.00136877, balance: 0.0789829, coact: 0.0146916, frob: 0.000296029\n",
      "step 400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.210761 \n",
      " Validation: accuracy: 0.984375 loss: 0.280981\n",
      " cross_entropy: 0.127241, clust_cross_entropy: 2.05803e-06, affinity: 0.00236647, balance: 0.169375, coact: 0.0286278, frob: 0.000298042\n",
      "step 500/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.217058 \n",
      " Validation: accuracy: 0.953125 loss: 0.496641\n",
      " cross_entropy: 0.14716, clust_cross_entropy: 0, affinity: 0.00117389, balance: 0.0714976, coact: 0.00779728, frob: 0.000290595\n",
      "step 600/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.232444 \n",
      " Validation: accuracy: 0.984375 loss: 0.669892\n",
      " cross_entropy: 0.133163, clust_cross_entropy: 2.33198e-05, affinity: 0.00234266, balance: 0.0769436, coact: 0.0065424, frob: 0.000291944\n",
      "step 700/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.294388 \n",
      " Validation: accuracy: 0.96875 loss: 0.420637\n",
      " cross_entropy: 0.22412, clust_cross_entropy: 4.5417e-05, affinity: 0.00257849, balance: 0.107694, coact: 0.0186645, frob: 0.000297205\n",
      "step 800/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.258578 \n",
      " Validation: accuracy: 0.9375 loss: 0.628291\n",
      " cross_entropy: 0.12442, clust_cross_entropy: 0, affinity: 0.0021645, balance: 0.149352, coact: 0.0136485, frob: 0.00029352\n",
      "step 900/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.236068 \n",
      " Validation: accuracy: 0.945312 loss: 0.812994\n",
      " cross_entropy: 0.144868, clust_cross_entropy: 6.90182e-06, affinity: 0.00174439, balance: 0.132462, coact: 0.0124769, frob: 0.000292433\n",
      "step 1000/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.220873 \n",
      " Validation: accuracy: 0.96875 loss: 0.284278\n",
      " cross_entropy: 0.181436, clust_cross_entropy: 1.46601e-05, affinity: 0.000701103, balance: 0.0837423, coact: 0.0106479, frob: 0.000289019\n",
      "step 1100/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.232071 \n",
      " Validation: accuracy: 0.960938 loss: 0.568117\n",
      " cross_entropy: 0.0769736, clust_cross_entropy: 1.49012e-08, affinity: 0.000168797, balance: 0.0692485, coact: 0.00709002, frob: 0.000283762\n",
      "step 1200/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.187876 \n",
      " Validation: accuracy: 0.945312 loss: 0.862394\n",
      " cross_entropy: 0.107079, clust_cross_entropy: 0, affinity: 0.0013456, balance: 0.0612408, coact: 0.000893528, frob: 0.000292736\n",
      "step 1300/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.254099 \n",
      " Validation: accuracy: 0.953125 loss: 0.717963\n",
      " cross_entropy: 0.118263, clust_cross_entropy: 1.18286e-06, affinity: 0.00127008, balance: 0.122347, coact: 0.00567034, frob: 0.000287957\n",
      "step 1400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.148881 \n",
      " Validation: accuracy: 0.984375 loss: 0.317306\n",
      " cross_entropy: 0.100237, clust_cross_entropy: 2.97055e-05, affinity: 0.00132506, balance: 0.0383523, coact: 0.0111948, frob: 0.000291194\n",
      "step 1500/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.192551 \n",
      " Validation: accuracy: 0.945312 loss: 0.888971\n",
      " cross_entropy: 0.0784009, clust_cross_entropy: 6.09043e-06, affinity: 0.00107159, balance: 0.104792, coact: 0.016933, frob: 0.000289012\n",
      "step 1600/20000 \n",
      " Train: accuracy: 0.929688, loss: 0.25505 \n",
      " Validation: accuracy: 0.976562 loss: 0.496432\n",
      " cross_entropy: 0.250996, clust_cross_entropy: 0, affinity: 0.00142041, balance: 0.0961538, coact: 0.00577876, frob: 0.000288389\n",
      "step 1700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.190294 \n",
      " Validation: accuracy: 0.992188 loss: 0.299334\n",
      " cross_entropy: 0.145559, clust_cross_entropy: 0.000105737, affinity: 0.00140162, balance: 0.0895126, coact: 0.0126445, frob: 0.000285847\n",
      "step 1800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.179699 \n",
      " Validation: accuracy: 0.960938 loss: 0.474095\n",
      " cross_entropy: 0.111288, clust_cross_entropy: 8.22401e-07, affinity: 0.000339707, balance: 0.130787, coact: 0.00435737, frob: 0.000301909\n",
      "step 1900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.156411 \n",
      " Validation: accuracy: 0.953125 loss: 0.694702\n",
      " cross_entropy: 0.13025, clust_cross_entropy: 0.000286703, affinity: 0.00146989, balance: 0.0868629, coact: 0.00611814, frob: 0.000283992\n",
      "step 2000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.190659 \n",
      " Validation: accuracy: 0.984375 loss: 0.330867\n",
      " cross_entropy: 0.0620456, clust_cross_entropy: 1.89799e-05, affinity: 0.000613158, balance: 0.110575, coact: 0.00170417, frob: 0.000281936\n",
      "step 2100/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.305737 \n",
      " Validation: accuracy: 0.96875 loss: 0.545556\n",
      " cross_entropy: 0.153394, clust_cross_entropy: 6.30105e-05, affinity: 0.00217251, balance: 0.0975186, coact: 0.0066769, frob: 0.000281828\n",
      "step 2200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.374998 \n",
      " Validation: accuracy: 0.921875 loss: 0.694434\n",
      " cross_entropy: 0.140434, clust_cross_entropy: 1.07855e-06, affinity: 0.000178192, balance: 0.187748, coact: 0.00232703, frob: 0.00028188\n",
      "step 2300/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.226287 \n",
      " Validation: accuracy: 0.992188 loss: 0.294464\n",
      " cross_entropy: 0.0980916, clust_cross_entropy: 0, affinity: 0.000772023, balance: 0.0302284, coact: 0.0139062, frob: 0.000294603\n",
      "step 2400/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.361077 \n",
      " Validation: accuracy: 0.960938 loss: 0.543497\n",
      " cross_entropy: 0.263839, clust_cross_entropy: 0, affinity: 0.00155768, balance: 0.106748, coact: 0.0112977, frob: 0.000282603\n",
      "step 2500/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.284593 \n",
      " Validation: accuracy: 0.976562 loss: 0.354629\n",
      " cross_entropy: 0.126484, clust_cross_entropy: 9.91922e-07, affinity: 0.00109056, balance: 0.0489453, coact: 0.0200921, frob: 0.000289059\n",
      "step 2600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.220057 \n",
      " Validation: accuracy: 0.960938 loss: 0.537104\n",
      " cross_entropy: 0.0964138, clust_cross_entropy: 0, affinity: 0.00173823, balance: 0.168065, coact: 0.00564744, frob: 0.000290529\n",
      "step 2700/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.318871 \n",
      " Validation: accuracy: 0.945312 loss: 0.581975\n",
      " cross_entropy: 0.15873, clust_cross_entropy: 1.11207e-06, affinity: 0.00213468, balance: 0.0945229, coact: 0.0164713, frob: 0.000280321\n",
      "step 2800/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.227189 \n",
      " Validation: accuracy: 0.96875 loss: 0.448469\n",
      " cross_entropy: 0.0618104, clust_cross_entropy: 4.2469e-07, affinity: 0.00048224, balance: 0.0817952, coact: 0.00608532, frob: 0.000290512\n",
      "step 2900/20000 \n",
      " Train: accuracy: 0.929688, loss: 0.277143 \n",
      " Validation: accuracy: 0.976562 loss: 0.482088\n",
      " cross_entropy: 0.249572, clust_cross_entropy: 3.49758e-05, affinity: 0.00103917, balance: 0.0655581, coact: 0.00310693, frob: 0.000297623\n",
      "step 3000/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.279994 \n",
      " Validation: accuracy: 0.953125 loss: 0.469777\n",
      " cross_entropy: 0.118534, clust_cross_entropy: 5.88618e-07, affinity: 0.00202305, balance: 0.119051, coact: 0.0146454, frob: 0.000294978\n",
      "step 3100/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.131676 \n",
      " Validation: accuracy: 0.976562 loss: 0.339116\n",
      " cross_entropy: 0.0452281, clust_cross_entropy: 0.0024644, affinity: 0.000897973, balance: 0.140289, coact: 0.0200761, frob: 0.000294434\n",
      "step 3200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.21414 \n",
      " Validation: accuracy: 0.976562 loss: 0.376901\n",
      " cross_entropy: 0.0995475, clust_cross_entropy: 8.02933e-06, affinity: 0.00228983, balance: 0.115826, coact: 0.0146007, frob: 0.000293537\n",
      "step 3300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.194554 \n",
      " Validation: accuracy: 0.992188 loss: 0.305186\n",
      " cross_entropy: 0.0848797, clust_cross_entropy: 1.86265e-08, affinity: 0.00129244, balance: 0.0724069, coact: 0.0330562, frob: 0.000292216\n",
      "step 3400/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.181214 \n",
      " Validation: accuracy: 0.992188 loss: 0.197011\n",
      " cross_entropy: 0.128712, clust_cross_entropy: 5.50525e-06, affinity: 0.0028095, balance: 0.0472929, coact: 0.00870947, frob: 0.000280484\n",
      "step 3500/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.197343 \n",
      " Validation: accuracy: 0.953125 loss: 0.725859\n",
      " cross_entropy: 0.18545, clust_cross_entropy: 1.61721e-05, affinity: 0.000332391, balance: 0.0697096, coact: 0.00550267, frob: 0.000294746\n",
      "step 3600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.260575 \n",
      " Validation: accuracy: 0.984375 loss: 0.451471\n",
      " cross_entropy: 0.0777433, clust_cross_entropy: 2.72874e-05, affinity: 0.00214427, balance: 0.107556, coact: 0.0138553, frob: 0.00029054\n",
      "step 3700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.287019 \n",
      " Validation: accuracy: 0.984375 loss: 0.245487\n",
      " cross_entropy: 0.159223, clust_cross_entropy: 9.31323e-10, affinity: 0.00077489, balance: 0.0798612, coact: 0.0142146, frob: 0.000301087\n",
      "step 3800/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.243123 \n",
      " Validation: accuracy: 1 loss: 0.263044\n",
      " cross_entropy: 0.105156, clust_cross_entropy: 0, affinity: 0.000796307, balance: 0.064165, coact: 0.0132302, frob: 0.000287543\n",
      "step 3900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.159006 \n",
      " Validation: accuracy: 0.960938 loss: 0.356586\n",
      " cross_entropy: 0.0452466, clust_cross_entropy: 0, affinity: 0.000252629, balance: 0.0602745, coact: 5.54264e-05, frob: 0.000293662\n",
      "step 4000/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.325151 \n",
      " Validation: accuracy: 0.976562 loss: 0.323277\n",
      " cross_entropy: 0.137528, clust_cross_entropy: 0, affinity: 0.000206302, balance: 0.132543, coact: 0.00140664, frob: 0.000290703\n",
      "step 4100/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.158601 \n",
      " Validation: accuracy: 0.976562 loss: 0.320266\n",
      " cross_entropy: 0.0555432, clust_cross_entropy: 0, affinity: 0.000257779, balance: 0.0356084, coact: 0.00256824, frob: 0.000305775\n",
      "step 4200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.310927 \n",
      " Validation: accuracy: 0.953125 loss: 0.38836\n",
      " cross_entropy: 0.173676, clust_cross_entropy: 1.86265e-09, affinity: 0.00169823, balance: 0.158138, coact: 0.00399487, frob: 0.000309563\n",
      "step 4300/20000 \n",
      " Train: accuracy: 0.929688, loss: 0.27794 \n",
      " Validation: accuracy: 0.960938 loss: 0.641828\n",
      " cross_entropy: 0.210216, clust_cross_entropy: 1.09718e-06, affinity: 0.000384401, balance: 0.0617368, coact: 0.0126226, frob: 0.000288448\n",
      "step 4400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.204843 \n",
      " Validation: accuracy: 0.9375 loss: 0.574484\n",
      " cross_entropy: 0.0924885, clust_cross_entropy: 1.47303e-06, affinity: 0.00232491, balance: 0.0651181, coact: 0.000777727, frob: 0.000308081\n",
      "step 4500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.128531 \n",
      " Validation: accuracy: 0.960938 loss: 0.582015\n",
      " cross_entropy: 0.161622, clust_cross_entropy: 4.15102e-06, affinity: 0.00150145, balance: 0.0579484, coact: 0.0337907, frob: 0.000290961\n",
      "step 4600/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.236656 \n",
      " Validation: accuracy: 0.984375 loss: 0.255318\n",
      " cross_entropy: 0.103268, clust_cross_entropy: 0, affinity: 0.000400273, balance: 0.0776019, coact: 0.0145967, frob: 0.000308506\n",
      "step 4700/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.266656 \n",
      " Validation: accuracy: 0.96875 loss: 0.513993\n",
      " cross_entropy: 0.118173, clust_cross_entropy: 0, affinity: 0.000137884, balance: 0.137975, coact: 0.00619051, frob: 0.000292874\n",
      "step 4800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0858124 \n",
      " Validation: accuracy: 0.984375 loss: 0.485744\n",
      " cross_entropy: 0.0859788, clust_cross_entropy: 4.30589e-05, affinity: 0.000298093, balance: 0.0399531, coact: 0.000228933, frob: 0.000304143\n",
      "step 4900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.205176 \n",
      " Validation: accuracy: 0.992188 loss: 0.292866\n",
      " cross_entropy: 0.093562, clust_cross_entropy: 0.000353268, affinity: 0.00114602, balance: 0.102887, coact: 0.00372124, frob: 0.0003094\n",
      "step 5000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.234132 \n",
      " Validation: accuracy: 0.96875 loss: 0.458306\n",
      " cross_entropy: 0.0786474, clust_cross_entropy: 1.76086e-06, affinity: 0.000330449, balance: 0.103225, coact: 0.000609017, frob: 0.000306006\n",
      "step 5100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.204806 \n",
      " Validation: accuracy: 0.984375 loss: 0.474263\n",
      " cross_entropy: 0.0810287, clust_cross_entropy: 0.000359817, affinity: 0.00130451, balance: 0.0941637, coact: 0.00726055, frob: 0.000304943\n",
      "step 5200/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.199256 \n",
      " Validation: accuracy: 0.960938 loss: 0.572306\n",
      " cross_entropy: 0.168131, clust_cross_entropy: 2.4494e-07, affinity: 0.000299255, balance: 0.0611377, coact: 0.000970027, frob: 0.000295787\n",
      "step 5300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.112119 \n",
      " Validation: accuracy: 0.953125 loss: 0.660439\n",
      " cross_entropy: 0.0669118, clust_cross_entropy: 0, affinity: 0.000798916, balance: 0.0464301, coact: 0.0070712, frob: 0.000300177\n",
      "step 5400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.18075 \n",
      " Validation: accuracy: 0.960938 loss: 0.366709\n",
      " cross_entropy: 0.0529523, clust_cross_entropy: 0, affinity: 0.00118333, balance: 0.109258, coact: 0.00617617, frob: 0.000299374\n",
      "step 5500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.17661 \n",
      " Validation: accuracy: 0.96875 loss: 0.293993\n",
      " cross_entropy: 0.150401, clust_cross_entropy: 0, affinity: 0.000451914, balance: 0.139722, coact: 0.00462948, frob: 0.000296311\n",
      "step 5600/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.128065 \n",
      " Validation: accuracy: 0.960938 loss: 0.509713\n",
      " cross_entropy: 0.0367571, clust_cross_entropy: 4.23524e-05, affinity: 0.00149843, balance: 0.0639376, coact: 0.00375984, frob: 0.000309926\n",
      "step 5700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.25169 \n",
      " Validation: accuracy: 0.953125 loss: 0.526576\n",
      " cross_entropy: 0.130774, clust_cross_entropy: 3.29927e-06, affinity: 0.00112804, balance: 0.0727767, coact: 0.0106681, frob: 0.000305444\n",
      "step 5800/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.242451 \n",
      " Validation: accuracy: 0.976562 loss: 0.400302\n",
      " cross_entropy: 0.0449142, clust_cross_entropy: 2.49053e-05, affinity: 0.000479886, balance: 0.154934, coact: 0.00875439, frob: 0.000300155\n",
      "step 5900/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.247276 \n",
      " Validation: accuracy: 0.96875 loss: 0.285597\n",
      " cross_entropy: 0.105352, clust_cross_entropy: 4.62881e-07, affinity: 0.000107601, balance: 0.0949165, coact: 0.0144941, frob: 0.000311014\n",
      "step 6000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.234547 \n",
      " Validation: accuracy: 0.976562 loss: 0.375646\n",
      " cross_entropy: 0.133014, clust_cross_entropy: 8.7855e-05, affinity: 0.00039996, balance: 0.101527, coact: 0, frob: 0.000299045\n",
      "step 6100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.164465 \n",
      " Validation: accuracy: 1 loss: 0.329553\n",
      " cross_entropy: 0.0894626, clust_cross_entropy: 2.1607e-07, affinity: 0.00194015, balance: 0.130246, coact: 0.0113056, frob: 0.000291918\n",
      "step 6200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.264329 \n",
      " Validation: accuracy: 0.984375 loss: 0.335774\n",
      " cross_entropy: 0.0442508, clust_cross_entropy: 2.82428e-06, affinity: 0.00111622, balance: 0.144554, coact: 0.0108354, frob: 0.000312036\n",
      "step 6300/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.201381 \n",
      " Validation: accuracy: 0.96875 loss: 0.645943\n",
      " cross_entropy: 0.127733, clust_cross_entropy: 0, affinity: 0.00135225, balance: 0.130236, coact: 0.0116827, frob: 0.000296005\n",
      "step 6400/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.172577 \n",
      " Validation: accuracy: 0.992188 loss: 0.408768\n",
      " cross_entropy: 0.112417, clust_cross_entropy: 1.16331e-06, affinity: 0.00156882, balance: 0.0901273, coact: 0.0133873, frob: 0.000298281\n",
      "step 6500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.431137 \n",
      " Validation: accuracy: 0.984375 loss: 0.419862\n",
      " cross_entropy: 0.253239, clust_cross_entropy: 1.3347e-06, affinity: 6.01841e-05, balance: 0.0954299, coact: 0.00490242, frob: 0.000306828\n",
      "step 6600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.160119 \n",
      " Validation: accuracy: 0.953125 loss: 0.527502\n",
      " cross_entropy: 0.0464165, clust_cross_entropy: 0, affinity: 0.0013136, balance: 0.0811623, coact: 0.0119234, frob: 0.000303956\n",
      "step 6700/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.111631 \n",
      " Validation: accuracy: 0.960938 loss: 0.505564\n",
      " cross_entropy: 0.0459555, clust_cross_entropy: 0, affinity: 0.000829986, balance: 0.0801309, coact: 0.00881556, frob: 0.000302008\n",
      "step 6800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.291838 \n",
      " Validation: accuracy: 0.976562 loss: 0.462493\n",
      " cross_entropy: 0.100102, clust_cross_entropy: 0, affinity: 0.00180681, balance: 0.168219, coact: 0.00181757, frob: 0.000294511\n",
      "step 6900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.232584 \n",
      " Validation: accuracy: 0.96875 loss: 0.418905\n",
      " cross_entropy: 0.0316064, clust_cross_entropy: 0, affinity: 0.000311985, balance: 0.125013, coact: 0.00503135, frob: 0.000305622\n",
      "step 7000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.165986 \n",
      " Validation: accuracy: 0.96875 loss: 0.348135\n",
      " cross_entropy: 0.0811356, clust_cross_entropy: 0, affinity: 0.000603506, balance: 0.0769739, coact: 0.0130367, frob: 0.000305902\n",
      "step 7100/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.197898 \n",
      " Validation: accuracy: 0.976562 loss: 0.43769\n",
      " cross_entropy: 0.0612583, clust_cross_entropy: 7.18846e-06, affinity: 0.000175517, balance: 0.104078, coact: 0.00523301, frob: 0.000314817\n",
      "step 7200/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.161171 \n",
      " Validation: accuracy: 0.992188 loss: 0.270128\n",
      " cross_entropy: 0.0829096, clust_cross_entropy: 0, affinity: 0.00156958, balance: 0.0750097, coact: 0.000711393, frob: 0.000315983\n",
      "step 7300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.261241 \n",
      " Validation: accuracy: 0.953125 loss: 0.526042\n",
      " cross_entropy: 0.0488008, clust_cross_entropy: 1.84148e-05, affinity: 0.00109015, balance: 0.179579, coact: 0.000921548, frob: 0.000298094\n",
      "step 7400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.148708 \n",
      " Validation: accuracy: 0.992188 loss: 0.314273\n",
      " cross_entropy: 0.0956177, clust_cross_entropy: 3.87145e-06, affinity: 0.00138905, balance: 0.096761, coact: 0.00216139, frob: 0.000316215\n",
      "step 7500/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.149439 \n",
      " Validation: accuracy: 0.96875 loss: 0.466731\n",
      " cross_entropy: 0.0661203, clust_cross_entropy: 0, affinity: 0.00138309, balance: 0.0966209, coact: 0.0135833, frob: 0.000296775\n",
      "step 7600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.190801 \n",
      " Validation: accuracy: 0.960938 loss: 0.897502\n",
      " cross_entropy: 0.0807091, clust_cross_entropy: 0.000102455, affinity: 0.00214995, balance: 0.0753638, coact: 0.01206, frob: 0.000307463\n",
      "step 7700/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.193397 \n",
      " Validation: accuracy: 0.984375 loss: 0.543728\n",
      " cross_entropy: 0.101587, clust_cross_entropy: 3.77742e-06, affinity: 0.000517739, balance: 0.0935019, coact: 0.0102059, frob: 0.000312237\n",
      "step 7800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.258999 \n",
      " Validation: accuracy: 0.984375 loss: 0.256124\n",
      " cross_entropy: 0.0738309, clust_cross_entropy: 9.33555e-06, affinity: 0.00328339, balance: 0.147768, coact: 0.0165189, frob: 0.00029934\n",
      "step 7900/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.254478 \n",
      " Validation: accuracy: 0.976562 loss: 0.316591\n",
      " cross_entropy: 0.0514247, clust_cross_entropy: 5.01538e-06, affinity: 0.000832819, balance: 0.0794861, coact: 0.0169758, frob: 0.000302415\n",
      "step 8000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.279134 \n",
      " Validation: accuracy: 0.984375 loss: 0.364904\n",
      " cross_entropy: 0.0727518, clust_cross_entropy: 5.06818e-05, affinity: 0.000509032, balance: 0.195924, coact: 0.00577282, frob: 0.000306648\n",
      "step 8100/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.170312 \n",
      " Validation: accuracy: 0.984375 loss: 0.310994\n",
      " cross_entropy: 0.121167, clust_cross_entropy: 1.6379e-06, affinity: 0.00237606, balance: 0.0533667, coact: 0.00561176, frob: 0.000307098\n",
      "step 8200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.154861 \n",
      " Validation: accuracy: 1 loss: 0.199201\n",
      " cross_entropy: 0.129271, clust_cross_entropy: 6.4357e-07, affinity: 0.00105326, balance: 0.0933226, coact: 0.00431054, frob: 0.000312913\n",
      "step 8300/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.270246 \n",
      " Validation: accuracy: 0.96875 loss: 0.521602\n",
      " cross_entropy: 0.157397, clust_cross_entropy: 3.00823e-07, affinity: 0.00157724, balance: 0.0657771, coact: 0.00426354, frob: 0.000305335\n",
      "step 8400/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.195671 \n",
      " Validation: accuracy: 0.992188 loss: 0.262278\n",
      " cross_entropy: 0.0828028, clust_cross_entropy: 2.86852e-07, affinity: 0.000814266, balance: 0.0649958, coact: 0.00922446, frob: 0.000311936\n",
      "step 8500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.155449 \n",
      " Validation: accuracy: 0.96875 loss: 0.381688\n",
      " cross_entropy: 0.0960504, clust_cross_entropy: 5.77422e-08, affinity: 0.00163784, balance: 0.0715448, coact: 0.00600772, frob: 0.00031093\n",
      "step 8600/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.170613 \n",
      " Validation: accuracy: 0.953125 loss: 0.447791\n",
      " cross_entropy: 0.0555909, clust_cross_entropy: 4.33977e-06, affinity: 0.000645578, balance: 0.0379428, coact: 0.00404606, frob: 0.000306095\n",
      "step 8700/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.191588 \n",
      " Validation: accuracy: 0.960938 loss: 0.558326\n",
      " cross_entropy: 0.119316, clust_cross_entropy: 2.84748e-05, affinity: 0.00127166, balance: 0.0948151, coact: 0.00948439, frob: 0.00031417\n",
      "step 8800/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.261334 \n",
      " Validation: accuracy: 0.976562 loss: 0.519085\n",
      " cross_entropy: 0.144132, clust_cross_entropy: 1.92388e-06, affinity: 0.000272216, balance: 0.0763546, coact: 0.001321, frob: 0.000314957\n",
      "step 8900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.191069 \n",
      " Validation: accuracy: 0.96875 loss: 0.457744\n",
      " cross_entropy: 0.14575, clust_cross_entropy: 0, affinity: 0.00108943, balance: 0.126321, coact: 0.00332835, frob: 0.000311297\n",
      "step 9000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.190269 \n",
      " Validation: accuracy: 0.984375 loss: 0.229979\n",
      " cross_entropy: 0.109357, clust_cross_entropy: 5.02592e-05, affinity: 0.000449516, balance: 0.0975799, coact: 0.0106785, frob: 0.000313519\n",
      "step 9100/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.316772 \n",
      " Validation: accuracy: 0.976562 loss: 0.483561\n",
      " cross_entropy: 0.185959, clust_cross_entropy: 2.08039e-06, affinity: 0.000291138, balance: 0.181396, coact: 0.00773746, frob: 0.000323292\n",
      "step 9200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.260115 \n",
      " Validation: accuracy: 0.960938 loss: 0.641289\n",
      " cross_entropy: 0.0709881, clust_cross_entropy: 7.18343e-05, affinity: 0.00140772, balance: 0.113364, coact: 0.0118021, frob: 0.000318863\n",
      "step 9300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.150524 \n",
      " Validation: accuracy: 0.976562 loss: 0.418266\n",
      " cross_entropy: 0.130234, clust_cross_entropy: 2.98024e-08, affinity: 0.000472498, balance: 0.0611421, coact: 0.0104964, frob: 0.000317282\n",
      "step 9400/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.17178 \n",
      " Validation: accuracy: 0.960938 loss: 0.412442\n",
      " cross_entropy: 0.0766304, clust_cross_entropy: 0, affinity: 0.000141314, balance: 0.0925681, coact: 0.0129314, frob: 0.000317272\n",
      "step 9500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.175278 \n",
      " Validation: accuracy: 0.976562 loss: 0.468631\n",
      " cross_entropy: 0.0632426, clust_cross_entropy: 4.37723e-08, affinity: 0.00013285, balance: 0.0572213, coact: 0.00928735, frob: 0.00031404\n",
      "step 9600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.153486 \n",
      " Validation: accuracy: 0.960938 loss: 0.588993\n",
      " cross_entropy: 0.0976969, clust_cross_entropy: 7.45062e-08, affinity: 0.000987821, balance: 0.0556857, coact: 0.00367848, frob: 0.000319772\n",
      "step 9700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.202618 \n",
      " Validation: accuracy: 1 loss: 0.228676\n",
      " cross_entropy: 0.0681397, clust_cross_entropy: 1.78828e-05, affinity: 0.000388051, balance: 0.0614578, coact: 0.00918464, frob: 0.00031304\n",
      "step 9800/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.210412 \n",
      " Validation: accuracy: 0.96875 loss: 0.522924\n",
      " cross_entropy: 0.0813181, clust_cross_entropy: 0, affinity: 0.00106079, balance: 0.0963262, coact: 0.00113849, frob: 0.000302854\n",
      "step 9900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.119481 \n",
      " Validation: accuracy: 0.976562 loss: 0.312496\n",
      " cross_entropy: 0.0996309, clust_cross_entropy: 1.00582e-05, affinity: 9.44253e-05, balance: 0.0852181, coact: 0.00407841, frob: 0.000308582\n",
      "step 10000/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.15407 \n",
      " Validation: accuracy: 0.992188 loss: 0.53682\n",
      " cross_entropy: 0.0750671, clust_cross_entropy: 0, affinity: 0.000354906, balance: 0.0652145, coact: 0.0170375, frob: 0.000310226\n",
      "step 10100/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.161939 \n",
      " Validation: accuracy: 0.992188 loss: 0.243759\n",
      " cross_entropy: 0.131151, clust_cross_entropy: 6.05361e-08, affinity: 0.00114003, balance: 0.0953166, coact: 0.0196525, frob: 0.000303733\n",
      "step 10200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.135491 \n",
      " Validation: accuracy: 0.984375 loss: 0.320505\n",
      " cross_entropy: 0.104864, clust_cross_entropy: 4.7033e-07, affinity: 0.000291984, balance: 0.0760494, coact: 0.00020892, frob: 0.000311344\n",
      "step 10300/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.256442 \n",
      " Validation: accuracy: 0.992188 loss: 0.251113\n",
      " cross_entropy: 0.114122, clust_cross_entropy: 0.000140953, affinity: 0.000309907, balance: 0.0669093, coact: 0.00439475, frob: 0.000306796\n",
      "step 10400/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.201954 \n",
      " Validation: accuracy: 0.96875 loss: 0.342001\n",
      " cross_entropy: 0.139442, clust_cross_entropy: 2.03847e-06, affinity: 9.17727e-05, balance: 0.0592718, coact: 0.00865447, frob: 0.000321751\n",
      "step 10500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.157012 \n",
      " Validation: accuracy: 1 loss: 0.350136\n",
      " cross_entropy: 0.0796849, clust_cross_entropy: 8.75235e-06, affinity: 0.000409748, balance: 0.084852, coact: 0.0015513, frob: 0.000304649\n",
      "step 10600/20000 \n",
      " Train: accuracy: 1, loss: 0.182638 \n",
      " Validation: accuracy: 0.976562 loss: 0.424071\n",
      " cross_entropy: 0.0349955, clust_cross_entropy: 4.72195e-07, affinity: 0.000500297, balance: 0.144819, coact: 0.00743161, frob: 0.000310783\n",
      "step 10700/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.121741 \n",
      " Validation: accuracy: 0.992188 loss: 0.399056\n",
      " cross_entropy: 0.0550622, clust_cross_entropy: 1.43631e-05, affinity: 0.000584686, balance: 0.0849907, coact: 0.00148325, frob: 0.000313679\n",
      "step 10800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.222822 \n",
      " Validation: accuracy: 0.992188 loss: 0.247575\n",
      " cross_entropy: 0.124021, clust_cross_entropy: 1.06643e-06, affinity: 0.00126011, balance: 0.0632222, coact: 0.00671091, frob: 0.000305622\n",
      "step 10900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.154126 \n",
      " Validation: accuracy: 0.976562 loss: 0.568466\n",
      " cross_entropy: 0.0366478, clust_cross_entropy: 3.98894e-06, affinity: 0.000459564, balance: 0.102407, coact: 0.0260288, frob: 0.000323445\n",
      "step 11000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.258303 \n",
      " Validation: accuracy: 0.96875 loss: 0.248115\n",
      " cross_entropy: 0.0769435, clust_cross_entropy: 0, affinity: 0.00123014, balance: 0.146585, coact: 0.00464648, frob: 0.000300627\n",
      "step 11100/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.156518 \n",
      " Validation: accuracy: 0.960938 loss: 0.469329\n",
      " cross_entropy: 0.0538237, clust_cross_entropy: 3.4459e-08, affinity: 0.00125507, balance: 0.0323204, coact: 0.00272247, frob: 0.000319536\n",
      "step 11200/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.167332 \n",
      " Validation: accuracy: 0.992188 loss: 0.391591\n",
      " cross_entropy: 0.0455927, clust_cross_entropy: 6.17841e-05, affinity: 0.00102202, balance: 0.110511, coact: 0.0196446, frob: 0.000308731\n",
      "step 11300/20000 \n",
      " Train: accuracy: 1, loss: 0.169847 \n",
      " Validation: accuracy: 0.992188 loss: 0.334998\n",
      " cross_entropy: 0.0307093, clust_cross_entropy: 3.91156e-08, affinity: 0.000681284, balance: 0.13704, coact: 0.0128424, frob: 0.000313021\n",
      "step 11400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.107701 \n",
      " Validation: accuracy: 0.96875 loss: 0.285727\n",
      " cross_entropy: 0.101136, clust_cross_entropy: 2.5053e-07, affinity: 0.00104322, balance: 0.0714749, coact: 0.00249496, frob: 0.000329299\n",
      "step 11500/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.226 \n",
      " Validation: accuracy: 0.976562 loss: 0.380416\n",
      " cross_entropy: 0.110999, clust_cross_entropy: 4.56349e-08, affinity: 0.000711744, balance: 0.14081, coact: 0.00546013, frob: 0.00032046\n",
      "step 11600/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.197123 \n",
      " Validation: accuracy: 0.984375 loss: 0.264585\n",
      " cross_entropy: 0.124137, clust_cross_entropy: 0.000298183, affinity: 3.86788e-05, balance: 0.102808, coact: 0.00149635, frob: 0.000312867\n",
      "step 11700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.264623 \n",
      " Validation: accuracy: 0.976562 loss: 0.355081\n",
      " cross_entropy: 0.0785317, clust_cross_entropy: 0, affinity: 0.000401383, balance: 0.0925177, coact: 0.00853163, frob: 0.000326926\n",
      "step 11800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0892877 \n",
      " Validation: accuracy: 0.953125 loss: 0.480651\n",
      " cross_entropy: 0.0334619, clust_cross_entropy: 0, affinity: 0.00136268, balance: 0.0529269, coact: 0.00305832, frob: 0.000318173\n",
      "step 11900/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.308623 \n",
      " Validation: accuracy: 0.992188 loss: 0.359223\n",
      " cross_entropy: 0.156049, clust_cross_entropy: 1.93356e-05, affinity: 0.000273299, balance: 0.0902203, coact: 0.0104677, frob: 0.000320099\n",
      "step 12000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.223575 \n",
      " Validation: accuracy: 0.976562 loss: 0.315087\n",
      " cross_entropy: 0.161009, clust_cross_entropy: 6.47296e-07, affinity: 0.00123553, balance: 0.125096, coact: 0.0155765, frob: 0.0003118\n",
      "step 12100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.141012 \n",
      " Validation: accuracy: 0.976562 loss: 0.471683\n",
      " cross_entropy: 0.0819279, clust_cross_entropy: 1.28918e-05, affinity: 0.000819491, balance: 0.05131, coact: 0.0050026, frob: 0.000317202\n",
      "step 12200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.168094 \n",
      " Validation: accuracy: 0.960938 loss: 0.503712\n",
      " cross_entropy: 0.0721222, clust_cross_entropy: 1.85335e-07, affinity: 0.00168584, balance: 0.0795111, coact: 0.00829835, frob: 0.000317856\n",
      "step 12300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.176728 \n",
      " Validation: accuracy: 0.976562 loss: 0.305116\n",
      " cross_entropy: 0.103953, clust_cross_entropy: 4.1445e-07, affinity: 0.0018724, balance: 0.0911329, coact: 0.00873263, frob: 0.000318015\n",
      "step 12400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.189308 \n",
      " Validation: accuracy: 1 loss: 0.307727\n",
      " cross_entropy: 0.0647567, clust_cross_entropy: 3.32618e-06, affinity: 7.18684e-05, balance: 0.189245, coact: 0.00879574, frob: 0.000313912\n",
      "step 12500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.326855 \n",
      " Validation: accuracy: 0.992188 loss: 0.320282\n",
      " cross_entropy: 0.136983, clust_cross_entropy: 0.0014411, affinity: 0.00103526, balance: 0.115917, coact: 0.0101551, frob: 0.000335105\n",
      "step 12600/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.22249 \n",
      " Validation: accuracy: 0.976562 loss: 0.366388\n",
      " cross_entropy: 0.0657389, clust_cross_entropy: 7.12414e-06, affinity: 0.000310673, balance: 0.151264, coact: 0.00211266, frob: 0.000318326\n",
      "step 12700/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.315744 \n",
      " Validation: accuracy: 0.96875 loss: 0.386915\n",
      " cross_entropy: 0.190792, clust_cross_entropy: 1.77885e-07, affinity: 4.4585e-05, balance: 0.0540912, coact: 0.00401764, frob: 0.000323051\n",
      "step 12800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.160133 \n",
      " Validation: accuracy: 1 loss: 0.219693\n",
      " cross_entropy: 0.101665, clust_cross_entropy: 2.23518e-08, affinity: 0.000910393, balance: 0.0890076, coact: 0.00567138, frob: 0.000325467\n",
      "step 12900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.129691 \n",
      " Validation: accuracy: 0.976562 loss: 0.273987\n",
      " cross_entropy: 0.0628358, clust_cross_entropy: 1.72297e-07, affinity: 0.000295251, balance: 0.0637189, coact: 0.00495782, frob: 0.00032091\n",
      "step 13000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.271628 \n",
      " Validation: accuracy: 0.953125 loss: 0.463167\n",
      " cross_entropy: 0.0784539, clust_cross_entropy: 0, affinity: 0.000587668, balance: 0.0988834, coact: 0.001574, frob: 0.000321233\n",
      "step 13100/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.211028 \n",
      " Validation: accuracy: 0.976562 loss: 0.318372\n",
      " cross_entropy: 0.0876744, clust_cross_entropy: 1.66744e-05, affinity: 0.000974988, balance: 0.115335, coact: 0.0135171, frob: 0.000329113\n",
      "step 13200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.12304 \n",
      " Validation: accuracy: 0.953125 loss: 0.715141\n",
      " cross_entropy: 0.0918088, clust_cross_entropy: 6.71772e-06, affinity: 0.00111473, balance: 0.0267309, coact: 0.00878229, frob: 0.000314096\n",
      "step 13300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.122322 \n",
      " Validation: accuracy: 0.96875 loss: 0.328146\n",
      " cross_entropy: 0.0677331, clust_cross_entropy: 0, affinity: 4.26023e-05, balance: 0.0624856, coact: 0.00622604, frob: 0.000324488\n",
      "step 13400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.179087 \n",
      " Validation: accuracy: 0.984375 loss: 0.294817\n",
      " cross_entropy: 0.119674, clust_cross_entropy: 0, affinity: 0.000460503, balance: 0.0982946, coact: 0.00128335, frob: 0.000312841\n",
      "step 13500/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.140763 \n",
      " Validation: accuracy: 0.976562 loss: 0.293192\n",
      " cross_entropy: 0.0750193, clust_cross_entropy: 1.27592e-07, affinity: 0.00026305, balance: 0.082785, coact: 0.00619025, frob: 0.000334791\n",
      "step 13600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.135472 \n",
      " Validation: accuracy: 0.96875 loss: 0.50485\n",
      " cross_entropy: 0.0690606, clust_cross_entropy: 5.58794e-09, affinity: 0.000153785, balance: 0.10623, coact: 0.0116508, frob: 0.000327254\n",
      "step 13700/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.116945 \n",
      " Validation: accuracy: 0.984375 loss: 0.477701\n",
      " cross_entropy: 0.0873948, clust_cross_entropy: 1.86265e-09, affinity: 0.000965909, balance: 0.0902119, coact: 0.00354603, frob: 0.000334468\n",
      "step 13800/20000 \n",
      " Train: accuracy: 1, loss: 0.121557 \n",
      " Validation: accuracy: 0.984375 loss: 0.268767\n",
      " cross_entropy: 0.0741749, clust_cross_entropy: 0, affinity: 0.000294637, balance: 0.0912281, coact: 0.0107973, frob: 0.000329459\n",
      "step 13900/20000 \n",
      " Train: accuracy: 1, loss: 0.210767 \n",
      " Validation: accuracy: 0.976562 loss: 0.339651\n",
      " cross_entropy: 0.0578756, clust_cross_entropy: 1.05992e-06, affinity: 0.00139848, balance: 0.14472, coact: 0.0110688, frob: 0.000326937\n",
      "step 14000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.224636 \n",
      " Validation: accuracy: 0.984375 loss: 0.492586\n",
      " cross_entropy: 0.125305, clust_cross_entropy: 0.000162059, affinity: 0.000236202, balance: 0.113548, coact: 0.0121489, frob: 0.00031588\n",
      "step 14100/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.132524 \n",
      " Validation: accuracy: 1 loss: 0.303147\n",
      " cross_entropy: 0.0439148, clust_cross_entropy: 0.000193802, affinity: 0.000101782, balance: 0.104811, coact: 0.0150365, frob: 0.000339196\n",
      "step 14200/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.382995 \n",
      " Validation: accuracy: 0.992188 loss: 0.257071\n",
      " cross_entropy: 0.101745, clust_cross_entropy: 0, affinity: 0.00203821, balance: 0.130688, coact: 0.00748085, frob: 0.000314176\n",
      "step 14300/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.254353 \n",
      " Validation: accuracy: 0.96875 loss: 0.747481\n",
      " cross_entropy: 0.129196, clust_cross_entropy: 1.40864e-05, affinity: 0.00240339, balance: 0.0871142, coact: 0.00226751, frob: 0.000319007\n",
      "step 14400/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.300109 \n",
      " Validation: accuracy: 0.984375 loss: 0.29096\n",
      " cross_entropy: 0.151864, clust_cross_entropy: 4.51704e-07, affinity: 0.00017093, balance: 0.149844, coact: 0.00532637, frob: 0.000326323\n",
      "step 14500/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.267338 \n",
      " Validation: accuracy: 0.96875 loss: 0.366365\n",
      " cross_entropy: 0.18486, clust_cross_entropy: 0.000696373, affinity: 0.000395941, balance: 0.135967, coact: 0.00417928, frob: 0.0003267\n",
      "step 14600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.180575 \n",
      " Validation: accuracy: 0.976562 loss: 0.597549\n",
      " cross_entropy: 0.103144, clust_cross_entropy: 1.58987e-06, affinity: 0.000277898, balance: 0.0673032, coact: 0.0110545, frob: 0.00032601\n",
      "step 14700/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.204441 \n",
      " Validation: accuracy: 0.976562 loss: 0.250728\n",
      " cross_entropy: 0.103483, clust_cross_entropy: 2.28339e-06, affinity: 0.00109521, balance: 0.0208073, coact: 0.00545484, frob: 0.00032577\n",
      "step 14800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.130103 \n",
      " Validation: accuracy: 0.984375 loss: 0.398406\n",
      " cross_entropy: 0.0651701, clust_cross_entropy: 8.38191e-09, affinity: 0.001251, balance: 0.0909107, coact: 0.00782116, frob: 0.000325098\n",
      "step 14900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.226364 \n",
      " Validation: accuracy: 0.992188 loss: 0.262626\n",
      " cross_entropy: 0.0572287, clust_cross_entropy: 0.000188649, affinity: 0.000169833, balance: 0.211156, coact: 0.012066, frob: 0.000336439\n",
      "step 15000/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.31687 \n",
      " Validation: accuracy: 0.976562 loss: 0.567848\n",
      " cross_entropy: 0.11307, clust_cross_entropy: 3.01061e-06, affinity: 0.000700581, balance: 0.179659, coact: 0.00492901, frob: 0.00033401\n",
      "step 15100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.208872 \n",
      " Validation: accuracy: 0.992188 loss: 0.144708\n",
      " cross_entropy: 0.116488, clust_cross_entropy: 1.51807e-07, affinity: 0.000678073, balance: 0.114375, coact: 0.00422874, frob: 0.000324972\n",
      "step 15200/20000 \n",
      " Train: accuracy: 1, loss: 0.150433 \n",
      " Validation: accuracy: 0.976562 loss: 0.334364\n",
      " cross_entropy: 0.0589613, clust_cross_entropy: 7.51732e-05, affinity: 0.000496908, balance: 0.115542, coact: 0.00725409, frob: 0.000329488\n",
      "step 15300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.130162 \n",
      " Validation: accuracy: 0.984375 loss: 0.378542\n",
      " cross_entropy: 0.0410353, clust_cross_entropy: 0, affinity: 0.00031234, balance: 0.0608185, coact: 0.010481, frob: 0.000324763\n",
      "step 15400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.116225 \n",
      " Validation: accuracy: 0.984375 loss: 0.263962\n",
      " cross_entropy: 0.0431943, clust_cross_entropy: 0, affinity: 1.75385e-05, balance: 0.0765016, coact: 0.00543234, frob: 0.000322404\n",
      "step 15500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.13533 \n",
      " Validation: accuracy: 0.976562 loss: 0.402586\n",
      " cross_entropy: 0.112149, clust_cross_entropy: 5.96049e-08, affinity: 0.000938629, balance: 0.0841166, coact: 0.00994106, frob: 0.000331516\n",
      "step 15600/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.238765 \n",
      " Validation: accuracy: 0.96875 loss: 0.62834\n",
      " cross_entropy: 0.0246602, clust_cross_entropy: 2.60771e-08, affinity: 2.40034e-05, balance: 0.164177, coact: 0.00204142, frob: 0.000329776\n",
      "step 15700/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.125143 \n",
      " Validation: accuracy: 1 loss: 0.21581\n",
      " cross_entropy: 0.0554011, clust_cross_entropy: 0, affinity: 0.00045484, balance: 0.0791497, coact: 0.00615156, frob: 0.000321948\n",
      "step 15800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.141425 \n",
      " Validation: accuracy: 0.984375 loss: 0.205713\n",
      " cross_entropy: 0.0988314, clust_cross_entropy: 0, affinity: 0.000464033, balance: 0.05816, coact: 0.0074014, frob: 0.000322916\n",
      "step 15900/20000 \n",
      " Train: accuracy: 1, loss: 0.125979 \n",
      " Validation: accuracy: 0.960938 loss: 0.492507\n",
      " cross_entropy: 0.0619336, clust_cross_entropy: 3.85336e-06, affinity: 0.000220011, balance: 0.112551, coact: 0.00651086, frob: 0.000325\n",
      "step 16000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.256656 \n",
      " Validation: accuracy: 0.976562 loss: 0.344761\n",
      " cross_entropy: 0.0332793, clust_cross_entropy: 5.00129e-07, affinity: 0.000577124, balance: 0.163876, coact: 0.0124858, frob: 0.000323201\n",
      "step 16100/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.258396 \n",
      " Validation: accuracy: 0.976562 loss: 0.297324\n",
      " cross_entropy: 0.120197, clust_cross_entropy: 0, affinity: 0.00101953, balance: 0.135923, coact: 0.0156441, frob: 0.000330588\n",
      "step 16200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.242281 \n",
      " Validation: accuracy: 0.976562 loss: 0.32144\n",
      " cross_entropy: 0.0985162, clust_cross_entropy: 4.88315e-05, affinity: 0.000257347, balance: 0.113958, coact: 0.00894041, frob: 0.000325217\n",
      "step 16300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.1991 \n",
      " Validation: accuracy: 0.96875 loss: 0.426526\n",
      " cross_entropy: 0.0823744, clust_cross_entropy: 0, affinity: 0.0011727, balance: 0.159855, coact: 0.0049246, frob: 0.000328586\n",
      "step 16400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.21654 \n",
      " Validation: accuracy: 0.984375 loss: 0.548408\n",
      " cross_entropy: 0.0481174, clust_cross_entropy: 8.25284e-06, affinity: 0.00108788, balance: 0.114606, coact: 0.0019677, frob: 0.000337399\n",
      "step 16500/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.157682 \n",
      " Validation: accuracy: 0.96875 loss: 0.517621\n",
      " cross_entropy: 0.125539, clust_cross_entropy: 2.95232e-07, affinity: 0.000766481, balance: 0.0937021, coact: 0.00111738, frob: 0.000326193\n",
      "step 16600/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.253752 \n",
      " Validation: accuracy: 0.976562 loss: 0.535442\n",
      " cross_entropy: 0.137225, clust_cross_entropy: 2.21658e-07, affinity: 0.00091614, balance: 0.147795, coact: 0.00639861, frob: 0.000334305\n",
      "step 16700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.13171 \n",
      " Validation: accuracy: 0.960938 loss: 0.3438\n",
      " cross_entropy: 0.0289032, clust_cross_entropy: 0, affinity: 0.000849805, balance: 0.0886148, coact: 0.00197878, frob: 0.000327841\n",
      "step 16800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.169761 \n",
      " Validation: accuracy: 0.992188 loss: 0.445227\n",
      " cross_entropy: 0.0484578, clust_cross_entropy: 0, affinity: 0.00170395, balance: 0.104731, coact: 0.018996, frob: 0.000319362\n",
      "step 16900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.148476 \n",
      " Validation: accuracy: 1 loss: 0.137087\n",
      " cross_entropy: 0.102056, clust_cross_entropy: 3.50036e-05, affinity: 0.00146463, balance: 0.0631084, coact: 0.00159557, frob: 0.00031833\n",
      "step 17000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.145353 \n",
      " Validation: accuracy: 0.992188 loss: 0.262446\n",
      " cross_entropy: 0.0847536, clust_cross_entropy: 1.39612e-06, affinity: 0.00042118, balance: 0.031764, coact: 0.00740381, frob: 0.000332688\n",
      "step 17100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.22966 \n",
      " Validation: accuracy: 0.992188 loss: 0.351698\n",
      " cross_entropy: 0.0423585, clust_cross_entropy: 1.66344e-05, affinity: 0.000119347, balance: 0.146912, coact: 0.00169995, frob: 0.000340835\n",
      "step 17200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.228075 \n",
      " Validation: accuracy: 0.992188 loss: 0.219069\n",
      " cross_entropy: 0.0582625, clust_cross_entropy: 1.02446e-08, affinity: 0.000208452, balance: 0.153655, coact: 0.00391244, frob: 0.000327752\n",
      "step 17300/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.235589 \n",
      " Validation: accuracy: 0.960938 loss: 0.503739\n",
      " cross_entropy: 0.0477357, clust_cross_entropy: 0, affinity: 0.000642013, balance: 0.124795, coact: 0.0156433, frob: 0.000335585\n",
      "step 17400/20000 \n",
      " Train: accuracy: 1, loss: 0.12018 \n",
      " Validation: accuracy: 0.984375 loss: 0.208097\n",
      " cross_entropy: 0.0455911, clust_cross_entropy: 1.38826e-06, affinity: 0.000256174, balance: 0.068174, coact: 0.00547824, frob: 0.000332901\n",
      "step 17500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.133727 \n",
      " Validation: accuracy: 0.992188 loss: 0.276168\n",
      " cross_entropy: 0.0389995, clust_cross_entropy: 0, affinity: 0.000169426, balance: 0.0691497, coact: 0.017181, frob: 0.000332431\n",
      "step 17600/20000 \n",
      " Train: accuracy: 1, loss: 0.1097 \n",
      " Validation: accuracy: 0.992188 loss: 0.26442\n",
      " cross_entropy: 0.0250788, clust_cross_entropy: 0, affinity: 0.00048344, balance: 0.0725746, coact: 0.00557687, frob: 0.000324511\n",
      "step 17700/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.207677 \n",
      " Validation: accuracy: 0.976562 loss: 0.218916\n",
      " cross_entropy: 0.0320088, clust_cross_entropy: 1.57734e-06, affinity: 0.000525252, balance: 0.125975, coact: 0.00755103, frob: 0.000341949\n",
      "step 17800/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.178059 \n",
      " Validation: accuracy: 0.976562 loss: 0.271289\n",
      " cross_entropy: 0.0730017, clust_cross_entropy: 3.94502e-06, affinity: 0.00053116, balance: 0.0861415, coact: 0.00865651, frob: 0.000330544\n",
      "step 17900/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.233611 \n",
      " Validation: accuracy: 0.960938 loss: 0.267196\n",
      " cross_entropy: 0.0497972, clust_cross_entropy: 4.6067e-05, affinity: 0.000490768, balance: 0.161938, coact: 0.00110034, frob: 0.000337458\n",
      "step 18000/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.200851 \n",
      " Validation: accuracy: 0.992188 loss: 0.220231\n",
      " cross_entropy: 0.0814314, clust_cross_entropy: 6.61242e-08, affinity: 0.000694576, balance: 0.0793625, coact: 0.00741081, frob: 0.000334738\n",
      "step 18100/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.174084 \n",
      " Validation: accuracy: 0.992188 loss: 0.234031\n",
      " cross_entropy: 0.0317945, clust_cross_entropy: 0, affinity: 0.000277884, balance: 0.0681944, coact: 0.00369453, frob: 0.000343264\n",
      "step 18200/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.214838 \n",
      " Validation: accuracy: 0.992188 loss: 0.153985\n",
      " cross_entropy: 0.0556266, clust_cross_entropy: 0, affinity: 0.000164128, balance: 0.0996545, coact: 0.000385999, frob: 0.000341953\n",
      "step 18300/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.132599 \n",
      " Validation: accuracy: 0.992188 loss: 0.157591\n",
      " cross_entropy: 0.0879818, clust_cross_entropy: 0, affinity: 0.00184711, balance: 0.0649273, coact: 0.00238456, frob: 0.000342875\n",
      "step 18400/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.15936 \n",
      " Validation: accuracy: 0.976562 loss: 0.374436\n",
      " cross_entropy: 0.053755, clust_cross_entropy: 1.19771e-05, affinity: 0.000544745, balance: 0.155467, coact: 0.00608213, frob: 0.000335621\n",
      "step 18500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.141329 \n",
      " Validation: accuracy: 0.976562 loss: 0.356422\n",
      " cross_entropy: 0.0780225, clust_cross_entropy: 0, affinity: 0, balance: 0.0804263, coact: 0.00428458, frob: 0.000325497\n",
      "step 18600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.164018 \n",
      " Validation: accuracy: 1 loss: 0.207369\n",
      " cross_entropy: 0.0872074, clust_cross_entropy: 1.34111e-07, affinity: 0.00117032, balance: 0.0823636, coact: 0.0135412, frob: 0.000334575\n",
      "step 18700/20000 \n",
      " Train: accuracy: 1, loss: 0.251219 \n",
      " Validation: accuracy: 0.984375 loss: 0.313609\n",
      " cross_entropy: 0.0504795, clust_cross_entropy: 3.6054e-05, affinity: 0.000575687, balance: 0.123686, coact: 0.00902327, frob: 0.000331891\n",
      "step 18800/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.153053 \n",
      " Validation: accuracy: 0.984375 loss: 0.445171\n",
      " cross_entropy: 0.0403456, clust_cross_entropy: 0, affinity: 0.000281813, balance: 0.0468037, coact: 0.00387058, frob: 0.000329748\n",
      "step 18900/20000 \n",
      " Train: accuracy: 1, loss: 0.0926283 \n",
      " Validation: accuracy: 0.945312 loss: 0.659231\n",
      " cross_entropy: 0.0279593, clust_cross_entropy: 7.17122e-08, affinity: 0.000339952, balance: 0.0856016, coact: 0.0114428, frob: 0.000334214\n",
      "step 19000/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.167183 \n",
      " Validation: accuracy: 0.992188 loss: 0.261995\n",
      " cross_entropy: 0.0350951, clust_cross_entropy: 0, affinity: 6.00992e-05, balance: 0.0583675, coact: 0.00679271, frob: 0.000334415\n",
      "step 19100/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.155486 \n",
      " Validation: accuracy: 0.984375 loss: 0.2723\n",
      " cross_entropy: 0.0772182, clust_cross_entropy: 2.68813e-05, affinity: 1.0004e-05, balance: 0.0462957, coact: 0.00133025, frob: 0.000327258\n",
      "step 19200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.151122 \n",
      " Validation: accuracy: 0.984375 loss: 0.271577\n",
      " cross_entropy: 0.0244956, clust_cross_entropy: 4.3025e-06, affinity: 0.000181546, balance: 0.0806502, coact: 0.00626418, frob: 0.000326961\n",
      "step 19300/20000 \n",
      " Train: accuracy: 1, loss: 0.0702031 \n",
      " Validation: accuracy: 0.984375 loss: 0.276245\n",
      " cross_entropy: 0.0470508, clust_cross_entropy: 0, affinity: 0.000189704, balance: 0.0365398, coact: 0.00480572, frob: 0.0003362\n",
      "step 19400/20000 \n",
      " Train: accuracy: 1, loss: 0.111115 \n",
      " Validation: accuracy: 1 loss: 0.226767\n",
      " cross_entropy: 0.0476199, clust_cross_entropy: 0.000978208, affinity: 0.000481246, balance: 0.0690598, coact: 0.00110498, frob: 0.000332793\n",
      "step 19500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.170574 \n",
      " Validation: accuracy: 1 loss: 0.284953\n",
      " cross_entropy: 0.0730843, clust_cross_entropy: 0, affinity: 0.000305716, balance: 0.178942, coact: 0.0174524, frob: 0.000333815\n",
      "step 19600/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.175736 \n",
      " Validation: accuracy: 0.992188 loss: 0.565647\n",
      " cross_entropy: 0.147985, clust_cross_entropy: 5.89819e-05, affinity: 0.000754533, balance: 0.0470804, coact: 0.00513746, frob: 0.000340189\n",
      "step 19700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.165875 \n",
      " Validation: accuracy: 0.992188 loss: 0.40576\n",
      " cross_entropy: 0.0993744, clust_cross_entropy: 2.51458e-08, affinity: 0.000282328, balance: 0.0549286, coact: 0.004316, frob: 0.000331306\n",
      "step 19800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.175325 \n",
      " Validation: accuracy: 0.976562 loss: 0.234325\n",
      " cross_entropy: 0.0579436, clust_cross_entropy: 0.00378101, affinity: 0.000383008, balance: 0.174918, coact: 0.00711198, frob: 0.000331987\n",
      "step 19900/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.167522 \n",
      " Validation: accuracy: 0.976562 loss: 0.35497\n",
      " cross_entropy: 0.0622507, clust_cross_entropy: 5.4548e-06, affinity: 0.000722457, balance: 0.0683873, coact: 0.0208774, frob: 0.000344717\n"
     ]
    }
   ],
   "source": [
    "#Learning with everything -> step 2\n",
    "totalSteps=20000\n",
    "\n",
    "convy2 = y2\n",
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "for i in range(totalSteps):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images, train_labels_clipped, train_super_labels,_epochs_completed_train,_index_in_epoch_train)\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels, validation_super_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1], y2_: valbatch[2],keep_prob: 0.3})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g, clust_cross_entropy: %g, affinity: %g, balance: %g, coact: %g, frob: %g\"%(cc0*entr, cc5*entr2 ,cc1*hist['affinity'][-1],cc2*(1-hist['balance'][-1]),cc3*hist['coactivity'][-1],cc4*frb))\n",
    "    feed_dict = {x: trainbatch[0], y_: trainbatch[1], y2_: trainbatch[2],keep_prob: 0.3}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: accuracy: 0.976562, loss: 0.293484\n",
      "Test: accuracy: 0.984375, loss: 0.293947\n",
      "Test: accuracy: 1, loss: 0.205227\n",
      "Test: accuracy: 0.992188, loss: 0.162449\n",
      "Test: accuracy: 0.992188, loss: 0.177489\n",
      "Test: accuracy: 1, loss: 0.0712948\n",
      "Test: accuracy: 0.984375, loss: 0.368067\n",
      "Test: accuracy: 0.992188, loss: 0.102358\n",
      "Test: accuracy: 0.976562, loss: 0.157928\n",
      "Test: accuracy: 1, loss: 0.176039\n",
      "Test: accuracy: 1, loss: 0.129421\n",
      "Test: accuracy: 0.984375, loss: 0.251613\n",
      "Test: accuracy: 0.984375, loss: 0.263382\n",
      "Test: accuracy: 1, loss: 0.0607565\n",
      "Test: accuracy: 0.984375, loss: 0.257975\n",
      "Test: accuracy: 1, loss: 0.178439\n",
      "Test: accuracy: 0.992188, loss: 0.140905\n",
      "Test: accuracy: 0.992188, loss: 0.174653\n",
      "Test: accuracy: 0.992188, loss: 0.162298\n",
      "Test: accuracy: 0.992188, loss: 0.227417\n",
      "Test: accuracy: 0.992188, loss: 0.152748\n",
      "Test: accuracy: 1, loss: 0.0812796\n",
      "Test: accuracy: 0.976562, loss: 0.266734\n",
      "Test: accuracy: 0.992188, loss: 0.16361\n",
      "Test: accuracy: 1, loss: 0.195422\n",
      "Test: accuracy: 0.976562, loss: 0.28599\n",
      "Test: accuracy: 0.992188, loss: 0.121345\n",
      "Test: accuracy: 0.984375, loss: 0.226113\n",
      "Test: accuracy: 0.976562, loss: 0.278928\n",
      "Test: accuracy: 0.96875, loss: 0.424201\n",
      "Test: accuracy: 1, loss: 0.09897\n",
      "Test: accuracy: 0.984375, loss: 0.313075\n",
      "Test: accuracy: 1, loss: 0.15518\n",
      "Test: accuracy: 0.976562, loss: 0.245741\n",
      "Test: accuracy: 0.976562, loss: 0.285754\n",
      "Test: accuracy: 1, loss: 0.164565\n",
      "Test: accuracy: 0.992188, loss: 0.216034\n",
      "Test: accuracy: 1, loss: 0.225578\n",
      "Test: accuracy: 0.992188, loss: 0.148488\n",
      "Test: accuracy: 1, loss: 0.0676062\n",
      "Test: accuracy: 0.992188, loss: 0.31664\n",
      "Test: accuracy: 0.984375, loss: 0.276553\n",
      "Test: accuracy: 0.992188, loss: 0.152633\n",
      "Test: accuracy: 0.992188, loss: 0.167648\n",
      "Test: accuracy: 0.984375, loss: 0.227553\n",
      "Test: accuracy: 0.992188, loss: 0.0583419\n",
      "Test: accuracy: 0.992188, loss: 0.106059\n",
      "Test: accuracy: 1, loss: 0.19033\n",
      "Test: accuracy: 0.984375, loss: 0.219637\n",
      "Test: accuracy: 0.984375, loss: 0.153981\n",
      "Test: accuracy: 0.984375, loss: 0.227187\n",
      "Test: accuracy: 1, loss: 0.223528\n",
      "Test: accuracy: 1, loss: 0.174473\n",
      "Test: accuracy: 1, loss: 0.0853734\n",
      "Test: accuracy: 0.992188, loss: 0.302443\n",
      "Test: accuracy: 1, loss: 0.102219\n",
      "Test: accuracy: 0.984375, loss: 0.20108\n",
      "Test: accuracy: 0.960938, loss: 0.331987\n",
      "Test: accuracy: 0.984375, loss: 0.190581\n",
      "Test: accuracy: 1, loss: 0.123941\n",
      "Test: accuracy: 0.96875, loss: 0.272773\n",
      "Test: accuracy: 1, loss: 0.190732\n",
      "Test: accuracy: 0.976562, loss: 0.25119\n",
      "Test: accuracy: 1, loss: 0.19257\n",
      "Test: accuracy: 1, loss: 0.20244\n",
      "Test: accuracy: 0.984375, loss: 0.188231\n",
      "Test: accuracy: 0.992188, loss: 0.359805\n",
      "Test: accuracy: 0.976562, loss: 0.244713\n",
      "Test: accuracy: 0.992188, loss: 0.24501\n",
      "Test: accuracy: 0.992188, loss: 0.185169\n",
      "Test: accuracy: 0.992188, loss: 0.231775\n",
      "Test: accuracy: 0.984375, loss: 0.279332\n",
      "Test: accuracy: 0.992188, loss: 0.180215\n",
      "Test: accuracy: 0.992188, loss: 0.207628\n",
      "Test: accuracy: 0.992188, loss: 0.222106\n",
      "Test: accuracy: 0.984375, loss: 0.142509\n",
      "Test: accuracy: 1, loss: 0.155227\n",
      "Test: accuracy: 0.976562, loss: 0.244046\n",
      "Test: accuracy: 0.984375, loss: 0.244004\n",
      "Test: accuracy: 1, loss: 0.145001\n",
      "Test: accuracy: 0.960938, loss: 0.375175\n",
      "Test: accuracy: 0.976562, loss: 0.38651\n",
      "Test: accuracy: 0.984375, loss: 0.237106\n",
      "Test: accuracy: 0.984375, loss: 0.330096\n",
      "Test: accuracy: 0.976562, loss: 0.291662\n",
      "Test: accuracy: 0.992188, loss: 0.211262\n",
      "Test: accuracy: 1, loss: 0.136349\n",
      "Test: accuracy: 0.984375, loss: 0.210685\n",
      "Test: accuracy: 1, loss: 0.223778\n",
      "Test: accuracy: 0.992188, loss: 0.27596\n",
      "Test: accuracy: 0.960938, loss: 0.364593\n",
      "Test: accuracy: 1, loss: 0.108669\n",
      "Test: accuracy: 0.992188, loss: 0.15189\n",
      "Test: accuracy: 0.976562, loss: 0.242405\n",
      "Test: accuracy: 0.984375, loss: 0.149321\n",
      "Test: accuracy: 0.984375, loss: 0.347543\n",
      "Test: accuracy: 0.984375, loss: 0.246047\n",
      "Test: accuracy: 0.992188, loss: 0.143282\n",
      "Test: accuracy: 0.992188, loss: 0.148393\n",
      "Test: accuracy: 1, loss: 0.146945\n",
      "0.989062\n"
     ]
    }
   ],
   "source": [
    "tAcc = []\n",
    "testSize = 1000\n",
    "for i in range(100):\n",
    "    testbatch = next_batch(batchSize,True,test_images, test_labels, test_super_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "\n",
    "    test_loss,test_acc = sess.run([loss,accuracy],{x: testbatch[0], y_: testbatch[1], y2_: testbatch[2],keep_prob: 1.0})\n",
    "    tAcc.append(test_acc)\n",
    "    print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))\n",
    "print np.average(tAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5e0ced37d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAANSCAYAAAAtZYyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e52b97410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy and loss\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(211)\n",
    "plt.plot(hist['train_acc'],'-b',label='train_acc')\n",
    "plt.plot(hist['val_acc'],'-r',label='val_acc')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['val_loss'],'-r',label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5e0cb43790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAGfCAYAAAAHwBxKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e0d0d8410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "#plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['affinity'],'-r',label='affinity')\n",
    "plt.plot(np.subtract(1,hist['balance']),'-y',label='balance')\n",
    "plt.plot(hist['coactivity'],'-g',label='coactivity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digitTrace = np.zeros((classCount*clustCount,784))\n",
    "digitTraceCount = np.zeros((classCount*clustCount))\n",
    "digitCount = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    testbatch = next_batch(1,True,test_images, test_labels, test_super_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "    lbl = testbatch[2].ravel()\n",
    "    digitCount[np.argmax(lbl)]+=1\n",
    "    smMat, acc = sess.run([softmaxMat,accuracy],feed_dict={x: testbatch[0], y_: testbatch[1], y2_:testbatch[2],keep_prob: 1.0})\n",
    "    ypred = softmaxMat.eval({x: testbatch[0], y_: testbatch[1], y2_:testbatch[2],keep_prob: 1.0})\n",
    "    ypred.reshape(10)\n",
    "    digitTrace[np.argmax(ypred),:] += testbatch[0].ravel()\n",
    "    digitTraceCount[np.argmax(ypred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100.  134.  105.   93.   89.   91.   83.   96.  109.  100.]\n",
      "[ 100.  135.  108.   92.   88.   93.   80.   94.  109.  101.]\n"
     ]
    }
   ],
   "source": [
    "print(digitCount)\n",
    "print(digitTraceCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAC4CAYAAACPdMm0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoXd2AzDMIxYYTc2wzAMI1b8f/qAdLVDeIHIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e48321210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stepCount = len(hist['train_acc'])*100\n",
    "with open('./trainlog.txt','ab') as f:\n",
    "    f.write('lr: %g, batchsize: %i, steps: %i, thresh: %g, c1: %g, c2: %g, c3: %g, c4: %g, test_acc: %g, test_loss: %g\\n'%\n",
    "            (lr,batchSize,stepCount,tresh.eval(), cc1, cc2, cc3, cc4, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "Clustering Accuracy: 0.975\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "(10000, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "testbatch = next_batch(10000,True,test_images, test_labels, test_super_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "lbls = testbatch[2].reshape(10000,10)\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1],y2_:testbatch[2],keep_prob: 1.0}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((testbatch[0].shape[0],clustCount*classCount))\n",
    "print(np.argmax(ypred,1).shape)\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(testbatch[2][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(lbls,1).astype('int32'))\n",
    "clustaccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(clustaccuracy))\n",
    "print(ylookup)\n",
    "print(testbatch[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "testbatch = [test_images[:1000,:],test_super_labels[:1000,:],test_labels[:1000,:,:]]\n",
    "lbls = testbatch[2].reshape(1000,10)\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1],y2_:testbatch[2],keep_prob: 0.0}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((testbatch[0].shape[0],clustCount*classCount))\n",
    "print(np.argmax(ypred,1).shape)\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(testbatch[2][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(lbls,1).astype('int32')).eval()\n",
    "\n",
    "with open('acol_reproduction-fixedNodes partial learning_%g.txt'%(perc),'w') as f:\n",
    "    f.write(str(correct_prediction))\n",
    "print(np.sum(correct_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it to k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb0 = [tb[0][np.argmax(tb[1],1)<5],tb[1][np.argmax(tb[1],1)<5]]\n",
    "tb1 = [tb[0][np.argmax(tb[1],1)>4],tb[1][np.argmax(tb[1],1)>4]]\n",
    "#<5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km0_ypred = kmeans.fit_transform(tb0[0])\n",
    "km0_ypred = np.argmax(km0_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb0[1][km0_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km0_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb0[1],1).astype('int32'))\n",
    "km0_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "#>4\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km1_ypred = kmeans.fit_transform(tb1[0])\n",
    "km1_ypred = np.argmax(km1_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb1[1][km1_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km1_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb1[1],1).astype('int32'))\n",
    "km1_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "print('ACOL Accuracy: %g'%(accuracy))\n",
    "print('KMeans Accuracy: %g'%((km0_accuracy+km1_accuracy)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualise kmeans\n",
    "digitTrace = np.concatenate([[np.sum(tb0[0][km0_ypred==i,:],axis=0) for i in range(clustCount)],\n",
    "                       [np.sum(tb1[0][km1_ypred==i,:],axis=0) for i in range(clustCount)]])\n",
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
