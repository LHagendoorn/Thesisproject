{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACOL replication tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "perc = float(os.environ.get('perc', 0.01))\n",
    "balanced = bool(os.environ.get('balanced', True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage subclass labelled: 0.01\n",
      "Balanced: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage subclass labelled: %g\"%(perc))\n",
    "print(\"Balanced: %r\"%(balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from notifiers import notify\n",
    "import random\n",
    "\n",
    "#imports and settings: \n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from jupyterthemes import jtplot\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import threshold\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "#jtplot.style()\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "\n",
    "local_file = base.maybe_download(TRAIN_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_images = mnist.extract_images(f)\n",
    "    \n",
    "local_file = base.maybe_download(TRAIN_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TRAIN_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    train_labels = mnist.extract_labels(f, one_hot=True)\n",
    "\n",
    "local_file = base.maybe_download(TEST_IMAGES, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_IMAGES)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_images = mnist.extract_images(f)\n",
    "\n",
    "local_file = base.maybe_download(TEST_LABELS, './MNIST_data',\n",
    "                                   SOURCE_URL + TEST_LABELS)\n",
    "with open(local_file, 'rb') as f:\n",
    "    test_labels = mnist.extract_labels(f, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def notify(body):\n",
    "#    msg = MIMEText(body)\n",
    "#    # me == the sender's email address\n",
    "    # you == the recipient's email address\n",
    "#    msg['Subject'] = 'Finished training!'\n",
    "#    msg['From'] = \"scriptnotificiations@gmail.com\"\n",
    "#    msg['To'] = \"scriptnotificiations@gmail.com\"\n",
    "\n",
    "    # Send the message via our own SMTP server, but don't include the\n",
    "    # envelope header.\n",
    "#    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "#    s.starttls()\n",
    "#    s.login(\"scriptnotificiations@gmail.com\", \"SuperSecretMegaPassword!!!\")\n",
    "#    s.sendmail(\"scriptnotificiations@gmail.com\", [\"scriptnotificiations@gmail.com\"], msg.as_string())\n",
    "#    s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clustCount = 5\n",
    "classCount = 10\n",
    "net = 0\n",
    "trainsteps = 20000\n",
    "\n",
    "#trainsteps = 30000\n",
    "\n",
    "perc = 0.01\n",
    "balance = False\n",
    "\n",
    "validation_size=5000\n",
    "_epochs_completed_train = 0\n",
    "_index_in_epoch_train = 0\n",
    "_epochs_completed_val = 0\n",
    "_index_in_epoch_val = 0\n",
    "_epochs_completed_test = 0\n",
    "_index_in_epoch_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_images=test_images[:int(60000*perc)]\n",
    "#test_labels=test_labels[:int(60000*perc)]\n",
    "\n",
    "#train_super_labels = np.array([y[np.argmax(train_labels[j])] for j in range(60000)])\n",
    "#train_labels_clipped = np.array([train_labels[j] for j in range(int(60000*perc))])\n",
    "#train_labels_clipped = np.concatenate([train_labels_clipped,np.array([train_labels[j] for j in range(int(60000*perc),60000)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([68, 58, 52, 62, 51, 40, 50, 57, 56, 56]))\n"
     ]
    }
   ],
   "source": [
    "if not 0 <= validation_size <= len(train_images):\n",
    "    raise ValueError(\n",
    "        'Validation size should be between 0 and {}. Received: {}.'\n",
    "        .format(len(train_images), validation_size))\n",
    "\n",
    "validation_images = train_images[:validation_size]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "#validation_super_labels = train_super_labels[:validation_size]\n",
    "#validation_labels_clipped = train_labels_clipped[:validation_size]\n",
    "train_images = train_images[validation_size:]\n",
    "train_labels = train_labels[validation_size:]\n",
    "#train_super_labels = train_super_labels[validation_size:]\n",
    "#train_labels_clipped = train_labels_clipped[validation_size:]\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1] * train_images.shape[2])\n",
    "train_images = train_images.astype(np.float32)\n",
    "train_images = np.multiply(train_images, 1.0 / 255.0)\n",
    "\n",
    "validation_images = validation_images.reshape(validation_images.shape[0],validation_images.shape[1] * validation_images.shape[2])\n",
    "validation_images = validation_images.astype(np.float32)\n",
    "validation_images = np.multiply(validation_images, 1.0 / 255.0)\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1] * test_images.shape[2])\n",
    "test_images = test_images.astype(np.float32)\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "trainCount=len(train_images)\n",
    "if balance:\n",
    "    inds = []\n",
    "    classSize = int(np.ceil(trainCount*perc/10))\n",
    "    for j in range(10):\n",
    "        inds.extend([i for i, x in enumerate(np.argmax(train_labels,1)) if x == j][:classSize])\n",
    "    random.shuffle(inds)\n",
    "\n",
    "    train_images=train_images[inds,:]\n",
    "    train_labels=train_labels[inds,:]\n",
    "else:\n",
    "    train_images=train_images[:int(trainCount*perc),:]\n",
    "    train_labels=train_labels[:int(trainCount*perc),:]\n",
    "    \n",
    "print np.unique(np.argmax(train_labels,1),return_counts=True)\n",
    "#    options = dict(dtype=dtypes.float32, reshape=True, seed=None)\n",
    "  \n",
    "#    train = DataSet(train_images, train_labels, **options)\n",
    "#    validation = DataSet(validation_images, validation_labels, **options)\n",
    "#    test = DataSet(test_images, test_labels, **options)\n",
    "  \n",
    "#    mnist = base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, shuffle, images, labels, ep_compl, ep_ind):\n",
    "    _epochs_completed = ep_compl\n",
    "    _index_in_epoch = ep_ind\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = _index_in_epoch\n",
    "    _num_examples = images.shape[0]\n",
    "    # Shuffle for the first epoch\n",
    "    if _epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      _images = images[perm0]\n",
    "      _labels = labels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = _num_examples - start\n",
    "      images_rest_part = _images[start:_num_examples]\n",
    "      labels_rest_part = _labels[start:_num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(_num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        _images = images[perm]\n",
    "        #print(_images)\n",
    "        _labels = labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size - rest_num_examples\n",
    "      end = _index_in_epoch\n",
    "      images_new_part = _images[start:end]\n",
    "      labels_new_part = _labels[start:end]\n",
    "      l = np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "      return np.concatenate((images_rest_part, images_new_part), axis=0) ,l\n",
    "    else:\n",
    "      _index_in_epoch += batch_size\n",
    "      end = _index_in_epoch\n",
    "      return _images[start:end], _labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper funcs\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def matrix_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    return tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "\n",
    "def avg_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_sum(totalSoft,2)\n",
    "\n",
    "def max_softmax(x):\n",
    "    shape = x.get_shape().as_list()\n",
    "    shape[0] = int(-1)\n",
    "    totalSoft = tf.reshape(tf.nn.softmax(tf.contrib.layers.flatten(x)),shape)\n",
    "    return tf.reduce_max(totalSoft,2)\n",
    "\n",
    "def initACOL(in_size,clust,clss):\n",
    "    acolLayers = []\n",
    "    for i in range(clss):\n",
    "        acolLayers.append([\n",
    "            weight_variable([in_size, clustCount]),\n",
    "            bias_variable([clustCount])\n",
    "        ])\n",
    "    return acolLayers\n",
    "        \n",
    "def connectACOL(inLayer,acol):\n",
    "    clust = []\n",
    "    for l in range(0,len(acol)):\n",
    "        clust.append(tf.matmul(inLayer, acol[l][0]) + acol[l][1])\n",
    "    return clust\n",
    "        \n",
    "def acol(input,clust_count, class_count):\n",
    "    acolLayers = []\n",
    "    for i in range(class_count):\n",
    "        if isinstance(input, tuple):\n",
    "                input = input[0]\n",
    "\n",
    "        #I don't know what this bit does, but I don't think it'll hurt anything\n",
    "        #Or maybe it does, who knows\n",
    "        input_shape = input.get_shape()\n",
    "        if input_shape.ndims == 4:\n",
    "            dim = 1\n",
    "            for d in input_shape[1:].as_list():\n",
    "                dim *= d\n",
    "        #    feed_in = tf.reshape(tf.transpose(input,[0,3,1,2]), [-1, dim])\n",
    "        else:\n",
    "            feed_in, dim = (input, int(input_shape[-1]))\n",
    "\n",
    "        init_weights = tf.truncated_normal_initializer(0.0, stddev=0.1)#(0.0, stddev=0.01)\n",
    "        init_biases = tf.constant_initializer(1.0)#(0.1)\n",
    "\n",
    "        weights = weight_variable([dim, clust_count])\n",
    "        biases = bias_variable([clust_count])\n",
    "\n",
    "        acoll = tf.nn.xw_plus_b(input,weights,biases)\n",
    "        acolLayers.append(acol)\n",
    "    return acolLayers    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders (weights&biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    #Init model weights & biases\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    #y_ = tf.placeholder(tf.float32, shape=[None, classCount])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None,classCount])\n",
    "    \n",
    "    #conv_layer1\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    #conv_layer2\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    #fc layer 1\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    #acol = initACOL(1024,clustCount,classCount)\n",
    "\n",
    "    #final fc layer\n",
    "    W_fc2 = weight_variable([1024, classCount])\n",
    "    b_fc2 = bias_variable([classCount])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if net==0:\n",
    "    dropout=0.3\n",
    "    #Define net\n",
    "    #conv 1\n",
    "    l_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    l_pool1 = max_pool_2x2(l_conv1)\n",
    "\n",
    "    #conv 2\n",
    "    l_conv2 = tf.nn.relu(conv2d(l_pool1, W_conv2) + b_conv2)\n",
    "    l_pool2 = max_pool_2x2(l_conv2)\n",
    "\n",
    "    #fc 1\n",
    "    l_pool2_flat = tf.reshape(l_pool2, [-1, 7*7*64])\n",
    "    l_fc1 = tf.nn.relu(tf.matmul(l_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    l_fc1_drop = tf.nn.dropout(l_fc1, keep_prob)\n",
    "\n",
    "    y_conv = tf.nn.softmax(tf.matmul(l_fc1_drop, W_fc2) + b_fc2)\n",
    "    \n",
    "    #l_acol = connectACOL(l_fc1_drop,acol)\n",
    "    #l_acol = acol(l_fc1_drop,clustCount,classCount)\n",
    "\n",
    "    #Classification layer\n",
    "    #stackedClusts = tf.stack(l_acol,1)\n",
    "    #softmaxMat = matrix_softmax(stackedClusts)\n",
    "    #smStacked = tf.reduce_max(softmaxMat,2)\n",
    "\n",
    "    #y_conv = smStacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#helper loss funcs\n",
    "def zBar(x):\n",
    "    xshape = x.shape.as_list()\n",
    "    s=[-1,xshape[1]*xshape[2]]\n",
    "    return tf.maximum(tf.reshape(x,s),0)\n",
    "    \n",
    "def bigU(zb):\n",
    "    return tf.matmul(tf.transpose(zb),zb)\n",
    "\n",
    "def selectNonDiag(x):\n",
    "    selection = np.ones(x.shape.as_list()[0],dtype='float32') - np.eye(x.shape.as_list()[0],dtype='float32')\n",
    "    return tf.reduce_sum(tf.multiply(x,selection))\n",
    "\n",
    "def bigV(x):\n",
    "    smallNu=tf.reshape(tf.reduce_sum(x,axis=0),[1,-1])\n",
    "    return tf.multiply(tf.transpose(smallNu),smallNu)\n",
    "\n",
    "def specialNormalise(x):\n",
    "    top = selectNonDiag(x)\n",
    "    bottom = tf.multiply(tf.to_float(x.shape[1]-1),tf.reduce_sum(tf.multiply(x,np.eye(x.shape[1],dtype='float32'))))\n",
    "    return tf.divide(top,bottom)\n",
    "\n",
    "def frobNorm(x):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x)))\n",
    "\n",
    "tresh = tf.constant(0.03)\n",
    "cc0=1.0\n",
    "cc1=1.0\n",
    "cc2=1.0\n",
    "cc3=0.0003\n",
    "cc4=0.000001\n",
    "cc5=1.0\n",
    "c0 = tf.constant(cc0)\n",
    "c1 = tf.constant(cc1)\n",
    "c2 = tf.constant(cc2)\n",
    "c3val = tf.constant(cc3)\n",
    "c3 = lambda affinity: tf.cond(tf.less(affinity,tresh),lambda: c3val,lambda: tf.constant(0.0))\n",
    "c4 =tf.constant(cc4)\n",
    "c5 = tf.constant(cc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate losses\n",
    "#affinity\n",
    "#bZ = zBar(stackedClusts)#softmaxMat)\n",
    "#bU = bigU(bZ)\n",
    "#coact = selectNonDiag(bU)\n",
    "#affinity = specialNormalise(bU)\n",
    "\n",
    "#balance\n",
    "#bV=bigV(bZ)\n",
    "#balance = specialNormalise(bV)\n",
    "\n",
    "#cluster cross entropy (added if secondary label is set for that input, hard to do with batches?)\n",
    "#clust_cross_entropy = tf.reduce_mean(-tf.reduce_sum(y2_ * tf.log(tf.clip_by_value(softmaxMat,1e-10,1.0)), reduction_indices=[1,2]))\n",
    "\n",
    "#cross entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))\n",
    "\n",
    "#frob = frobNorm(stackedClusts)#softmaxMat)\n",
    "\n",
    "loss = c0*cross_entropy# + c5*clust_cross_entropy# + c1*affinity + c2*tf.subtract(tf.constant(1.0),balance) + c3(affinity)*coact + c4*frob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "totalSteps = trainsteps\n",
    "stepCount=0\n",
    "batchSize = 128\n",
    "hist = {\n",
    "    'train_acc':[],\n",
    "    'val_acc':[],\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'affinity':[],\n",
    "    'balance':[],\n",
    "    'coactivity':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "step 0/20000 \n",
      " Train: accuracy: 0.0625, loss: 12.9949 \n",
      " Validation: accuracy: 0.0703125 loss: 13.1191\n",
      " cross_entropy: 12.6455\n",
      "step 100/20000 \n",
      " Train: accuracy: 0.171875, loss: 7.85091 \n",
      " Validation: accuracy: 0.125 loss: 8.67017\n",
      " cross_entropy: 7.93835\n",
      "step 200/20000 \n",
      " Train: accuracy: 0.15625, loss: 6.00484 \n",
      " Validation: accuracy: 0.257812 loss: 5.36695\n",
      " cross_entropy: 4.96306\n",
      "step 300/20000 \n",
      " Train: accuracy: 0.359375, loss: 3.24849 \n",
      " Validation: accuracy: 0.273438 loss: 4.30508\n",
      " cross_entropy: 3.58213\n",
      "step 400/20000 \n",
      " Train: accuracy: 0.460938, loss: 2.10811 \n",
      " Validation: accuracy: 0.335938 loss: 3.25656\n",
      " cross_entropy: 2.42022\n",
      "step 500/20000 \n",
      " Train: accuracy: 0.554688, loss: 1.7019 \n",
      " Validation: accuracy: 0.507812 loss: 1.99263\n",
      " cross_entropy: 1.90721\n",
      "step 600/20000 \n",
      " Train: accuracy: 0.625, loss: 1.50923 \n",
      " Validation: accuracy: 0.539062 loss: 1.73242\n",
      " cross_entropy: 1.6621\n",
      "step 700/20000 \n",
      " Train: accuracy: 0.609375, loss: 1.49243 \n",
      " Validation: accuracy: 0.523438 loss: 1.77812\n",
      " cross_entropy: 1.09419\n",
      "step 800/20000 \n",
      " Train: accuracy: 0.765625, loss: 0.855971 \n",
      " Validation: accuracy: 0.578125 loss: 1.5385\n",
      " cross_entropy: 0.844961\n",
      "step 900/20000 \n",
      " Train: accuracy: 0.679688, loss: 0.96229 \n",
      " Validation: accuracy: 0.601562 loss: 1.29536\n",
      " cross_entropy: 0.94861\n",
      "step 1000/20000 \n",
      " Train: accuracy: 0.78125, loss: 0.843383 \n",
      " Validation: accuracy: 0.617188 loss: 1.35574\n",
      " cross_entropy: 0.825003\n",
      "step 1100/20000 \n",
      " Train: accuracy: 0.75, loss: 0.708462 \n",
      " Validation: accuracy: 0.71875 loss: 0.939159\n",
      " cross_entropy: 0.61763\n",
      "step 1200/20000 \n",
      " Train: accuracy: 0.804688, loss: 0.595162 \n",
      " Validation: accuracy: 0.734375 loss: 0.878771\n",
      " cross_entropy: 0.60915\n",
      "step 1300/20000 \n",
      " Train: accuracy: 0.820312, loss: 0.572848 \n",
      " Validation: accuracy: 0.695312 loss: 0.961547\n",
      " cross_entropy: 0.602155\n",
      "step 1400/20000 \n",
      " Train: accuracy: 0.75, loss: 0.795414 \n",
      " Validation: accuracy: 0.757812 loss: 0.822408\n",
      " cross_entropy: 0.592067\n",
      "step 1500/20000 \n",
      " Train: accuracy: 0.835938, loss: 0.452711 \n",
      " Validation: accuracy: 0.804688 loss: 0.701492\n",
      " cross_entropy: 0.438921\n",
      "step 1600/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.290371 \n",
      " Validation: accuracy: 0.75 loss: 0.742882\n",
      " cross_entropy: 0.358796\n",
      "step 1700/20000 \n",
      " Train: accuracy: 0.882812, loss: 0.349269 \n",
      " Validation: accuracy: 0.710938 loss: 0.962202\n",
      " cross_entropy: 0.434877\n",
      "step 1800/20000 \n",
      " Train: accuracy: 0.867188, loss: 0.371323 \n",
      " Validation: accuracy: 0.742188 loss: 0.922847\n",
      " cross_entropy: 0.345339\n",
      "step 1900/20000 \n",
      " Train: accuracy: 0.882812, loss: 0.332733 \n",
      " Validation: accuracy: 0.851562 loss: 0.59691\n",
      " cross_entropy: 0.36485\n",
      "step 2000/20000 \n",
      " Train: accuracy: 0.898438, loss: 0.314715 \n",
      " Validation: accuracy: 0.757812 loss: 0.794425\n",
      " cross_entropy: 0.239487\n",
      "step 2100/20000 \n",
      " Train: accuracy: 0.914062, loss: 0.296341 \n",
      " Validation: accuracy: 0.828125 loss: 0.540683\n",
      " cross_entropy: 0.312432\n",
      "step 2200/20000 \n",
      " Train: accuracy: 0.898438, loss: 0.29265 \n",
      " Validation: accuracy: 0.789062 loss: 0.736308\n",
      " cross_entropy: 0.222244\n",
      "step 2300/20000 \n",
      " Train: accuracy: 0.90625, loss: 0.314719 \n",
      " Validation: accuracy: 0.84375 loss: 0.519557\n",
      " cross_entropy: 0.264822\n",
      "step 2400/20000 \n",
      " Train: accuracy: 0.921875, loss: 0.226718 \n",
      " Validation: accuracy: 0.8125 loss: 0.639223\n",
      " cross_entropy: 0.29064\n",
      "step 2500/20000 \n",
      " Train: accuracy: 0.921875, loss: 0.196939 \n",
      " Validation: accuracy: 0.8125 loss: 0.614033\n",
      " cross_entropy: 0.153678\n",
      "step 2600/20000 \n",
      " Train: accuracy: 0.9375, loss: 0.19766 \n",
      " Validation: accuracy: 0.804688 loss: 0.657861\n",
      " cross_entropy: 0.170519\n",
      "step 2700/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.150632 \n",
      " Validation: accuracy: 0.757812 loss: 0.729304\n",
      " cross_entropy: 0.109651\n",
      "step 2800/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.178908 \n",
      " Validation: accuracy: 0.78125 loss: 0.718169\n",
      " cross_entropy: 0.150001\n",
      "step 2900/20000 \n",
      " Train: accuracy: 0.945312, loss: 0.179533 \n",
      " Validation: accuracy: 0.765625 loss: 0.856543\n",
      " cross_entropy: 0.266771\n",
      "step 3000/20000 \n",
      " Train: accuracy: 0.914062, loss: 0.165844 \n",
      " Validation: accuracy: 0.828125 loss: 0.500617\n",
      " cross_entropy: 0.142338\n",
      "step 3100/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.11291 \n",
      " Validation: accuracy: 0.828125 loss: 0.65785\n",
      " cross_entropy: 0.125784\n",
      "step 3200/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.101486 \n",
      " Validation: accuracy: 0.757812 loss: 0.796536\n",
      " cross_entropy: 0.15462\n",
      "step 3300/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.142977 \n",
      " Validation: accuracy: 0.804688 loss: 0.656336\n",
      " cross_entropy: 0.154357\n",
      "step 3400/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.121667 \n",
      " Validation: accuracy: 0.820312 loss: 0.479093\n",
      " cross_entropy: 0.0881476\n",
      "step 3500/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.068759 \n",
      " Validation: accuracy: 0.84375 loss: 0.585799\n",
      " cross_entropy: 0.148832\n",
      "step 3600/20000 \n",
      " Train: accuracy: 0.953125, loss: 0.102455 \n",
      " Validation: accuracy: 0.851562 loss: 0.405838\n",
      " cross_entropy: 0.134223\n",
      "step 3700/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.115063 \n",
      " Validation: accuracy: 0.875 loss: 0.325328\n",
      " cross_entropy: 0.103323\n",
      "step 3800/20000 \n",
      " Train: accuracy: 0.960938, loss: 0.0930418 \n",
      " Validation: accuracy: 0.882812 loss: 0.341887\n",
      " cross_entropy: 0.0696609\n",
      "step 3900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0617181 \n",
      " Validation: accuracy: 0.820312 loss: 0.586577\n",
      " cross_entropy: 0.101185\n",
      "step 4000/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.0746424 \n",
      " Validation: accuracy: 0.835938 loss: 0.621715\n",
      " cross_entropy: 0.0727395\n",
      "step 4100/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0398455 \n",
      " Validation: accuracy: 0.820312 loss: 0.747148\n",
      " cross_entropy: 0.0621946\n",
      "step 4200/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.0628227 \n",
      " Validation: accuracy: 0.820312 loss: 0.611496\n",
      " cross_entropy: 0.0849787\n",
      "step 4300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0752086 \n",
      " Validation: accuracy: 0.898438 loss: 0.361252\n",
      " cross_entropy: 0.0549315\n",
      "step 4400/20000 \n",
      " Train: accuracy: 0.96875, loss: 0.0790187 \n",
      " Validation: accuracy: 0.8125 loss: 0.680334\n",
      " cross_entropy: 0.0692493\n",
      "step 4500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0537143 \n",
      " Validation: accuracy: 0.867188 loss: 0.570605\n",
      " cross_entropy: 0.039781\n",
      "step 4600/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.0510017 \n",
      " Validation: accuracy: 0.867188 loss: 0.353161\n",
      " cross_entropy: 0.0464627\n",
      "step 4700/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.0890353 \n",
      " Validation: accuracy: 0.851562 loss: 0.507662\n",
      " cross_entropy: 0.111973\n",
      "step 4800/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.0578032 \n",
      " Validation: accuracy: 0.820312 loss: 0.721618\n",
      " cross_entropy: 0.0681251\n",
      "step 4900/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.043223 \n",
      " Validation: accuracy: 0.84375 loss: 0.486951\n",
      " cross_entropy: 0.0513956\n",
      "step 5000/20000 \n",
      " Train: accuracy: 1, loss: 0.0224243 \n",
      " Validation: accuracy: 0.882812 loss: 0.385336\n",
      " cross_entropy: 0.0382285\n",
      "step 5100/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.043429 \n",
      " Validation: accuracy: 0.84375 loss: 0.593195\n",
      " cross_entropy: 0.0637138\n",
      "step 5200/20000 \n",
      " Train: accuracy: 0.976562, loss: 0.0549488 \n",
      " Validation: accuracy: 0.867188 loss: 0.461333\n",
      " cross_entropy: 0.0326964\n",
      "step 5300/20000 \n",
      " Train: accuracy: 1, loss: 0.0438201 \n",
      " Validation: accuracy: 0.929688 loss: 0.182648\n",
      " cross_entropy: 0.0548687\n",
      "step 5400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.0431738 \n",
      " Validation: accuracy: 0.835938 loss: 0.614797\n",
      " cross_entropy: 0.055227\n",
      "step 5500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0333648 \n",
      " Validation: accuracy: 0.890625 loss: 0.293087\n",
      " cross_entropy: 0.0255707\n",
      "step 5600/20000 \n",
      " Train: accuracy: 1, loss: 0.0180202 \n",
      " Validation: accuracy: 0.859375 loss: 0.699967\n",
      " cross_entropy: 0.0577449\n",
      "step 5700/20000 \n",
      " Train: accuracy: 1, loss: 0.023071 \n",
      " Validation: accuracy: 0.851562 loss: 0.679645\n",
      " cross_entropy: 0.0430145\n",
      "step 5800/20000 \n",
      " Train: accuracy: 1, loss: 0.0115372 \n",
      " Validation: accuracy: 0.875 loss: 0.524683\n",
      " cross_entropy: 0.0220937\n",
      "step 5900/20000 \n",
      " Train: accuracy: 1, loss: 0.0308826 \n",
      " Validation: accuracy: 0.84375 loss: 0.705722\n",
      " cross_entropy: 0.0222893\n",
      "step 6000/20000 \n",
      " Train: accuracy: 1, loss: 0.0099451 \n",
      " Validation: accuracy: 0.890625 loss: 0.438941\n",
      " cross_entropy: 0.0152351\n",
      "step 6100/20000 \n",
      " Train: accuracy: 1, loss: 0.0166876 \n",
      " Validation: accuracy: 0.867188 loss: 0.542754\n",
      " cross_entropy: 0.0158742\n",
      "step 6200/20000 \n",
      " Train: accuracy: 1, loss: 0.0121195 \n",
      " Validation: accuracy: 0.890625 loss: 0.585413\n",
      " cross_entropy: 0.0124875\n",
      "step 6300/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0326068 \n",
      " Validation: accuracy: 0.828125 loss: 0.511467\n",
      " cross_entropy: 0.0284643\n",
      "step 6400/20000 \n",
      " Train: accuracy: 0.984375, loss: 0.0398499 \n",
      " Validation: accuracy: 0.875 loss: 0.414018\n",
      " cross_entropy: 0.0280678\n",
      "step 6500/20000 \n",
      " Train: accuracy: 1, loss: 0.0215862 \n",
      " Validation: accuracy: 0.84375 loss: 0.600798\n",
      " cross_entropy: 0.0232849\n",
      "step 6600/20000 \n",
      " Train: accuracy: 1, loss: 0.0130107 \n",
      " Validation: accuracy: 0.898438 loss: 0.4638\n",
      " cross_entropy: 0.0101961\n",
      "step 6700/20000 \n",
      " Train: accuracy: 1, loss: 0.0220295 \n",
      " Validation: accuracy: 0.882812 loss: 0.42518\n",
      " cross_entropy: 0.0236975\n",
      "step 6800/20000 \n",
      " Train: accuracy: 1, loss: 0.0109123 \n",
      " Validation: accuracy: 0.851562 loss: 0.496381\n",
      " cross_entropy: 0.0187811\n",
      "step 6900/20000 \n",
      " Train: accuracy: 1, loss: 0.0143987 \n",
      " Validation: accuracy: 0.882812 loss: 0.49596\n",
      " cross_entropy: 0.0154665\n",
      "step 7000/20000 \n",
      " Train: accuracy: 1, loss: 0.00878515 \n",
      " Validation: accuracy: 0.945312 loss: 0.310127\n",
      " cross_entropy: 0.0137507\n",
      "step 7100/20000 \n",
      " Train: accuracy: 1, loss: 0.017909 \n",
      " Validation: accuracy: 0.835938 loss: 0.493999\n",
      " cross_entropy: 0.00588538\n",
      "step 7200/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0234521 \n",
      " Validation: accuracy: 0.90625 loss: 0.364277\n",
      " cross_entropy: 0.0132581\n",
      "step 7300/20000 \n",
      " Train: accuracy: 1, loss: 0.0158498 \n",
      " Validation: accuracy: 0.945312 loss: 0.201437\n",
      " cross_entropy: 0.00964441\n",
      "step 7400/20000 \n",
      " Train: accuracy: 1, loss: 0.0229308 \n",
      " Validation: accuracy: 0.898438 loss: 0.363748\n",
      " cross_entropy: 0.00773547\n",
      "step 7500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0304005 \n",
      " Validation: accuracy: 0.890625 loss: 0.425159\n",
      " cross_entropy: 0.00952484\n",
      "step 7600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0346894 \n",
      " Validation: accuracy: 0.882812 loss: 0.569118\n",
      " cross_entropy: 0.0176011\n",
      "step 7700/20000 \n",
      " Train: accuracy: 1, loss: 0.00796945 \n",
      " Validation: accuracy: 0.859375 loss: 0.641331\n",
      " cross_entropy: 0.0192862\n",
      "step 7800/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0209613 \n",
      " Validation: accuracy: 0.851562 loss: 0.549724\n",
      " cross_entropy: 0.00420212\n",
      "step 7900/20000 \n",
      " Train: accuracy: 1, loss: 0.0110307 \n",
      " Validation: accuracy: 0.90625 loss: 0.343312\n",
      " cross_entropy: 0.00930227\n",
      "step 8000/20000 \n",
      " Train: accuracy: 1, loss: 0.0104114 \n",
      " Validation: accuracy: 0.84375 loss: 0.459381\n",
      " cross_entropy: 0.00916702\n",
      "step 8100/20000 \n",
      " Train: accuracy: 1, loss: 0.0139742 \n",
      " Validation: accuracy: 0.890625 loss: 0.419508\n",
      " cross_entropy: 0.00604874\n",
      "step 8200/20000 \n",
      " Train: accuracy: 1, loss: 0.00730841 \n",
      " Validation: accuracy: 0.890625 loss: 0.390393\n",
      " cross_entropy: 0.0180392\n",
      "step 8300/20000 \n",
      " Train: accuracy: 1, loss: 0.011934 \n",
      " Validation: accuracy: 0.867188 loss: 0.505861\n",
      " cross_entropy: 0.0162449\n",
      "step 8400/20000 \n",
      " Train: accuracy: 1, loss: 0.00836962 \n",
      " Validation: accuracy: 0.914062 loss: 0.263834\n",
      " cross_entropy: 0.0168916\n",
      "step 8500/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0153202 \n",
      " Validation: accuracy: 0.921875 loss: 0.423508\n",
      " cross_entropy: 0.00413493\n",
      "step 8600/20000 \n",
      " Train: accuracy: 1, loss: 0.00813585 \n",
      " Validation: accuracy: 0.898438 loss: 0.497098\n",
      " cross_entropy: 0.0155195\n",
      "step 8700/20000 \n",
      " Train: accuracy: 1, loss: 0.013509 \n",
      " Validation: accuracy: 0.875 loss: 0.404283\n",
      " cross_entropy: 0.00448884\n",
      "step 8800/20000 \n",
      " Train: accuracy: 1, loss: 0.0108572 \n",
      " Validation: accuracy: 0.898438 loss: 0.432598\n",
      " cross_entropy: 0.0116409\n",
      "step 8900/20000 \n",
      " Train: accuracy: 1, loss: 0.00688242 \n",
      " Validation: accuracy: 0.867188 loss: 0.454528\n",
      " cross_entropy: 0.00421662\n",
      "step 9000/20000 \n",
      " Train: accuracy: 1, loss: 0.0090475 \n",
      " Validation: accuracy: 0.804688 loss: 0.601187\n",
      " cross_entropy: 0.00353345\n",
      "step 9100/20000 \n",
      " Train: accuracy: 1, loss: 0.00602523 \n",
      " Validation: accuracy: 0.875 loss: 0.452921\n",
      " cross_entropy: 0.00582322\n",
      "step 9200/20000 \n",
      " Train: accuracy: 1, loss: 0.00380267 \n",
      " Validation: accuracy: 0.898438 loss: 0.430892\n",
      " cross_entropy: 0.00781349\n",
      "step 9300/20000 \n",
      " Train: accuracy: 1, loss: 0.0027531 \n",
      " Validation: accuracy: 0.882812 loss: 0.331319\n",
      " cross_entropy: 0.0105423\n",
      "step 9400/20000 \n",
      " Train: accuracy: 1, loss: 0.00368288 \n",
      " Validation: accuracy: 0.914062 loss: 0.247925\n",
      " cross_entropy: 0.0055225\n",
      "step 9500/20000 \n",
      " Train: accuracy: 1, loss: 0.00524623 \n",
      " Validation: accuracy: 0.867188 loss: 0.299814\n",
      " cross_entropy: 0.00661195\n",
      "step 9600/20000 \n",
      " Train: accuracy: 1, loss: 0.00918998 \n",
      " Validation: accuracy: 0.890625 loss: 0.354622\n",
      " cross_entropy: 0.0109848\n",
      "step 9700/20000 \n",
      " Train: accuracy: 1, loss: 0.00604352 \n",
      " Validation: accuracy: 0.859375 loss: 0.578631\n",
      " cross_entropy: 0.0105717\n",
      "step 9800/20000 \n",
      " Train: accuracy: 1, loss: 0.00581539 \n",
      " Validation: accuracy: 0.84375 loss: 0.691911\n",
      " cross_entropy: 0.00700875\n",
      "step 9900/20000 \n",
      " Train: accuracy: 1, loss: 0.00757709 \n",
      " Validation: accuracy: 0.84375 loss: 0.444436\n",
      " cross_entropy: 0.0141103\n",
      "step 10000/20000 \n",
      " Train: accuracy: 1, loss: 0.00342526 \n",
      " Validation: accuracy: 0.90625 loss: 0.426831\n",
      " cross_entropy: 0.00295619\n",
      "step 10100/20000 \n",
      " Train: accuracy: 1, loss: 0.0106905 \n",
      " Validation: accuracy: 0.890625 loss: 0.587823\n",
      " cross_entropy: 0.00412302\n",
      "step 10200/20000 \n",
      " Train: accuracy: 1, loss: 0.00246721 \n",
      " Validation: accuracy: 0.890625 loss: 0.61256\n",
      " cross_entropy: 0.00232893\n",
      "step 10300/20000 \n",
      " Train: accuracy: 1, loss: 0.00433097 \n",
      " Validation: accuracy: 0.875 loss: 0.391996\n",
      " cross_entropy: 0.00537687\n",
      "step 10400/20000 \n",
      " Train: accuracy: 1, loss: 0.00715863 \n",
      " Validation: accuracy: 0.890625 loss: 0.479668\n",
      " cross_entropy: 0.0062782\n",
      "step 10500/20000 \n",
      " Train: accuracy: 1, loss: 0.00383566 \n",
      " Validation: accuracy: 0.929688 loss: 0.243385\n",
      " cross_entropy: 0.00418264\n",
      "step 10600/20000 \n",
      " Train: accuracy: 0.992188, loss: 0.0147922 \n",
      " Validation: accuracy: 0.898438 loss: 0.478108\n",
      " cross_entropy: 0.00277125\n",
      "step 10700/20000 \n",
      " Train: accuracy: 1, loss: 0.00560927 \n",
      " Validation: accuracy: 0.90625 loss: 0.355874\n",
      " cross_entropy: 0.00206682\n",
      "step 10800/20000 \n",
      " Train: accuracy: 1, loss: 0.00349224 \n",
      " Validation: accuracy: 0.851562 loss: 0.539834\n",
      " cross_entropy: 0.0116687\n",
      "step 10900/20000 \n",
      " Train: accuracy: 1, loss: 0.00266896 \n",
      " Validation: accuracy: 0.867188 loss: 0.52761\n",
      " cross_entropy: 0.00669486\n",
      "step 11000/20000 \n",
      " Train: accuracy: 1, loss: 0.00185429 \n",
      " Validation: accuracy: 0.882812 loss: 0.464944\n",
      " cross_entropy: 0.00228017\n",
      "step 11100/20000 \n",
      " Train: accuracy: 1, loss: 0.00237316 \n",
      " Validation: accuracy: 0.921875 loss: 0.513281\n",
      " cross_entropy: 0.0245189\n",
      "step 11200/20000 \n",
      " Train: accuracy: 1, loss: 0.00736119 \n",
      " Validation: accuracy: 0.945312 loss: 0.206978\n",
      " cross_entropy: 0.00156456\n",
      "step 11300/20000 \n",
      " Train: accuracy: 1, loss: 0.00308649 \n",
      " Validation: accuracy: 0.90625 loss: 0.329976\n",
      " cross_entropy: 0.00395449\n",
      "step 11400/20000 \n",
      " Train: accuracy: 1, loss: 0.00214746 \n",
      " Validation: accuracy: 0.882812 loss: 0.41026\n",
      " cross_entropy: 0.00313039\n",
      "step 11500/20000 \n",
      " Train: accuracy: 1, loss: 0.00291091 \n",
      " Validation: accuracy: 0.835938 loss: 0.481288\n",
      " cross_entropy: 0.00165574\n",
      "step 11600/20000 \n",
      " Train: accuracy: 1, loss: 0.00263025 \n",
      " Validation: accuracy: 0.921875 loss: 0.386158\n",
      " cross_entropy: 0.00157252\n",
      "step 11700/20000 \n",
      " Train: accuracy: 1, loss: 0.00123291 \n",
      " Validation: accuracy: 0.867188 loss: 0.499825\n",
      " cross_entropy: 0.00316047\n",
      "step 11800/20000 \n",
      " Train: accuracy: 1, loss: 0.00309242 \n",
      " Validation: accuracy: 0.875 loss: 0.620541\n",
      " cross_entropy: 0.00170775\n",
      "step 11900/20000 \n",
      " Train: accuracy: 1, loss: 0.00183281 \n",
      " Validation: accuracy: 0.914062 loss: 0.594841\n",
      " cross_entropy: 0.00308568\n",
      "step 12000/20000 \n",
      " Train: accuracy: 1, loss: 0.0063572 \n",
      " Validation: accuracy: 0.914062 loss: 0.427836\n",
      " cross_entropy: 0.00700289\n",
      "step 12100/20000 \n",
      " Train: accuracy: 1, loss: 0.00163219 \n",
      " Validation: accuracy: 0.835938 loss: 0.661075\n",
      " cross_entropy: 0.00335449\n",
      "step 12200/20000 \n",
      " Train: accuracy: 1, loss: 0.00362337 \n",
      " Validation: accuracy: 0.867188 loss: 0.445878\n",
      " cross_entropy: 0.00311159\n",
      "step 12300/20000 \n",
      " Train: accuracy: 1, loss: 0.00110034 \n",
      " Validation: accuracy: 0.898438 loss: 0.393135\n",
      " cross_entropy: 0.00617611\n",
      "step 12400/20000 \n",
      " Train: accuracy: 1, loss: 0.00534922 \n",
      " Validation: accuracy: 0.898438 loss: 0.431528\n",
      " cross_entropy: 0.00315594\n",
      "step 12500/20000 \n",
      " Train: accuracy: 1, loss: 0.00515189 \n",
      " Validation: accuracy: 0.851562 loss: 0.499188\n",
      " cross_entropy: 0.00170831\n",
      "step 12600/20000 \n",
      " Train: accuracy: 1, loss: 0.00193568 \n",
      " Validation: accuracy: 0.9375 loss: 0.30053\n",
      " cross_entropy: 0.00120721\n",
      "step 12700/20000 \n",
      " Train: accuracy: 1, loss: 0.0022868 \n",
      " Validation: accuracy: 0.914062 loss: 0.428859\n",
      " cross_entropy: 0.00381747\n",
      "step 12800/20000 \n",
      " Train: accuracy: 1, loss: 0.0064374 \n",
      " Validation: accuracy: 0.953125 loss: 0.145962\n",
      " cross_entropy: 0.00301501\n",
      "step 12900/20000 \n",
      " Train: accuracy: 1, loss: 0.000618641 \n",
      " Validation: accuracy: 0.882812 loss: 0.600894\n",
      " cross_entropy: 0.00187669\n",
      "step 13000/20000 \n",
      " Train: accuracy: 1, loss: 0.00170347 \n",
      " Validation: accuracy: 0.9375 loss: 0.306038\n",
      " cross_entropy: 0.00109874\n",
      "step 13100/20000 \n",
      " Train: accuracy: 1, loss: 0.00183407 \n",
      " Validation: accuracy: 0.890625 loss: 0.354314\n",
      " cross_entropy: 0.0046242\n",
      "step 13200/20000 \n",
      " Train: accuracy: 1, loss: 0.00967126 \n",
      " Validation: accuracy: 0.890625 loss: 0.654736\n",
      " cross_entropy: 0.00713899\n",
      "step 13300/20000 \n",
      " Train: accuracy: 1, loss: 0.00288956 \n",
      " Validation: accuracy: 0.898438 loss: 0.649407\n",
      " cross_entropy: 0.00418758\n",
      "step 13400/20000 \n",
      " Train: accuracy: 1, loss: 0.00161458 \n",
      " Validation: accuracy: 0.921875 loss: 0.418678\n",
      " cross_entropy: 0.0115556\n",
      "step 13500/20000 \n",
      " Train: accuracy: 1, loss: 0.00137013 \n",
      " Validation: accuracy: 0.90625 loss: 0.37512\n",
      " cross_entropy: 0.00319071\n",
      "step 13600/20000 \n",
      " Train: accuracy: 1, loss: 0.00105851 \n",
      " Validation: accuracy: 0.875 loss: 0.906115\n",
      " cross_entropy: 0.00203339\n",
      "step 13700/20000 \n",
      " Train: accuracy: 1, loss: 0.00186498 \n",
      " Validation: accuracy: 0.898438 loss: 0.459844\n",
      " cross_entropy: 0.0108407\n",
      "step 13800/20000 \n",
      " Train: accuracy: 1, loss: 0.00243474 \n",
      " Validation: accuracy: 0.867188 loss: 0.816747\n",
      " cross_entropy: 0.000957862\n",
      "step 13900/20000 \n",
      " Train: accuracy: 1, loss: 0.00119816 \n",
      " Validation: accuracy: 0.9375 loss: 0.252567\n",
      " cross_entropy: 0.000681241\n",
      "step 14000/20000 \n",
      " Train: accuracy: 1, loss: 0.00109104 \n",
      " Validation: accuracy: 0.875 loss: 0.568713\n",
      " cross_entropy: 0.000601497\n",
      "step 14100/20000 \n",
      " Train: accuracy: 1, loss: 0.00151078 \n",
      " Validation: accuracy: 0.84375 loss: 0.651417\n",
      " cross_entropy: 0.00176264\n",
      "step 14200/20000 \n",
      " Train: accuracy: 1, loss: 0.00153546 \n",
      " Validation: accuracy: 0.875 loss: 0.412111\n",
      " cross_entropy: 0.00135172\n",
      "step 14300/20000 \n",
      " Train: accuracy: 1, loss: 0.00187688 \n",
      " Validation: accuracy: 0.859375 loss: 0.638027\n",
      " cross_entropy: 0.00148161\n",
      "step 14400/20000 \n",
      " Train: accuracy: 1, loss: 0.00164898 \n",
      " Validation: accuracy: 0.929688 loss: 0.243244\n",
      " cross_entropy: 0.0069352\n",
      "step 14500/20000 \n",
      " Train: accuracy: 1, loss: 0.0025385 \n",
      " Validation: accuracy: 0.875 loss: 0.434545\n",
      " cross_entropy: 0.00868203\n",
      "step 14600/20000 \n",
      " Train: accuracy: 1, loss: 0.000797457 \n",
      " Validation: accuracy: 0.914062 loss: 0.519328\n",
      " cross_entropy: 0.0033034\n",
      "step 14700/20000 \n",
      " Train: accuracy: 1, loss: 0.00252371 \n",
      " Validation: accuracy: 0.929688 loss: 0.434799\n",
      " cross_entropy: 0.000764369\n",
      "step 14800/20000 \n",
      " Train: accuracy: 1, loss: 0.00114018 \n",
      " Validation: accuracy: 0.945312 loss: 0.182842\n",
      " cross_entropy: 0.0042768\n",
      "step 14900/20000 \n",
      " Train: accuracy: 1, loss: 0.00100953 \n",
      " Validation: accuracy: 0.90625 loss: 0.360113\n",
      " cross_entropy: 0.00804798\n",
      "step 15000/20000 \n",
      " Train: accuracy: 1, loss: 0.000750223 \n",
      " Validation: accuracy: 0.921875 loss: 0.580097\n",
      " cross_entropy: 0.00485346\n",
      "step 15100/20000 \n",
      " Train: accuracy: 1, loss: 0.000409296 \n",
      " Validation: accuracy: 0.9375 loss: 0.357557\n",
      " cross_entropy: 0.00622625\n",
      "step 15200/20000 \n",
      " Train: accuracy: 1, loss: 0.000475944 \n",
      " Validation: accuracy: 0.898438 loss: 0.40077\n",
      " cross_entropy: 0.00103656\n",
      "step 15300/20000 \n",
      " Train: accuracy: 1, loss: 0.00334661 \n",
      " Validation: accuracy: 0.867188 loss: 0.574164\n",
      " cross_entropy: 0.000700417\n",
      "step 15400/20000 \n",
      " Train: accuracy: 1, loss: 0.0023604 \n",
      " Validation: accuracy: 0.835938 loss: 0.81757\n",
      " cross_entropy: 0.000577756\n",
      "step 15500/20000 \n",
      " Train: accuracy: 1, loss: 0.00212261 \n",
      " Validation: accuracy: 0.9375 loss: 0.421746\n",
      " cross_entropy: 0.00122985\n",
      "step 15600/20000 \n",
      " Train: accuracy: 1, loss: 0.000620347 \n",
      " Validation: accuracy: 0.851562 loss: 0.600115\n",
      " cross_entropy: 0.00084882\n",
      "step 15700/20000 \n",
      " Train: accuracy: 1, loss: 0.00307735 \n",
      " Validation: accuracy: 0.921875 loss: 0.308976\n",
      " cross_entropy: 0.00129286\n",
      "step 15800/20000 \n",
      " Train: accuracy: 1, loss: 0.000647891 \n",
      " Validation: accuracy: 0.867188 loss: 0.749787\n",
      " cross_entropy: 0.000409941\n",
      "step 15900/20000 \n",
      " Train: accuracy: 1, loss: 0.00148741 \n",
      " Validation: accuracy: 0.882812 loss: 0.631952\n",
      " cross_entropy: 0.000691422\n",
      "step 16000/20000 \n",
      " Train: accuracy: 1, loss: 0.00177831 \n",
      " Validation: accuracy: 0.953125 loss: 0.230114\n",
      " cross_entropy: 0.00167532\n",
      "step 16100/20000 \n",
      " Train: accuracy: 1, loss: 0.00126122 \n",
      " Validation: accuracy: 0.914062 loss: 0.351047\n",
      " cross_entropy: 0.000337341\n",
      "step 16200/20000 \n",
      " Train: accuracy: 1, loss: 0.00108805 \n",
      " Validation: accuracy: 0.890625 loss: 0.743901\n",
      " cross_entropy: 0.000544266\n",
      "step 16300/20000 \n",
      " Train: accuracy: 1, loss: 0.00133713 \n",
      " Validation: accuracy: 0.898438 loss: 0.330657\n",
      " cross_entropy: 0.00638597\n",
      "step 16400/20000 \n",
      " Train: accuracy: 1, loss: 0.000249467 \n",
      " Validation: accuracy: 0.921875 loss: 0.673091\n",
      " cross_entropy: 0.0081614\n",
      "step 16500/20000 \n",
      " Train: accuracy: 1, loss: 0.000720913 \n",
      " Validation: accuracy: 0.914062 loss: 0.348848\n",
      " cross_entropy: 0.00184006\n",
      "step 16600/20000 \n",
      " Train: accuracy: 1, loss: 0.000149694 \n",
      " Validation: accuracy: 0.921875 loss: 0.395582\n",
      " cross_entropy: 0.00321839\n",
      "step 16700/20000 \n",
      " Train: accuracy: 1, loss: 0.000624943 \n",
      " Validation: accuracy: 0.867188 loss: 0.79669\n",
      " cross_entropy: 0.000439423\n",
      "step 16800/20000 \n",
      " Train: accuracy: 1, loss: 0.00294018 \n",
      " Validation: accuracy: 0.898438 loss: 0.450743\n",
      " cross_entropy: 0.00116071\n",
      "step 16900/20000 \n",
      " Train: accuracy: 1, loss: 0.00127455 \n",
      " Validation: accuracy: 0.929688 loss: 0.435284\n",
      " cross_entropy: 0.000611796\n",
      "step 17000/20000 \n",
      " Train: accuracy: 1, loss: 0.00267483 \n",
      " Validation: accuracy: 0.890625 loss: 0.684786\n",
      " cross_entropy: 0.00162513\n",
      "step 17100/20000 \n",
      " Train: accuracy: 1, loss: 0.000505321 \n",
      " Validation: accuracy: 0.914062 loss: 0.400976\n",
      " cross_entropy: 0.000162885\n",
      "step 17200/20000 \n",
      " Train: accuracy: 1, loss: 0.00168391 \n",
      " Validation: accuracy: 0.90625 loss: 0.536349\n",
      " cross_entropy: 0.0013083\n",
      "step 17300/20000 \n",
      " Train: accuracy: 1, loss: 0.000748826 \n",
      " Validation: accuracy: 0.851562 loss: 0.757479\n",
      " cross_entropy: 0.000790016\n",
      "step 17400/20000 \n",
      " Train: accuracy: 1, loss: 0.000579303 \n",
      " Validation: accuracy: 0.882812 loss: 0.795661\n",
      " cross_entropy: 0.000183599\n",
      "step 17500/20000 \n",
      " Train: accuracy: 1, loss: 0.000344712 \n",
      " Validation: accuracy: 0.898438 loss: 0.499705\n",
      " cross_entropy: 0.00310187\n",
      "step 17600/20000 \n",
      " Train: accuracy: 1, loss: 0.00245044 \n",
      " Validation: accuracy: 0.875 loss: 0.839114\n",
      " cross_entropy: 0.00204981\n",
      "step 17700/20000 \n",
      " Train: accuracy: 1, loss: 0.00404062 \n",
      " Validation: accuracy: 0.921875 loss: 0.473897\n",
      " cross_entropy: 0.000369579\n",
      "step 17800/20000 \n",
      " Train: accuracy: 1, loss: 0.000289157 \n",
      " Validation: accuracy: 0.90625 loss: 0.485019\n",
      " cross_entropy: 0.000224311\n",
      "step 17900/20000 \n",
      " Train: accuracy: 1, loss: 0.000487309 \n",
      " Validation: accuracy: 0.9375 loss: 0.282737\n",
      " cross_entropy: 0.00230163\n",
      "step 18000/20000 \n",
      " Train: accuracy: 1, loss: 0.000719672 \n",
      " Validation: accuracy: 0.921875 loss: 0.279919\n",
      " cross_entropy: 0.000106441\n",
      "step 18100/20000 \n",
      " Train: accuracy: 1, loss: 0.000242325 \n",
      " Validation: accuracy: 0.921875 loss: 0.498746\n",
      " cross_entropy: 0.00132163\n",
      "step 18200/20000 \n",
      " Train: accuracy: 1, loss: 0.000311154 \n",
      " Validation: accuracy: 0.867188 loss: 0.751678\n",
      " cross_entropy: 0.000396258\n",
      "step 18300/20000 \n",
      " Train: accuracy: 1, loss: 0.00037915 \n",
      " Validation: accuracy: 0.914062 loss: 0.247862\n",
      " cross_entropy: 0.00014071\n",
      "step 18400/20000 \n",
      " Train: accuracy: 1, loss: 0.000377642 \n",
      " Validation: accuracy: 0.851562 loss: 0.613524\n",
      " cross_entropy: 0.000731265\n",
      "step 18500/20000 \n",
      " Train: accuracy: 1, loss: 0.000509462 \n",
      " Validation: accuracy: 0.890625 loss: 0.353954\n",
      " cross_entropy: 0.000560897\n",
      "step 18600/20000 \n",
      " Train: accuracy: 1, loss: 0.00246948 \n",
      " Validation: accuracy: 0.890625 loss: 0.848611\n",
      " cross_entropy: 0.00221807\n",
      "step 18700/20000 \n",
      " Train: accuracy: 1, loss: 0.000695711 \n",
      " Validation: accuracy: 0.890625 loss: 0.6971\n",
      " cross_entropy: 0.000264802\n",
      "step 18800/20000 \n",
      " Train: accuracy: 1, loss: 0.000174725 \n",
      " Validation: accuracy: 0.921875 loss: 0.404785\n",
      " cross_entropy: 0.000162366\n",
      "step 18900/20000 \n",
      " Train: accuracy: 1, loss: 0.000854759 \n",
      " Validation: accuracy: 0.90625 loss: 0.649247\n",
      " cross_entropy: 0.00015128\n",
      "step 19000/20000 \n",
      " Train: accuracy: 1, loss: 0.000444056 \n",
      " Validation: accuracy: 0.9375 loss: 0.421871\n",
      " cross_entropy: 0.000557252\n",
      "step 19100/20000 \n",
      " Train: accuracy: 1, loss: 7.19462e-05 \n",
      " Validation: accuracy: 0.882812 loss: 0.494832\n",
      " cross_entropy: 0.000147481\n",
      "step 19200/20000 \n",
      " Train: accuracy: 1, loss: 0.000299141 \n",
      " Validation: accuracy: 0.921875 loss: 0.488625\n",
      " cross_entropy: 8.6997e-05\n",
      "step 19300/20000 \n",
      " Train: accuracy: 1, loss: 0.00155336 \n",
      " Validation: accuracy: 0.859375 loss: 1.0353\n",
      " cross_entropy: 0.000532783\n",
      "step 19400/20000 \n",
      " Train: accuracy: 1, loss: 0.00195555 \n",
      " Validation: accuracy: 0.882812 loss: 0.495385\n",
      " cross_entropy: 0.000196708\n",
      "step 19500/20000 \n",
      " Train: accuracy: 1, loss: 0.000622129 \n",
      " Validation: accuracy: 0.929688 loss: 0.325347\n",
      " cross_entropy: 0.00178252\n",
      "step 19600/20000 \n",
      " Train: accuracy: 1, loss: 0.00114244 \n",
      " Validation: accuracy: 0.882812 loss: 0.394019\n",
      " cross_entropy: 0.00126781\n",
      "step 19700/20000 \n",
      " Train: accuracy: 1, loss: 0.000366772 \n",
      " Validation: accuracy: 0.882812 loss: 0.642724\n",
      " cross_entropy: 0.00086971\n",
      "step 19800/20000 \n",
      " Train: accuracy: 1, loss: 0.000337235 \n",
      " Validation: accuracy: 0.882812 loss: 0.406292\n",
      " cross_entropy: 0.000859503\n",
      "step 19900/20000 \n",
      " Train: accuracy: 1, loss: 0.000449946 \n",
      " Validation: accuracy: 0.921875 loss: 0.432148\n",
      " cross_entropy: 0.000265095\n"
     ]
    }
   ],
   "source": [
    "#totalSteps = int(totalSteps*perc)\n",
    "print totalSteps\n",
    "dropout=0.3\n",
    "for i in range(20000):\n",
    "    #if i > totalSteps*perc:\n",
    "    #   convy2 = emptyy2\n",
    "        \n",
    "    trainbatch = next_batch(batchSize,True,train_images, train_labels,_epochs_completed_train,_index_in_epoch_train)\n",
    "    trainbatch = (trainbatch[0],trainbatch[1])\n",
    "    valbatch = next_batch(batchSize,True,validation_images, validation_labels,_epochs_completed_val,_index_in_epoch_val)\n",
    "    valbatch = (valbatch[0],valbatch[1])\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_loss,train_acc = sess.run([loss, accuracy],feed_dict={x: trainbatch[0], y_: trainbatch[1],keep_prob:dropout})\n",
    "        val_loss, val_acc = sess.run([loss, accuracy],feed_dict={x: valbatch[0], y_: valbatch[1],keep_prob:dropout})\n",
    "        hist['train_acc'].append(train_acc)\n",
    "        hist['val_acc'].append(val_acc)\n",
    "        hist['train_loss'].append(train_loss)\n",
    "        hist['val_loss'].append(val_loss)\n",
    "        print(\"step %d/%d \\n Train: accuracy: %g, loss: %g \\n Validation: accuracy: %g loss: %g\"%(i,totalSteps, train_acc, train_loss, val_acc, val_loss))\n",
    "        #hist['affinity'].append(affinity.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]}))\n",
    "        #hist['balance'].append(balance.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]}))\n",
    "        #hist['coactivity'].append(coact.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]}))\n",
    "        entr = cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1],keep_prob:dropout})\n",
    "        #entr2 = clust_cross_entropy.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        #frb = frob.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        #print bV.eval(feed_dict={x:trainbatch[0], y_: trainbatch[1]})\n",
    "        \n",
    "        print(\" cross_entropy: %g\"%(cc0*entr))\n",
    "    feed_dict={x: trainbatch[0], y_: trainbatch[1],keep_prob:dropout}\n",
    "    _ = sess.run([train_step],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notify(\"Hello! Look at me plz!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: accuracy: 0.914062, loss: 0.315862\n",
      "Test: accuracy: 0.960938, loss: 0.141533\n",
      "Test: accuracy: 0.898438, loss: 0.601737\n",
      "Test: accuracy: 0.960938, loss: 0.216814\n",
      "Test: accuracy: 0.945312, loss: 0.16731\n",
      "Test: accuracy: 0.929688, loss: 0.279086\n",
      "Test: accuracy: 0.929688, loss: 0.381759\n",
      "Test: accuracy: 0.914062, loss: 0.30101\n",
      "Test: accuracy: 0.9375, loss: 0.224738\n",
      "Test: accuracy: 0.945312, loss: 0.165037\n",
      "Test: accuracy: 0.960938, loss: 0.184409\n",
      "Test: accuracy: 0.929688, loss: 0.305573\n",
      "Test: accuracy: 0.945312, loss: 0.246412\n",
      "Test: accuracy: 0.929688, loss: 0.217355\n",
      "Test: accuracy: 0.914062, loss: 0.205579\n",
      "Test: accuracy: 0.921875, loss: 0.286958\n",
      "Test: accuracy: 0.929688, loss: 0.500221\n",
      "Test: accuracy: 0.945312, loss: 0.295978\n",
      "Test: accuracy: 0.945312, loss: 0.314558\n",
      "Test: accuracy: 0.929688, loss: 0.280176\n",
      "Test: accuracy: 0.914062, loss: 0.300505\n",
      "Test: accuracy: 0.945312, loss: 0.297405\n",
      "Test: accuracy: 0.953125, loss: 0.170788\n",
      "Test: accuracy: 0.9375, loss: 0.343059\n",
      "Test: accuracy: 0.921875, loss: 0.331718\n",
      "Test: accuracy: 0.9375, loss: 0.367347\n",
      "Test: accuracy: 0.945312, loss: 0.363273\n",
      "Test: accuracy: 0.929688, loss: 0.433688\n",
      "Test: accuracy: 0.890625, loss: 0.387105\n",
      "Test: accuracy: 0.921875, loss: 0.23476\n",
      "Test: accuracy: 0.890625, loss: 0.462449\n",
      "Test: accuracy: 0.90625, loss: 0.381721\n",
      "Test: accuracy: 0.929688, loss: 0.371968\n",
      "Test: accuracy: 0.929688, loss: 0.302492\n",
      "Test: accuracy: 0.921875, loss: 0.295086\n",
      "Test: accuracy: 0.9375, loss: 0.265225\n",
      "Test: accuracy: 0.921875, loss: 0.452556\n",
      "Test: accuracy: 0.929688, loss: 0.297359\n",
      "Test: accuracy: 0.945312, loss: 0.168396\n",
      "Test: accuracy: 0.921875, loss: 0.354016\n",
      "Test: accuracy: 0.90625, loss: 0.429195\n",
      "Test: accuracy: 0.945312, loss: 0.162881\n",
      "Test: accuracy: 0.859375, loss: 0.950676\n",
      "Test: accuracy: 0.9375, loss: 0.373423\n",
      "Test: accuracy: 0.9375, loss: 0.248172\n",
      "Test: accuracy: 0.929688, loss: 0.344423\n",
      "Test: accuracy: 0.9375, loss: 0.402463\n",
      "Test: accuracy: 0.945312, loss: 0.421749\n",
      "Test: accuracy: 0.945312, loss: 0.241447\n",
      "Test: accuracy: 0.9375, loss: 0.330003\n",
      "Test: accuracy: 0.890625, loss: 0.406655\n",
      "Test: accuracy: 0.96875, loss: 0.15866\n",
      "Test: accuracy: 0.882812, loss: 0.530049\n",
      "Test: accuracy: 0.914062, loss: 0.341362\n",
      "Test: accuracy: 0.898438, loss: 0.401922\n",
      "Test: accuracy: 0.898438, loss: 0.491253\n",
      "Test: accuracy: 0.90625, loss: 0.549465\n",
      "Test: accuracy: 0.882812, loss: 0.453644\n",
      "Test: accuracy: 0.9375, loss: 0.163549\n",
      "Test: accuracy: 0.945312, loss: 0.302031\n",
      "Test: accuracy: 0.9375, loss: 0.311739\n",
      "Test: accuracy: 0.929688, loss: 0.462085\n",
      "Test: accuracy: 0.929688, loss: 0.361428\n",
      "Test: accuracy: 0.96875, loss: 0.136826\n",
      "Test: accuracy: 0.914062, loss: 0.361658\n",
      "Test: accuracy: 0.921875, loss: 0.489629\n",
      "Test: accuracy: 0.914062, loss: 0.457335\n",
      "Test: accuracy: 0.921875, loss: 0.549597\n",
      "Test: accuracy: 0.890625, loss: 0.585025\n",
      "Test: accuracy: 0.953125, loss: 0.325948\n",
      "Test: accuracy: 0.90625, loss: 0.365886\n",
      "Test: accuracy: 0.914062, loss: 0.367188\n",
      "Test: accuracy: 0.898438, loss: 0.566917\n",
      "Test: accuracy: 0.929688, loss: 0.322303\n",
      "Test: accuracy: 0.960938, loss: 0.172406\n",
      "Test: accuracy: 0.953125, loss: 0.233608\n",
      "Test: accuracy: 0.96875, loss: 0.152207\n",
      "Test: accuracy: 0.960938, loss: 0.121238\n",
      "Test: accuracy: 0.90625, loss: 0.368494\n",
      "Test: accuracy: 0.890625, loss: 0.481938\n",
      "Test: accuracy: 0.9375, loss: 0.299472\n",
      "Test: accuracy: 0.929688, loss: 0.498694\n",
      "Test: accuracy: 0.929688, loss: 0.311497\n",
      "Test: accuracy: 0.9375, loss: 0.261007\n",
      "Test: accuracy: 0.945312, loss: 0.260927\n",
      "Test: accuracy: 0.929688, loss: 0.241951\n",
      "Test: accuracy: 0.90625, loss: 0.320826\n",
      "Test: accuracy: 0.914062, loss: 0.372025\n",
      "Test: accuracy: 0.953125, loss: 0.105996\n",
      "Test: accuracy: 0.945312, loss: 0.290986\n",
      "Test: accuracy: 0.921875, loss: 0.368792\n",
      "Test: accuracy: 0.921875, loss: 0.255348\n",
      "Test: accuracy: 0.90625, loss: 0.518085\n",
      "Test: accuracy: 0.921875, loss: 0.273886\n",
      "Test: accuracy: 0.9375, loss: 0.260975\n",
      "Test: accuracy: 0.929688, loss: 0.267886\n",
      "Test: accuracy: 0.890625, loss: 0.404326\n",
      "Test: accuracy: 0.90625, loss: 0.469156\n",
      "Test: accuracy: 0.945312, loss: 0.278595\n",
      "Test: accuracy: 0.914062, loss: 0.350461\n",
      "0.927188\n"
     ]
    }
   ],
   "source": [
    "tAcc = []\n",
    "testSize = 1000\n",
    "for i in range(100):\n",
    "    testbatch = next_batch(batchSize,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "\n",
    "    test_loss,test_acc = sess.run([loss,accuracy],{x: testbatch[0], y_: testbatch[1],keep_prob:1.0})\n",
    "    tAcc.append(test_acc)\n",
    "    print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))\n",
    "print np.average(tAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.992188, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.921875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.914062, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.921875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.984375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.929688, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.96875, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.953125, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.976562, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.9375, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.945312, loss: 0.350461\n",
      "(128, 10)\n",
      "Test: accuracy: 0.960938, loss: 0.350461\n",
      "0.955390625\n"
     ]
    }
   ],
   "source": [
    "binY = lambda x: 0 if x<5 else 1\n",
    "tAcc = []\n",
    "testSize = 1000\n",
    "for i in range(100):\n",
    "    testbatch = next_batch(batchSize,True,test_images, test_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "    \n",
    "    y_pred = sess.run([y_conv],{x: testbatch[0], y_: testbatch[1],keep_prob:1.0})[0]\n",
    "    print(y_pred.shape)\n",
    "    y_pred = [binY(i) for i in np.argmax(y_pred,1)]\n",
    "    y_gt = [binY(i) for i in np.argmax(testbatch[1],1)]\n",
    "    corr_pred = np.equal(y_pred, y_gt)\n",
    "    test_acc = np.mean(corr_pred)\n",
    "    \n",
    "    tAcc.append(test_acc)\n",
    "    print('Test: accuracy: %g, loss: %g'%(test_acc,test_loss))\n",
    "print np.average(tAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f80429ed8d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAANSCAYAAAD23iayAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niGQwBW0iIiIiIiIZ7P8DerseLPRLj8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8053cae290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy and loss\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(211)\n",
    "plt.plot(hist['train_acc'],'-b',label='train_acc')\n",
    "plt.plot(hist['val_acc'],'-r',label='val_acc')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['val_loss'],'-r',label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f803a82ccd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAGfCAYAAAAEW9AnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804291ec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "#plt.plot(hist['train_loss'],'-b',label='train_loss')\n",
    "plt.plot(hist['affinity'],'-r',label='affinity')\n",
    "plt.plot(np.subtract(1,hist['balance']),'-y',label='balance')\n",
    "plt.plot(hist['coactivity'],'-g',label='coactivity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustCount' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-19c9febbf7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdigitTrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclustCount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdigitTraceCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclustCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdigitCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clustCount' is not defined"
     ]
    }
   ],
   "source": [
    "digitTrace = np.zeros((classCount*clustCount,784))\n",
    "digitTraceCount = np.zeros((classCount*clustCount))\n",
    "digitCount = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    testbatch = next_batch(1,True,test_images, test_labels, test_super_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "    lbl = testbatch[2].ravel()\n",
    "    digitCount[np.argmax(lbl)]+=1\n",
    "    smMat, acc = sess.run([softmaxMat,accuracy],feed_dict={x: testbatch[0], y_: testbatch[1], y2_:testbatch[2],keep_prob:1.0})\n",
    "    ypred = softmaxMat.eval({x: testbatch[0], y_: testbatch[1], y2_:testbatch[2],keep_prob:1.0})\n",
    "    ypred.reshape(10)\n",
    "    digitTrace[np.argmax(ypred),:] += testbatch[0].ravel()\n",
    "    digitTraceCount[np.argmax(ypred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digitCount)\n",
    "print(digitTraceCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stepCount = len(hist['train_acc'])*100\n",
    "with open('./trainlog.txt','ab') as f:\n",
    "    f.write('lr: %g, batchsize: %i, steps: %i, thresh: %g, c1: %g, c2: %g, c3: %g, c4: %g, test_acc: %g, test_loss: %g\\n'%\n",
    "            (lr,batchSize,stepCount,tresh.eval(), cc1, cc2, cc3, cc4, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testbatch = next_batch(10000,True,test_images, test_labels, test_super_labels,_epochs_completed_test,_index_in_epoch_test)\n",
    "lbls = testbatch[2].reshape(10000,10)\n",
    "testFeed = {x: testbatch[0], y_: testbatch[1],y2_:testbatch[2],keep_prob:1.0}\n",
    "ypred = softmaxMat.eval(testFeed)\n",
    "ypred = ypred.reshape((testbatch[0].shape[0],clustCount*classCount))\n",
    "print(np.argmax(ypred,1).shape)\n",
    "ypred = tf.argmax(ypred,1).eval()\n",
    "ylookup = [np.argmax(np.sum(testbatch[2][ypred==i],0)).astype('int32') for i in range(clustCount*classCount)]\n",
    "yconverted = [ylookup[i] for i in ypred]\n",
    "correct_prediction = tf.equal(yconverted, np.argmax(lbls,1).astype('int32'))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).eval()\n",
    "print('Clustering Accuracy: %g'%(accuracy))\n",
    "print(ylookup)\n",
    "print(testbatch[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it to k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb0 = [tb[0][np.argmax(tb[1],1)<5],tb[1][np.argmax(tb[1],1)<5]]\n",
    "tb1 = [tb[0][np.argmax(tb[1],1)>4],tb[1][np.argmax(tb[1],1)>4]]\n",
    "#<5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km0_ypred = kmeans.fit_transform(tb0[0])\n",
    "km0_ypred = np.argmax(km0_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb0[1][km0_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km0_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb0[1],1).astype('int32'))\n",
    "km0_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "#>4\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km1_ypred = kmeans.fit_transform(tb1[0])\n",
    "km1_ypred = np.argmax(km1_ypred,1)\n",
    "km_ylookup = [np.argmax(np.sum(tb1[1][km1_ypred==i],0)).astype('int32') for i in range(clustCount)]\n",
    "km_yconverted = [km_ylookup[i] for i in km1_ypred]\n",
    "km_correct_prediction = tf.equal(km_yconverted, np.argmax(tb1[1],1).astype('int32'))\n",
    "km1_accuracy = tf.reduce_mean(tf.cast(km_correct_prediction, tf.float32)).eval()\n",
    "print('ACOL Accuracy: %g'%(accuracy))\n",
    "print('KMeans Accuracy: %g'%((km0_accuracy+km1_accuracy)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualise kmeans\n",
    "digitTrace = np.concatenate([[np.sum(tb0[0][km0_ypred==i,:],axis=0) for i in range(clustCount)],\n",
    "                       [np.sum(tb1[0][km1_ypred==i,:],axis=0) for i in range(clustCount)]])\n",
    "digitTrace = digitTrace/np.max(digitTrace)\n",
    "f,ax=plt.subplots(nrows=classCount, ncols=clustCount, figsize=(1.5*clustCount,1.5*classCount))\n",
    "gs = gridspec.GridSpec(classCount,clustCount)\n",
    "gs.update(wspace=0.025, hspace=0.025)\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "for i in range(digitTrace.shape[0]):\n",
    "    sp = plt.subplot(gs[i])\n",
    "    sp.set_xticklabels([])\n",
    "    sp.set_yticklabels([])\n",
    "    sp.set_aspect('equal')\n",
    "    sp.grid = False\n",
    "    plt.imshow(np.reshape(digitTrace[i,:],(28,28)),cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
